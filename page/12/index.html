<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">


  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({
      google_ad_client: "ca-pub-5653382914441020",
      enable_page_level_ads: true
    });
  </script>

  <meta name="google-site-verification" content="WSpJFvfcmIPBX_iK8uPbmCHIy_0f1lvd7ZJpbyad2sA">
  <meta name="yandex-verification" content="808eb057eb8396cc">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"kezunlin.me","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Kezunlin&#39;s Blog">
<meta property="og:url" content="https://kezunlin.me/page/12/index.html">
<meta property="og:site_name" content="Kezunlin&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="kezunlin">
<meta property="article:tag" content="linux, c++, python, AI, LLM">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://kezunlin.me/page/12/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Kezunlin's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Kezunlin's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Kezunlin's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Live and Learn</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://kezunlin.me/blog/quick-guide-to-install-and-use-tensorflow-on-ubuntu-16-04/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="kezunlin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kezunlin's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/quick-guide-to-install-and-use-tensorflow-on-ubuntu-16-04/" class="post-title-link" itemprop="url">install and use tensorflow on ubuntu 16.04</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-08-21 17:05:00" itemprop="dateCreated datePublished" datetime="2018-08-21T17:05:00+08:00">2018-08-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-10-14 13:39:28" itemprop="dateModified" datetime="2024-10-14T13:39:28+08:00">2024-10-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Guide"><a href="#Guide" class="headerlink" title="Guide"></a>Guide</h2><ul>
<li><strong><a href="https://kezunlin.me/post/f7eab850/">Part 1: Tensorflow for Unbutu 16.04</a></strong></li>
<li><a href="https://kezunlin.me/post/a123bf9e/">Part 2: Tensorflow for Windows 10</a></li>
</ul>
<h3 id="version"><a href="#version" class="headerlink" title="version"></a>version</h3><ul>
<li>ubuntu 16.04 64 bit</li>
<li>cuda driver 384.130</li>
<li>tensorflow-gpu 1.4.0 (CUDA 8.0 + cudnn 6.0)</li>
<li>tensorflow-gpu 1.5.0+ (CUDA 9.0 + cudnn )</li>
<li>python 3.5</li>
</ul>
<h3 id="install"><a href="#install" class="headerlink" title="install"></a>install</h3><p> version: </p>
<ul>
<li>cpu:  tensorflow</li>
<li>gpu: tensorflow-gpu</li>
</ul>
<p>commands </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">workon py3</span><br><span class="line">pip install tensorflow-gpu==1.4 </span><br><span class="line">pip install keras</span><br><span class="line"></span><br><span class="line">pip install Pillow scipy sklearn scikit-image ipython</span><br><span class="line"></span><br><span class="line">pip list</span><br><span class="line">pip3 list <span class="comment"># same results as pip</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>tips, for virtualenv workon see <a href="https://kezunlin.me/post/f07cae6a/">python virtualenv tutorial</a></p>
</blockquote>
<h3 id="test"><a href="#test" class="headerlink" title="test"></a>test</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">hello = tf.constant(<span class="string">&#x27;Hello, TensorFlow!&#x27;</span>)</span><br><span class="line">sess = tf.Session()</span><br><span class="line"><span class="built_in">print</span> hello</span><br><span class="line"><span class="built_in">print</span>(sess.run(hello))</span><br></pre></td></tr></table></figure>

<p>output </p>
<pre><code>Tensor(&quot;Const:0&quot;, shape=(), dtype=string)
Hello, TensorFlow!
</code></pre>
<h3 id="fix-errors"><a href="#fix-errors" class="headerlink" title="fix errors"></a>fix errors</h3><p>error </p>
<pre><code>ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory
ImportError: libcudnn.so.6: cannot open shared object file: No such file or directory
</code></pre>
<p><code>tensorflow-gpu 1.5</code> use <code>cuda 9.0</code>, so we install <code>tensorflow-gpu 1.4</code>to use <code>cuda 8.0</code></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pip uninstall tensorflow-gpu</span><br><span class="line">pip install tensorflow-gpu==1.4</span><br></pre></td></tr></table></figure>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- kzl in-article ad -->
<p><ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5653382914441020"
     data-ad-slot="7925631830"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h2 id="Jupyter-notebook-with-tensorflow"><a href="#Jupyter-notebook-with-tensorflow" class="headerlink" title="Jupyter notebook with tensorflow"></a>Jupyter notebook with tensorflow</h2><h3 id="install-tensorflow-kernel"><a href="#install-tensorflow-kernel" class="headerlink" title="install tensorflow kernel"></a>install tensorflow kernel</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">workon py3</span><br><span class="line">pip install ipykernel</span><br><span class="line"></span><br><span class="line">python -m ipykernel install --user --name=tensorflow</span><br><span class="line">Installed kernelspec tensorflow <span class="keyword">in</span> /home/kezunlin/.local/share/jupyter/kernels/tensorflow</span><br></pre></td></tr></table></figure>

<h3 id="use-tensorflow-kernel"><a href="#use-tensorflow-kernel" class="headerlink" title="use tensorflow kernel"></a>use tensorflow kernel</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> workspace/anjian</span><br><span class="line">jupyter notebook </span><br></pre></td></tr></table></figure>

<p>create a notebook with <code>tensorflow</code> kernel </p>
<p><img src="https://kezunlin.me/images/posts/635233-20180822180822847-2097924604.png" alt="png"></p>
<h2 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h2><h3 id="disable-info"><a href="#disable-info" class="headerlink" title="disable info"></a>disable info</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>] = <span class="string">&#x27;2&#x27;</span></span><br><span class="line"><span class="comment">#默认为0：输出所有log信息</span></span><br><span class="line"><span class="comment">#设置为1：进一步屏蔽INFO信息</span></span><br><span class="line"><span class="comment">#设置为2：进一步屏蔽WARNING信息</span></span><br><span class="line"><span class="comment">#设置为3：进一步屏蔽ERROR信息</span></span><br><span class="line">```bash</span><br><span class="line"></span><br><span class="line"><span class="comment">### tensorflow errors</span></span><br><span class="line"></span><br><span class="line">error</span><br><span class="line"></span><br><span class="line">    Exception ignored <span class="keyword">in</span>: &lt;bound method BaseSession.__del__ of &lt;tensorflow.python.client.session.Session <span class="built_in">object</span> at <span class="number">0x7fd3edd13e10</span>&gt;&gt;</span><br><span class="line"></span><br><span class="line">    Traceback (most recent call last):</span><br><span class="line">    File <span class="string">&quot;venv/lib/python3.5/site-packages/tensorflow/python/client/session.py&quot;</span>, line <span class="number">712</span>, <span class="keyword">in</span> __del__</span><br><span class="line">    TypeError: <span class="string">&#x27;NoneType&#x27;</span> <span class="built_in">object</span> <span class="keyword">is</span> <span class="keyword">not</span> <span class="built_in">callable</span></span><br><span class="line"></span><br><span class="line">fix </span><br><span class="line">```python</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="comment">#...</span></span><br><span class="line"><span class="comment">#...</span></span><br><span class="line">K.clear_session()</span><br></pre></td></tr></table></figure>

<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/lengguoxing/article/details/78456279">tensorflow tips</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/fan_pgm_v/article/details/79637700">tensorflow with jupyter notebook</a></li>
<li><a target="_blank" rel="noopener" href="https://www.pyimagesearch.com/2015/06/22/install-opencv-3-0-and-python-2-7-on-ubuntu/">install opencv with python on ubuntu</a></li>
</ul>
<h2 id="History"><a href="#History" class="headerlink" title="History"></a>History</h2><ul>
<li>20180821: created.</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://kezunlin.me/blog/guide-to-install-and-use-bazel-on-ubuntu-16-04/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="kezunlin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kezunlin's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/guide-to-install-and-use-bazel-on-ubuntu-16-04/" class="post-title-link" itemprop="url">how to install and use bazel on ubuntu 16.04</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-08-21 15:22:00" itemprop="dateCreated datePublished" datetime="2018-08-21T15:22:00+08:00">2018-08-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-10-14 13:39:28" itemprop="dateModified" datetime="2024-10-14T13:39:28+08:00">2024-10-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/cpp/" itemprop="url" rel="index"><span itemprop="name">cpp</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="How-to-Install"><a href="#How-to-Install" class="headerlink" title="How to Install"></a>How to Install</h2><blockquote>
<p>Bazel is an open-source build and test tool similar to Make, Maven, and Gradle. It uses a human-readable, high-level build language. Bazel supports projects in multiple languages and builds outputs for multiple platforms. Bazel supports large codebases across multiple repositories, and large numbers of users.</p>
</blockquote>
<p>support language and platform:</p>
<ul>
<li>c++</li>
<li>java</li>
<li>android</li>
<li>ios</li>
</ul>
<h3 id="Using-binary-installer"><a href="#Using-binary-installer" class="headerlink" title="Using binary installer"></a>Using binary installer</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get install pkg-config zip g++ zlib1g-dev unzip python</span><br><span class="line"></span><br><span class="line"><span class="comment">#download `bazel-0.16.1-installer-linux-x86_64.sh` from `https://github.com/bazelbuild/bazel/releases`</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">chmod</span> +x bazel-0.16.1-installer-linux-x86_64.sh</span><br><span class="line">./bazel-0.16.1-installer-linux-x86_64.sh --user</span><br><span class="line"><span class="comment"># The --user flag installs Bazel to the $HOME/bin directory on your system and sets the .bazelrc path to $HOME/.bazelrc.</span></span><br><span class="line"></span><br><span class="line">vim .bashrc</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;<span class="variable">$PATH</span>:<span class="variable">$HOME</span>/bin&quot;</span></span><br></pre></td></tr></table></figure>


<h3 id="Using-Bazel-custom-APT-repository"><a href="#Using-Bazel-custom-APT-repository" class="headerlink" title="Using Bazel custom APT repository"></a>Using Bazel custom APT repository</h3><blockquote>
<p>unable to access <code>googleapis.com</code></p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt-get install openjdk-8-jdk</span><br><span class="line"></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8&quot;</span> | <span class="built_in">sudo</span> <span class="built_in">tee</span> /etc/apt/sources.list.d/bazel.list</span><br><span class="line">curl https://bazel.build/bazel-release.pub.gpg | <span class="built_in">sudo</span> apt-key add -</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">sudo</span> apt-get update &amp;&amp; <span class="built_in">sudo</span> apt-get install bazel</span><br><span class="line"><span class="built_in">sudo</span> apt-get upgrade bazel</span><br></pre></td></tr></table></figure>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- kzl in-article ad -->
<p><ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5653382914441020"
     data-ad-slot="7925631830"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h2 id="Tutorial"><a href="#Tutorial" class="headerlink" title="Tutorial"></a>Tutorial</h2><p>get examples</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/bazelbuild/examples/</span><br></pre></td></tr></table></figure>

<p>folder structure</p>
<pre><code>cpp-tutorial/
├── README.md
├── stage1
│   ├── main
│   │   ├── BUILD
│   │   └── hello-world.cc
│   ├── README.md
│   └── WORKSPACE
├── stage2
│   ├── main
│   │   ├── BUILD
│   │   ├── hello-greet.cc
│   │   ├── hello-greet.h
│   │   └── hello-world.cc
│   ├── README.md
│   └── WORKSPACE
└── stage3
    ├── lib
    │   ├── BUILD
    │   ├── hello-time.cc
    │   └── hello-time.h
    ├── main
    │   ├── BUILD
    │   ├── hello-greet.cc
    │   ├── hello-greet.h
    │   └── hello-world.cc
    ├── README.md
    └── WORKSPACE

7 directories, 20 files
</code></pre>
<h3 id="stage1"><a href="#stage1" class="headerlink" title="stage1"></a>stage1</h3><h4 id="Understand-the-BUILD-file"><a href="#Understand-the-BUILD-file" class="headerlink" title="Understand the BUILD file"></a>Understand the BUILD file</h4><p>cpp-tutorial&#x2F;stage1&#x2F;main&#x2F;BUILD</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cc_binary(</span><br><span class="line">    name = &quot;hello-world&quot;,</span><br><span class="line">    srcs = [&quot;hello-world.cc&quot;],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>build target</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> stage1</span><br><span class="line">bazel build //main:hello-world</span><br></pre></td></tr></table></figure>

<p>output</p>
<pre><code>INFO: Found 1 target...
Target //main:hello-world up-to-date:
  bazel-bin/main/hello-world
INFO: Elapsed time: 2.267s, Critical Path: 0.25s
</code></pre>
<p>test binary</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bazel-bin/main/hello-world</span><br></pre></td></tr></table></figure>

<h4 id="Review-the-dependency-graph"><a href="#Review-the-dependency-graph" class="headerlink" title="Review the dependency graph"></a>Review the dependency graph</h4><p>install graphviz </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">sudo</span> apt install graphviz xdot</span><br></pre></td></tr></table></figure>

<p>vizualize </p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bazel query --nohost_deps --noimplicit_deps <span class="string">&#x27;deps(//main:hello-world)&#x27;</span> --output graph</span><br><span class="line">xdot &lt;(bazel query --nohost_deps --noimplicit_deps <span class="string">&#x27;deps(//main:hello-world)&#x27;</span> --output graph)</span><br></pre></td></tr></table></figure>
<p>graph</p>
<p><img src="https://kezunlin.me/images/posts/635233-20180821175314471-138498875.png" alt="png"></p>
<h3 id="stage2"><a href="#stage2" class="headerlink" title="stage2"></a>stage2</h3><p>Specify multiple build targets</p>
<p>cpp-tutorial&#x2F;stage2&#x2F;main&#x2F;BUILD</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cc_library(</span><br><span class="line">    name = &quot;hello-greet&quot;,</span><br><span class="line">    srcs = [&quot;hello-greet.cc&quot;],</span><br><span class="line">    hdrs = [&quot;hello-greet.h&quot;],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">cc_binary(</span><br><span class="line">    name = &quot;hello-world&quot;,</span><br><span class="line">    srcs = [&quot;hello-world.cc&quot;],</span><br><span class="line">    deps = [</span><br><span class="line">        &quot;:hello-greet&quot;,</span><br><span class="line">    ],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>build target</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> stage2</span><br><span class="line">bazel build //main:hello-world</span><br></pre></td></tr></table></figure>

<p>output</p>
<pre><code>INFO: Found 1 target...
Target //main:hello-world up-to-date:
  bazel-bin/main/hello-world
INFO: Elapsed time: 2.267s, Critical Path: 0.25s
</code></pre>
<p>test binary</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bazel-bin/main/hello-world</span><br></pre></td></tr></table></figure>

<p>graph</p>
<p><img src="https://kezunlin.me/images/posts/635233-20180821175337552-1624012450.png" alt="png"></p>
<h3 id="stage3"><a href="#stage3" class="headerlink" title="stage3"></a>stage3</h3><p>Use multiple packages</p>
<p>folder structure</p>
<pre><code>└──stage3
   ├── main
   │   ├── BUILD
   │   ├── hello-world.cc
   │   ├── hello-greet.cc
   │   └── hello-greet.h
   ├── lib
   │   ├── BUILD
   │   ├── hello-time.cc
   │   └── hello-time.h
   └── WORKSPACE
</code></pre>
<p>lib&#x2F;BUILD</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cc_library(</span><br><span class="line">    name = &quot;hello-time&quot;,</span><br><span class="line">    srcs = [&quot;hello-time.cc&quot;],</span><br><span class="line">    hdrs = [&quot;hello-time.h&quot;],</span><br><span class="line">    visibility = [&quot;//main:__pkg__&quot;],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>This is because by default targets are only visible to other targets in the same BUILD file.</p>
<p>main&#x2F;BUILD</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cc_library(</span><br><span class="line">    name = <span class="string">&quot;hello-greet&quot;</span>,</span><br><span class="line">    srcs = [<span class="string">&quot;hello-greet.cc&quot;</span>],</span><br><span class="line">    hdrs = [<span class="string">&quot;hello-greet.h&quot;</span>],</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">cc_binary(</span><br><span class="line">    name = <span class="string">&quot;hello-world&quot;</span>,</span><br><span class="line">    srcs = [<span class="string">&quot;hello-world.cc&quot;</span>],</span><br><span class="line">    deps = [</span><br><span class="line">        <span class="string">&quot;:hello-greet&quot;</span>,</span><br><span class="line">        <span class="string">&quot;//lib:hello-time&quot;</span>,</span><br><span class="line">    ],</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>build target</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> stage3</span><br><span class="line">bazel build //main:hello-world</span><br></pre></td></tr></table></figure>

<p>output</p>
<pre><code>INFO: Found 1 target...
Target //main:hello-world up-to-date:
  bazel-bin/main/hello-world
INFO: Elapsed time: 2.267s, Critical Path: 0.25s
</code></pre>
<p>test binary</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bazel-bin/main/hello-world</span><br></pre></td></tr></table></figure>

<p>graph</p>
<p><img src="https://kezunlin.me/images/posts/635233-20180821175340712-200534963.png" alt="png"></p>
<h3 id="Use-labels-to-reference-targets"><a href="#Use-labels-to-reference-targets" class="headerlink" title="Use labels to reference targets"></a>Use labels to reference targets</h3><pre><code>//path/to/package:target-name
</code></pre>
<ul>
<li>When referencing targets within the same package, you can skip the package path and just use <code>//:target-name</code>. </li>
<li>When referencing targets within the same BUILD file, you can even skip the <code>//</code> workspace root identifier and just use <code>:target-name</code>.</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://docs.bazel.build/versions/master/install.html">bazel install</a></li>
<li><a target="_blank" rel="noopener" href="https://docs.bazel.build/versions/master/tutorial/cpp.html">bazel cpp tutorials</a></li>
</ul>
<h2 id="History"><a href="#History" class="headerlink" title="History"></a>History</h2><ul>
<li>20180821: created.</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://kezunlin.me/blog/introduction-to-neural-network-forward-inference-framework/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="kezunlin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kezunlin's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/introduction-to-neural-network-forward-inference-framework/" class="post-title-link" itemprop="url">introduction to neural network forward/inference framework</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-08-17 10:54:00" itemprop="dateCreated datePublished" datetime="2018-08-17T10:54:00+08:00">2018-08-17</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-10-14 13:39:28" itemprop="dateModified" datetime="2024-10-14T13:39:28+08:00">2024-10-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Guide"><a href="#Guide" class="headerlink" title="Guide"></a>Guide</h2><h3 id="ncnn"><a href="#ncnn" class="headerlink" title="ncnn"></a>ncnn</h3><p>ncnn 是一个为手机端极致优化的高性能神经网络前向计算框架。ncnn 从设计之初深刻考虑手机端的部署和使用。无第三方依赖，跨平台，手机端 cpu 的速度快于目前所有已知的开源框架。基于 ncnn，开发者能够将深度学习算法轻松移植到手机端高效执行，开发出人工智能 APP，将 AI 带到你的指尖。ncnn 目前已在腾讯多款应用中使用，如 QQ，Qzone，微信，天天P图等。</p>
<p>功能概述</p>
<ul>
<li>支持卷积神经网络，支持多输入和多分支结构，可计算部分分支</li>
<li>无任何第三方库依赖，不依赖 BLAS&#x2F;NNPACK 等计算框架</li>
<li>纯 C++ 实现，跨平台，支持 android ios 等</li>
<li>ARM NEON 汇编级良心优化，计算速度极快</li>
<li>精细的内存管理和数据结构设计，内存占用极低</li>
<li>支持多核并行计算加速，ARM big.LITTLE cpu 调度优化</li>
<li>整体库体积小于 500K，并可轻松精简到小于 300K</li>
<li>可扩展的模型设计，支持 8bit 量化和半精度浮点存储，可导入 caffe 模型</li>
<li>支持直接内存零拷贝引用加载网络模型</li>
<li>可注册自定义层实现并扩展</li>
<li>恩，很强就是了，不怕被塞卷 QvQ</li>
</ul>
<p>nihui，喜爱C&#x2F;C++，腾讯优图实验室基础研究组高级研究员，负责图像和人脸相关的技术研究和软件开发，非常热爱开源社区，系腾讯社交网络事业群首个AI开源项目ncnn负责人。</p>
<p>features:</p>
<ul>
<li>跑vgg、googlenet、resnet等模型速度比其他已知的开源框架快2~4倍</li>
<li>C++较接近底层，能控制几乎所有资源，运行代价小。目前主要是面向android和ios的，实际上只要有C++编译器就可以。无任何第三方库依赖，不依赖 BLAS&#x2F;NNPACK等计算框架</li>
<li>ncnn代码全部使用C&#x2F;C++实现，跨平台的cmake编译系统，可在已知的绝大多数平台编译运行，如Linux，Windows，MacOS，Android，iOS等。由于ncnn不依赖第三方库，且采用C++03标准实现，只用到了std::vector和std::string两个STL模板，可轻松移植到其他系统和设备上。</li>
<li>为什么在计算硬件上选择CPU而不是GPU？CPU的兼容性很好，但是各种各样的GPU功能支持都不一样，不容易实现，比如ios的metal和android的opencl。不否认GPU会更快，但GPU优化很复杂，想写一个通用的GPU路径很难，目前实现起来也有一定的难度。</li>
<li>ncnn支撑着一些优图提供的算法，例如人脸相关的应用:人像自动美颜，照片风格化，超分辨率，物体识别等等，对于小型的网络模型可以跑到实时。</li>
<li>云端vs终端？AR，VR都需要实时性，云端即使再快也无法实时，所以终端部署是很有必要的。云端适合处理大数据，比如推荐系统，安全系统，终端适合实时化的应用场景，比如智能机器人，无人驾驶。</li>
</ul>
<p>tools:</p>
<ul>
<li>caffe2ncnn: caffe模型(prototxt,caffemodel)转换为ncnn的xxx.param,xxx.bin文件</li>
<li>ncnn2mem: 对模型xxx.param进行加密生成二进制文件xxx.param.bin</li>
</ul>
<p>NCNN暂时只支持opencv2。</p>
<h3 id="FeatherCNN"><a href="#FeatherCNN" class="headerlink" title="FeatherCNN"></a>FeatherCNN</h3><p>腾讯出品。</p>
<p>see <a target="_blank" rel="noopener" href="https://github.com/Tencent/FeatherCNN">here</a></p>
<h3 id="mace"><a href="#mace" class="headerlink" title="mace"></a>mace</h3><p>小米出品。</p>
<p>features</p>
<ul>
<li>速度：对于放在移动端进行计算的模型，一般对整体的预测延迟有着非常高的要求。在框架底层，针对ARM CPU进行了NEON指令级优化，针对移动端GPU，实现了高效的OpenCL内核代码。针对高通DSP，集成了nnlib计算库进行HVX加速。同时在算法层面，采用Winograd算法对卷积进行加速。</li>
<li>功耗：移动端对功耗非常敏感，框架针对ARM处理器的big.LITTLE架构，提供了高性能，低功耗等多种组合配置。针对Adreno GPU，提供了不同的功耗性能选项，使得开发者能够对性能和功耗进行灵活的调整。</li>
<li>系统响应：对于GPU计算模式，框架底层对OpenCL内核自适应的进行分拆调度，保证GPU渲染任务能够更好的进行抢占调度，从而保证系统的流畅度。</li>
<li>初始化延迟：在实际项目中，初始化时间对用户体验至关重要，框架对此进行了针对性的优化。</li>
<li>内存占用：通过对模型的算子进行依赖分析，引入内存复用技术，大大减少了内存的占用。</li>
<li>模型保护：对于移动端模型，知识产权的保护往往非常重要，MACE支持将模型转换成C++代码，大大提高了逆向工程的难度。<br>此外，MACE 支持 TensorFlow 和 Caffe 模型，提供转换工具，可以将训练好的模型转换成专有的模型数据文件，同时还可以选择将模型转换成C++代码，支持生成动态库或者静态库，提高模型保密性。</li>
</ul>
<h3 id="TensorRT"><a href="#TensorRT" class="headerlink" title="TensorRT"></a>TensorRT</h3><p>NVIDIA TensorRT是一种用于产品开发的高性能的深度学习推理引擎，应用有图像分类，分割和目标检测，提供的帧&#x2F;秒速度比只有CPU的推理引擎高14倍。</p>
<p>主要特点：</p>
<p>1）生成优化了的、实现好了的、可以用于预测的模型；</p>
<p>2）优化和部署广泛的神经网络层，如卷积，全连接，LRN，汇集，激活，softmax，Concat和反卷积层</p>
<p>3）支持caffe prototxt网络描述文件;</p>
<p>4）实现神经网络在全精度上（FP32）或减少（INT8、FP16精度）；</p>
<p>5）使用自定义层API来定义和实现独特的功能；</p>
<p>DIGITS 5和TensorRT可供NVIDIA开发者计划成员免费下载。</p>
<p>在线的部署最大的特点是对实时性要求很高，它对latency非常敏感，要我们能非常快的给出推断（Inference）的结果。部署端不只是成本的问题，如果方法不得当，即使使用目前最先进的GPU，也无法满足推断（Inference）的实时性要求。因为模型如果做得不好，没有做优化，可能需要二三百毫秒才能做完一次推断（Inference），再加上来回的网络传输，用户可能一秒后才能得到结果。在语音识别的场景之下，用户可以等待；但是在驾驶的场景之下，可能会有性命之庾。</p>
<p>在部署阶段，latency是非常重要的点，而TensorRT是专门针对部署端进行优化的，目前TensorRT支持大部分主流的深度学习应用，当然最擅长的是CNN（卷积神经网络）领域，但是的TensorRT 3.0也是有RNN的API。</p>
<p>总结一下推断（Inference）和训练（Training）的不同：</p>
<ul>
<li><p>推断（Inference）的网络权值已经固定下来，无后向传播过程，因此可以模型固定，可以对计算图进行优化； 输入输出大小固定，可以做memory优化（注意：有一个概念是fine-tuning，即训练好的模型继续调优，只是在已有的模型做小的改动，本质上仍然是训练（Training）的过程，TensorRT没有fine-tuning）</p>
</li>
<li><p>推断（Inference）的batch size要小很多，仍然是latency的问题，因为训练(training)如果batch size很大，吞吐可以达到很大，比如每秒可以处理1024个batch，500毫秒处理完，吞吐可以达到2048，可以很好地利用GPU；但是推断（Inference）不能做500毫秒处理，可以是8或者16，吞吐降低，没有办法很好地利用GPU.</p>
</li>
<li><p>推断（Inference）可以使用低精度的技术，训练的时候因为要保证前后向传播，每次梯度的更新是很微小的，这个时候需要相对较高的精度，一般来说需要float型，如FP32，32位的浮点型来处理数据，但是在推断（Inference）的时候，对精度的要求没有那么高，很多研究表明可以用低精度，如半长（16）的float型，即FP16，也可以用8位的整型（INT8）来做推断（Inference），研究结果表明没有特别大的精度损失，尤其对CNN。更有甚者，对Binary（二进制）的使用也处在研究过程中，即权值只有0和1。目前FP16和INT8的研究使用相对来说比较成熟。低精度计算的好处是一方面可以减少计算量，原来计算32位的单元处理FP16的时候，理论上可以达到两倍的速度，处理INT8的时候理论上可以达到四倍的速度。当然会引入一些其他额外的操作，后面的讲解中会详细介绍FP18和INT8；另一方面是模型需要的空间减少，不管是权值的存储还是中间值的存储，应用更低的精度，模型大小会相应减小。</p>
</li>
</ul>
<p>暂时抛开TensorRT，如果让大家从头写一个深度学习模型的前向过程，具体过程应该是</p>
<ol>
<li><p>首先实现NN的layer，如卷积的实现，pooling的实现。</p>
</li>
<li><p>管理memory，数据在各层之间如何流动。</p>
</li>
<li><p>推断（Inference）的engine来调用各层的实现。</p>
</li>
</ol>
<p>TensorRT高级特征介绍:</p>
<ul>
<li>插件支持: 在某些层TensorRT不支持的情况下，需要通过Plugin的形式自己去实现。</li>
<li>低精度支持: 低精度指的是之前所说过的FP16和INT8，其中FP16主要是Pascal P100和V100（tensor core）这两张卡支持；而INT8主要针对的是 P4和P40这两张卡，P4是专门针对线上做推断（Inference）的小卡，和IPhone手机差不多大，75瓦的一张卡，功耗和性能非常好。</li>
<li>Python接口和更多的框架支持: TensorRT目前支持Python和C++的API。Model importer（即Parser）主要支持Caffe和Uff，其他的框架可以通过API来添加。TensorRT去做推断（Inference）的时候是不再需要框架的（caffe,tensorflow）</li>
</ul>
<p>低精度的推断（Inference）</p>
<ul>
<li><p>FP16 推断（Inference: TensorRT支持高度自动化的FP16推断（Inference），解析模型要将模型的的数据类型设置为DataType::kHALF，同时通过builder- &gt;setHalf2Mode(true)指令将推断（Inference）设置为FP16的模式。需要注意两点，一点是FP16推断（Inference）不需要额外的输入，只需要输入预先训练好的FP32模型，另一点是目前只有Tesla P100&#x2F;V100支持原生的FP16。</p>
</li>
<li><p>INT8 推断（Inference: 主要关注INT8推断（Inference）的几个方面，即：如何生成校准表，如何使用校准表，和INT8推断（Inference）实例。</p>
</li>
</ul>
<p> 最后总结一下TensorRT的优点：</p>
<ul>
<li>TensorRT是一个高性能的深度学习推断（Inference）的优化器和运行的引擎；</li>
<li>TensorRT支持Plugin，对于不支持的层，用户可以通过Plugin来支持自定义创建；</li>
<li>TensorRT使用低精度的技术获得相对于FP32二到三倍的加速，用户只需要通过相应的代码来实现。</li>
</ul>
<h3 id="Anakin"><a href="#Anakin" class="headerlink" title="Anakin"></a>Anakin</h3><p>百度PaddlePaddle Anakin。<br>see <a target="_blank" rel="noopener" href="https://github.com/PaddlePaddle/Anakin">here</a></p>
<p>Anakin supports a wide range of neural network architectures and different hardware platforms. It is easy to run Anakin on GPU &#x2F; x86 &#x2F; ARM platform.</p>
<h3 id="TVM"><a href="#TVM" class="headerlink" title="TVM"></a>TVM</h3><p>see <a target="_blank" rel="noopener" href="https://github.com/dmlc/tvm">here</a></p>
<p>TVM是一个全新的框架，可以：</p>
<ul>
<li>为CPU、GPU和其他专用硬件，表示和优化常见的深度学习计算工作负载</li>
<li>自动转换计算图以最小化内存占用，优化数据布局和融合计算模式</li>
<li>提供端到端编译，从现有的前端框架到裸机硬件，直到浏览器可执行的javascript</li>
</ul>
<p>在TVM的帮助下，可以轻松在手机、嵌入式设备甚至浏览器上运行深度学习的工作负载，而不需要额外的工作。TVM还为许多硬件平台上的深度学习工作负载，提供统一的优化框架，包括依赖于新计算基元的专用加速器。</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="http://news.yesky.com/hotnews/305/275888305.shtml">腾讯优图　ncnn</a></li>
<li><a target="_blank" rel="noopener" href="https://blog.csdn.net/sanallen/article/details/79022669">ncnn compile for arm</a></li>
<li><a target="_blank" rel="noopener" href="https://baijiahao.baidu.com/s?id=1604506265110753139&wfr=spider&for=pc">小米　mace</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/Tencent/ncnn">ncnn git</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/XiaoMi/mace">mace igt</a></li>
</ul>
<p>TenorRT</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html">tensorrt-developer-guide</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://github.com/dusty-nv/jetson-inference">TensorRT inferene for classification</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.jianshu.com/p/59fe26073a41">NVIDIA TensorRT使用记录</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/35657027">高性能深度学习支持引擎实战——TensorRT</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/28597477">tvm</a></p>
</li>
</ul>
<h2 id="History"><a href="#History" class="headerlink" title="History"></a>History</h2><ul>
<li>20180817: created.</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://kezunlin.me/blog/py-faster-rcnn-tutorials/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="kezunlin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kezunlin's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/py-faster-rcnn-tutorials/" class="post-title-link" itemprop="url">a quick guide to py-faster-rcnn</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-08-16 10:42:00" itemprop="dateCreated datePublished" datetime="2018-08-16T10:42:00+08:00">2018-08-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-10-14 13:39:28" itemprop="dateModified" datetime="2024-10-14T13:39:28+08:00">2024-10-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Guide"><a href="#Guide" class="headerlink" title="Guide"></a>Guide</h2><h3 id="Quick-guide-with-Demo"><a href="#Quick-guide-with-Demo" class="headerlink" title="Quick guide with Demo"></a>Quick guide with Demo</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># install packages</span></span><br><span class="line"></span><br><span class="line">pip install cython  </span><br><span class="line">pip install easydict  </span><br><span class="line">apt-get install python-opencv  </span><br><span class="line"></span><br><span class="line"><span class="comment"># Make sure to clone with --recursive</span></span><br><span class="line">git <span class="built_in">clone</span> --recursive https://github.com/rbgirshick/py-faster-rcnn.git</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build the Cython modules</span></span><br><span class="line">py-faster-rcnn/lib</span><br><span class="line">make</span><br><span class="line"></span><br><span class="line"><span class="comment"># Build Caffe and pycaffe</span></span><br><span class="line"><span class="built_in">cd</span> py-faster-rcnn/caffe-fast-rcnn</span><br><span class="line"><span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build &amp;&amp; cmake-gui ..</span><br><span class="line">make -j8</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#Download pre-computed Faster R-CNN detectors</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> py-faster-rcnn</span><br><span class="line">./data/scripts/fetch_faster_rcnn_models.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># This will populate the `FRCN_ROOT/data` folder with faster_rcnn_models. See `data/README.md` for details. These models were trained on VOC 2007 trainval.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Demo </span></span><br><span class="line">./tools/demo.py　--gpu 0 --net zf </span><br><span class="line">./tools/demo.py　--gpu 0 --net vgg16</span><br></pre></td></tr></table></figure>


<h4 id="fix-gflags-error"><a href="#fix-gflags-error" class="headerlink" title="fix gflags error"></a>fix gflags error</h4><ul>
<li>caffe-fast-rcnn&#x2F;include&#x2F;caffe&#x2F;common.hpp</li>
<li>caffe-fast-rcnn&#x2F;examples&#x2F;mnist&#x2F;convert_mnist_data.cpp</li>
</ul>
<p>Comment out the ifndef</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// #ifndef GFLAGS_GFLAGS_H_</span></span><br><span class="line"><span class="keyword">namespace</span> gflags = google;</span><br><span class="line"><span class="comment">// #endif  // GFLAGS_GFLAGS_H_</span></span><br></pre></td></tr></table></figure>

<h3 id="Train-net-with-your-own-data"><a href="#Train-net-with-your-own-data" class="headerlink" title="Train net with your own data"></a>Train net with your own data</h3><p>faster rcnn训练方式有两种</p>
<ul>
<li>一种是交替优化方法（alternating optimization），即训练两个网络，一个是rpn，一个是fast rcnn，总计两个stage，每个stage各训练一次rpn和fast rcnn。</li>
<li>另外一种训练方式为近似联合训练（approximate joint training），也称end to end的训练方式，训练过程中只训练一个权重网络，训练速度有可观的提升，而训练精度不变。</li>
</ul>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># prepare data</span></span><br><span class="line">wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar</span><br><span class="line">wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar</span><br><span class="line">wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCdevkit_08-Jun-2007.tar</span><br><span class="line"></span><br><span class="line">tar xvf VOCtrainval_06-Nov-2007.tar</span><br><span class="line">tar xvf VOCtest_06-Nov-2007.tar</span><br><span class="line">tar xvf VOCdevkit_08-Jun-2007.tar</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">VOCdevkit/                           <span class="comment"># development kit</span></span><br><span class="line">VOCdevkit/VOCcode/                   <span class="comment"># VOC utility code</span></span><br><span class="line">VOCdevkit/VOC2007                    <span class="comment"># image sets, annotations, etc.</span></span><br><span class="line"><span class="comment"># ... and several other directories ...</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">cd</span> py-faster-rcnn/data</span><br><span class="line"><span class="built_in">ln</span> -s VOCdevkit VOCdevkit2007</span><br><span class="line"><span class="comment"># Using symlinks is a good idea because you will likely want to share the same PASCAL dataset installation between multiple projects.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># download pre-trained imagenet models</span></span><br><span class="line">./data/scripts/fetch_imagenet_models.sh</span><br><span class="line"></span><br><span class="line"><span class="comment"># train net</span></span><br><span class="line">./experiments/scripts/faster_rcnn_end2end.sh 0 ZF pascal_voc</span><br></pre></td></tr></table></figure>


<h4 id="error-fixs"><a href="#error-fixs" class="headerlink" title="error fixs"></a>error fixs</h4><p>error </p>
<pre><code>AttributeError: &#39;module&#39; object has no attribute &#39;text_format&#39;
</code></pre>
<p>fix </p>
<p>.&#x2F;lib&#x2F;fast_rcnn&#x2F;train.py增加一行</p>
<pre><code>import google.protobuf.text_format
</code></pre>
<h4 id="training-results"><a href="#training-results" class="headerlink" title="training results"></a>training results</h4><pre><code>AP for aeroplane = 0.6312
AP for bicycle = 0.7069
AP for bird = 0.5836
AP for boat = 0.4471
AP for bottle = 0.3562
AP for bus = 0.6682
AP for car = 0.7569
AP for cat = 0.7249
AP for chair = 0.3844
AP for cow = 0.6152
AP for diningtable = 0.6162
AP for dog = 0.6502
AP for horse = 0.7580
AP for motorbike = 0.7128
AP for person = 0.6744
AP for pottedplant = 0.3358
AP for sheep = 0.5872
AP for sofa = 0.5649
AP for train = 0.7128
AP for tvmonitor = 0.6133
Mean AP = 0.6050

Results:
0.631
0.707
0.584
0.447
0.356
0.668
0.757
0.725
0.384
0.615
0.616
0.650
0.758
0.713
0.674
0.336
0.587
0.565
0.713
0.613
0.605

--------------------------------------------------------------
Results computed with the **unofficial** Python eval code.
Results should be very close to the official MATLAB eval code.
Recompute with `./tools/reval.py --matlab ...` for your paper.
-- Thanks, The Management
--------------------------------------------------------------

real	5m16.906s
user	4m6.179s
sys	1m16.157s
</code></pre>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><p><a target="_blank" rel="noopener" href="https://github.com/rbgirshick/py-faster-rcnn">py-faster-rcnn</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://huangying-zhan.github.io/2016/09/22/detection-faster-rcnn.html">faster rcnn and train net</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/hansjorn/p/7724852.html">py faster rcnn and train your own data</a></p>
</li>
<li><p><strong><a target="_blank" rel="noopener" href="https://www.slideshare.net/hpkim0512/tutorial-of-faster-rcnn">ppt for faster rcnn</a></strong></p>
</li>
<li><p><strong><a target="_blank" rel="noopener" href="https://tryolabs.com/blog/2018/01/18/faster-r-cnn-down-the-rabbit-hole-of-modern-object-detection/">faster-r-cnn-down-the-rabbit-hole-of-modern-object-detection</a></strong></p>
</li>
<li><p><strong><a target="_blank" rel="noopener" href="http://kaiminghe.com/iccv17tutorial/maskrcnn_iccv2017_tutorial_kaiminghe.pdf">kaiminghe mask rcnn tutorial</a></strong></p>
</li>
<li><p><strong><a target="_blank" rel="noopener" href="https://www.slideshare.net/windmdk/mask-rcnn">kaiminghe mask rcnn oral</a></strong></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.slideshare.net/JinwonLee9/pr12-faster-rcnn170528">ppt2 for faster rcnn</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/skyfsm/p/6806246.html">rcnn, fast rcnn, faster rcnn</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_17448289/article/details/52871461">faster rcnn notes</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://docs.microsoft.com/en-us/cognitive-toolkit/object-detection-using-faster-r-cnn">object-detection-using-faster-r-cnn</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://huangying-zhan.github.io/2016/09/22/detection-faster-rcnn.html">detection-faster-rcnn</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://www.pyimagesearch.com/2018/05/14/a-gentle-guide-to-deep-learning-object-detection/">a-gentle-guide-to-deep-learning-object-detection</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://cv-tricks.com/object-detection/faster-r-cnn-yolo-ssd/">faster rcnn yolo ssd</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://research.fb.com/wp-content/uploads/2017/08/maskrcnn.pdf">paper mask rcnn</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/jiongnima/article/details/79094159">csdn mask rcnn</a></p>
</li>
<li><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/JNingWei/article/details/78822159">roialign</a></p>
</li>
<li><p><strong><a target="_blank" rel="noopener" href="http://blog.leanote.com/post/afanti.deng@gmail.com/b5f4f526490b">roialign roipool</a></strong></p>
</li>
</ul>
<h2 id="History"><a href="#History" class="headerlink" title="History"></a>History</h2><ul>
<li>20180816: created.</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://kezunlin.me/blog/matplot-RGB-vs-opencv-BGR-vs-caffe-images/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="kezunlin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kezunlin's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/matplot-RGB-vs-opencv-BGR-vs-caffe-images/" class="post-title-link" itemprop="url">matplot RGB vs opencv BGR vs caffe images</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-08-16 10:27:00" itemprop="dateCreated datePublished" datetime="2018-08-16T10:27:00+08:00">2018-08-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-10-14 13:39:28" itemprop="dateModified" datetime="2024-10-14T13:39:28+08:00">2024-10-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Guide"><a href="#Guide" class="headerlink" title="Guide"></a>Guide</h2><h3 id="Matplot-skimage-PIL-Image"><a href="#Matplot-skimage-PIL-Image" class="headerlink" title="Matplot (skimage&#x2F; PIL Image)"></a>Matplot (skimage&#x2F; PIL Image)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Matplot: dims: (height,width,channels),order: RGB,range: [0,255] dtype: uint8</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.image <span class="keyword">as</span> img</span><br><span class="line">image = img.imread(<span class="string">&quot;images/cat.jpg&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> image.shape <span class="comment"># (360, 480, 3)</span></span><br><span class="line"><span class="built_in">print</span> image[:<span class="number">5</span>,:<span class="number">5</span>,<span class="number">0</span>]</span><br><span class="line"><span class="comment">#plt.axis(&quot;off&quot;)</span></span><br><span class="line">plt.imshow(image)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>(360, 480, 3)
[[26 27 25 28 30]
 [26 27 25 26 28]
 [26 26 26 26 27]
 [27 26 27 28 29]
 [29 27 26 26 29]]
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180816102819164-727852617.png" alt="png"></p>
<h3 id="PIL-Image"><a href="#PIL-Image" class="headerlink" title="PIL.Image"></a>PIL.Image</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># PIL Image.open: dims: hwc,order: RGB, ??( range: [0,255] dtype: uint8)??</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line">image = Image.<span class="built_in">open</span>(<span class="string">&quot;images/cat.jpg&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(image)</span><br><span class="line"><span class="comment"># &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=480x360 at 0x7F258E0B8410&gt;</span></span><br><span class="line">plt.imshow(image)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p><img src="https://kezunlin.me/images/posts/635233-20180816102819164-727852617.png" alt="png"></p>
<h3 id="skimage"><a href="#skimage" class="headerlink" title="skimage"></a>skimage</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> skimage</span><br><span class="line">image = skimage.io.imread(image_filepath) <span class="comment"># RGB  (608, 606, 3)</span></span><br></pre></td></tr></table></figure>


<h3 id="OpenCV"><a href="#OpenCV" class="headerlink" title="OpenCV"></a>OpenCV</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># OpenCV: dims: (height,width,channels),order: BGR,range: [0,255] dtype: uint8</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">image = cv2.imread(<span class="string">&quot;images/cat.jpg&quot;</span>)</span><br><span class="line"><span class="built_in">print</span> image.shape <span class="comment"># (360, 480, 3)</span></span><br><span class="line"><span class="built_in">print</span> image[:<span class="number">5</span>,:<span class="number">5</span>,<span class="number">0</span>]</span><br><span class="line"><span class="comment">#plt.axis(&quot;off&quot;)</span></span><br><span class="line">plt.imshow(image)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>(360, 480, 3)
[[49 50 47 48 50]
 [51 52 48 48 50]
 [51 51 49 48 49]
 [50 49 49 48 49]
 [52 50 49 48 49]]
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180816102822472-37116830.png" alt="png"></p>
<p>The colors of our image are clearly wrong! Why is this?</p>
<p>The answer lies as a caveat with OpenCV.OpenCV represents RGB images as multi-dimensional NumPy arrays…but in reverse order! This means that <strong>OpenCV images are actually represented in BGR order rather than RGB</strong>!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">image = cv2.imread(<span class="string">&quot;images/cat.jpg&quot;</span>)</span><br><span class="line"><span class="comment"># convert from BGR to RGB</span></span><br><span class="line">rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)</span><br><span class="line">plt.axis(<span class="string">&quot;off&quot;</span>)</span><br><span class="line">plt.imshow(rgb_image)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p><img src="https://kezunlin.me/images/posts/635233-20180816102827030-476523183.png" alt="png"></p>
<h3 id="Matplot-VS-OpenCV"><a href="#Matplot-VS-OpenCV" class="headerlink" title="Matplot VS. OpenCV"></a>Matplot VS. OpenCV</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib.image <span class="keyword">as</span> img</span><br><span class="line">image1 = img.imread(<span class="string">&quot;images/cat.jpg&quot;</span>) <span class="comment"># rgb</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">image = cv2.imread(<span class="string">&quot;images/cat.jpg&quot;</span>)</span><br><span class="line"><span class="comment"># convert from BGR to RGB</span></span><br><span class="line">image2 = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) <span class="comment"># rgb</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#image1 and image2 are same at all.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> image1.dtype</span><br><span class="line"><span class="built_in">print</span> image1[:<span class="number">5</span>,:<span class="number">5</span>,<span class="number">0</span>] </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> </span><br><span class="line"><span class="built_in">print</span> image2.dtype</span><br><span class="line"><span class="built_in">print</span> image2[:<span class="number">5</span>,:<span class="number">5</span>,<span class="number">0</span>] </span><br><span class="line"></span><br><span class="line">equal_count = np.<span class="built_in">sum</span>( np.equal(image1[:,:,:],image2[:,:,:]) )</span><br><span class="line"><span class="built_in">print</span> equal_count</span><br><span class="line"><span class="built_in">print</span> equal_count == <span class="number">360</span>*<span class="number">480</span>*<span class="number">3</span></span><br></pre></td></tr></table></figure>

<pre><code>uint8
[[26 27 25 28 30]
 [26 27 25 26 28]
 [26 26 26 26 27]
 [27 26 27 28 29]
 [29 27 26 26 29]]

uint8
[[26 27 25 28 30]
 [26 27 25 26 28]
 [26 26 26 26 27]
 [27 26 27 28 29]
 [29 27 26 26 29]]
518400
True
</code></pre>
<h3 id="caffe-io-load-image"><a href="#caffe-io-load-image" class="headerlink" title="caffe.io.load_image"></a>caffe.io.load_image</h3><p><code>caffe.io.load_image</code> loads data in a normalized form (0-1)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># caffe.io.load_image: dims: (height,width,channels),order: RGB,range: [0,1] dtype: float32</span></span><br><span class="line"><span class="comment"># matplot: caffe_image = matplot_image/255.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># configure plotting</span></span><br><span class="line"><span class="comment">#plt.rcParams[&#x27;figure.figsize&#x27;] = (10, 10)</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;image.interpolation&#x27;</span>] = <span class="string">&#x27;nearest&#x27;</span></span><br><span class="line"><span class="comment">#plt.rcParams[&#x27;image.cmap&#x27;] = &#x27;gray&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">caffe_root = <span class="string">&#x27;../&#x27;</span>  <span class="comment"># this file should be run from &#123;caffe_root&#125;/examples (otherwise change this line)</span></span><br><span class="line">sys.path.insert(<span class="number">0</span>, caffe_root + <span class="string">&#x27;python&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> caffe</span><br><span class="line"><span class="comment">#======================================================================</span></span><br><span class="line"><span class="comment"># load image</span></span><br><span class="line"><span class="comment">#======================================================================</span></span><br><span class="line">image = caffe.io.load_image(caffe_root + <span class="string">&#x27;examples/images/cat.jpg&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span> image.shape,image.dtype <span class="comment"># (360, 480, 3) float32</span></span><br><span class="line"><span class="built_in">print</span> image[:<span class="number">5</span>,:<span class="number">5</span>,<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(image) <span class="comment"># (360, 480, 3) RGB</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#======================================================================</span></span><br><span class="line"><span class="comment"># load color image with color=False</span></span><br><span class="line"><span class="comment">#======================================================================</span></span><br><span class="line">image2 = caffe.io.load_image(caffe_root + <span class="string">&#x27;examples/images/cat.jpg&#x27;</span>,color=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span> image2.shape  <span class="comment">#(360, 480, 1)</span></span><br><span class="line">gray_image2 = image2.squeeze()</span><br><span class="line"><span class="built_in">print</span> gray_image2.shape,gray_image2.dtype <span class="comment"># (360, 480) float32</span></span><br><span class="line"><span class="built_in">print</span> gray_image2[:<span class="number">5</span>,:<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(gray_image2) <span class="comment"># (360, 480) gray</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#======================================================================</span></span><br><span class="line"><span class="comment"># load color image with color=False</span></span><br><span class="line"><span class="comment">#======================================================================</span></span><br><span class="line">image3 = caffe.io.load_image(caffe_root + <span class="string">&#x27;examples/images/cat_gray.jpg&#x27;</span>,color=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span> image3.shape  <span class="comment">#(360, 480, 1)</span></span><br><span class="line">gray_image3 = image3.squeeze()</span><br><span class="line"><span class="built_in">print</span> gray_image3.shape,gray_image3.dtype <span class="comment"># (360, 480) float32</span></span><br><span class="line"><span class="built_in">print</span> gray_image3[:<span class="number">5</span>,:<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(gray_image3) <span class="comment"># (360, 480) gray</span></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>(360, 480, 3) float32
[[ 0.10196079  0.10588235  0.09803922  0.10980392  0.11764706]
 [ 0.10196079  0.10588235  0.09803922  0.10196079  0.10980392]
 [ 0.10196079  0.10196079  0.10196079  0.10196079  0.10588235]
 [ 0.10588235  0.10196079  0.10588235  0.10980392  0.11372549]
 [ 0.11372549  0.10588235  0.10196079  0.10196079  0.11372549]]
(360, 480, 1)
(360, 480) float32
[[ 0.19543412  0.19935569  0.18842432  0.19120707  0.1990502 ]
 [ 0.19599961  0.19992118  0.19151255  0.19234589  0.20018902]
 [ 0.19599961  0.19599961  0.19543412  0.19234589  0.19626746]
 [ 0.19935569  0.19543412  0.19626746  0.19120707  0.19512863]
 [ 0.20719883  0.19935569  0.19543412  0.19234589  0.19512863]]
(360, 480, 1)
(360, 480) float32
[[ 0.10196079  0.10588235  0.09803922  0.10980392  0.11372549]
 [ 0.10196079  0.10588235  0.09803922  0.10196079  0.10980392]
 [ 0.10196079  0.10588235  0.10196079  0.10196079  0.10588235]
 [ 0.10588235  0.10196079  0.10588235  0.10980392  0.11372549]
 [ 0.11764706  0.10196079  0.10196079  0.10588235  0.10980392]]
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180816102829804-2136984998.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180816102832577-885538468.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180816102837178-881579112.png" alt="png"></p>
<h3 id="caffe-io-Transformer"><a href="#caffe-io-Transformer" class="headerlink" title="caffe.io.Transformer"></a>caffe.io.Transformer</h3><p><code>caffe.io.Transformer</code> for Network input blob(m,c,h,w):</p>
<ul>
<li><strong>caffe Network default use BGR image format just as OpenCV format</strong>.</li>
<li>caffe mean files use BGR ordering, which is calculated from <strong>trainning images</strong> instead of test images. <code>mu = np.array([104, 117, 123] # BGR</code></li>
<li>pixel range in <strong>[0,255] with dtype float32.</strong></li>
<li>(m,c,h,w), BGR order,[0,255] range,float32</li>
</ul>
<h4 id="caffe-io-load-image-1"><a href="#caffe-io-load-image-1" class="headerlink" title="caffe.io.load_image"></a>caffe.io.load_image</h4><p><code>caffe.io.Transformer</code>: </p>
<ul>
<li>input image: caffe.io.load_image: (h,w,c),RGB,[0,1],float32 </li>
<li>transformed image: (c,h,w), BGR,[0,255] float32</li>
</ul>
<p><code>caffe.io.Transformer</code> steps: </p>
<p>Note that the mean subtraction is always carried out before scaling. </p>
<ul>
<li>transformer.set_transpose(‘data’, (2,0,1))  #(h,w,c)-&gt;(c,h,w)</li>
<li>transformer.set_channel_swap(‘data’, (2,1,0)) # RGB-&gt;BGR</li>
<li>transformer.set_raw_scale(‘data’, 255) # [0,1]-&gt;[0,255] float32</li>
<li>transformer.set_mean(‘data’, mu) #  subtract BGR</li>
</ul>
<p>keep in mind that <strong>the Transformer is only required when using a deploy.prototxt</strong>-like network definition, so without the Data Layer. When using a Data Layer, things get easier to understand.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">caffe_root = <span class="string">&#x27;../&#x27;</span>  <span class="comment"># this file should be run from &#123;caffe_root&#125;/examples (otherwise change this line)</span></span><br><span class="line">sys.path.insert(<span class="number">0</span>, caffe_root + <span class="string">&#x27;python&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> caffe</span><br><span class="line">image = caffe.io.load_image(caffe_root + <span class="string">&#x27;examples/images/cat.jpg&#x27;</span>)</span><br><span class="line"><span class="comment"># caffe.io.load_image: dims: (height,width,channels),order: RGB,range: [0,1] dtype: float32</span></span><br><span class="line"><span class="built_in">print</span> image.shape,image.dtype <span class="comment"># (360, 480, 3) float32</span></span><br><span class="line"><span class="built_in">print</span> image[:<span class="number">5</span>,:<span class="number">5</span>,<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#plt.imshow(image)</span></span><br><span class="line"><span class="comment">#plt.show()</span></span><br><span class="line"></span><br><span class="line">mu = np.load(caffe_root + <span class="string">&#x27;python/caffe/imagenet/ilsvrc_2012_mean.npy&#x27;</span>) </span><br><span class="line">mu = mu.mean(<span class="number">1</span>).mean(<span class="number">1</span>)  <span class="comment"># # BGR</span></span><br><span class="line"></span><br><span class="line">data_shape = (<span class="number">10</span>, <span class="number">3</span>, <span class="number">227</span>, <span class="number">227</span>)</span><br><span class="line">transformer = caffe.io.Transformer(&#123;<span class="string">&#x27;data&#x27;</span>: data_shape&#125;)</span><br><span class="line"></span><br><span class="line">transformer.set_transpose(<span class="string">&#x27;data&#x27;</span>, (<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>)) <span class="comment"># h,w,c-&gt;c,h,w(012-&gt;201) move image channels to outermost dimension</span></span><br><span class="line">transformer.set_channel_swap(<span class="string">&#x27;data&#x27;</span>, (<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>))  <span class="comment"># swap channels from RGB to BGR</span></span><br><span class="line">transformer.set_raw_scale(<span class="string">&#x27;data&#x27;</span>, <span class="number">255</span>)      <span class="comment"># rescale from [0, 1] to [0, 255]</span></span><br><span class="line">transformer.set_mean(<span class="string">&#x27;data&#x27;</span>, mu)            <span class="comment"># subtract the dataset-mean value(BGR) in each channel</span></span><br><span class="line"></span><br><span class="line">transformed_image = transformer.preprocess(<span class="string">&#x27;data&#x27;</span>, image) </span><br><span class="line"><span class="built_in">print</span> </span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;original  image: &#x27;</span>,image.shape,image.dtype             <span class="comment"># (360, 480, 3) float32</span></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;transform image: &#x27;</span>,transformed_image.shape,transformed_image.dtype <span class="comment">#(3, 227, 227) float32</span></span><br><span class="line"><span class="built_in">print</span> transformed_image[<span class="number">0</span>,:<span class="number">5</span>,:<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># By default, using CaffeNet, your net.blobs[&#x27;data&#x27;].data.shape == (10, 3, 227, 227). </span></span><br><span class="line"><span class="comment"># This is because 10 random 227x227 crops are supposed to be extracted from a 256x256 image </span></span><br><span class="line"><span class="comment"># and passed through the net.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># net.blobs[&#x27;data&#x27;].reshape(50,3,227,227) # we can change network input mini-batch to 50 as we like</span></span><br><span class="line"><span class="comment"># net.blobs[&#x27;data&#x27;].data[...] = transformed_image # ---&gt;(50,3,227,227) 50 images</span></span><br></pre></td></tr></table></figure>

<pre><code>(360, 480, 3) float32
[[ 0.10196079  0.10588235  0.09803922  0.10980392  0.11764706]
 [ 0.10196079  0.10588235  0.09803922  0.10196079  0.10980392]
 [ 0.10196079  0.10196079  0.10196079  0.10196079  0.10588235]
 [ 0.10588235  0.10196079  0.10588235  0.10980392  0.11372549]
 [ 0.11372549  0.10588235  0.10196079  0.10196079  0.11372549]]

original  image:  (360, 480, 3) float32
transform image:  (3, 227, 227) float32
[[-53.86381531 -56.23903656 -53.54626465 -53.14715195 -51.32625961]
 [-52.93947601 -55.71855164 -54.00423813 -54.76469803 -52.88771057]
 [-53.89373398 -55.67879486 -55.4278717  -55.22265625 -53.47174454]
 [-50.98455811 -51.3506012  -54.06866074 -52.09104156 -52.94168854]
 [-49.92769241 -49.85874176 -52.08575439 -52.50840759 -51.3900528 ]]
</code></pre>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- kzl in-article ad -->
<p><ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5653382914441020"
     data-ad-slot="7925631830"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>



<h4 id="cv2-imread"><a href="#cv2-imread" class="headerlink" title="cv2.imread"></a>cv2.imread</h4><p><code>caffe.io.Transformer</code>: </p>
<ul>
<li>input image: cv2.imread: (h,w,c),BGR,[0,255],float32 </li>
<li>transformed image: (c,h,w), BGR order,[0,255] float32</li>
</ul>
<p><code>caffe.io.Transformer</code> steps: </p>
<p>Note that the mean subtraction is always carried out before scaling. </p>
<ul>
<li>transformer.set_transpose(‘data’, (2,0,1))  #(h,w,c)-&gt;(c,h,w)</li>
<li>transformer.set_mean(‘data’, mu) #  subtract BGR</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"></span><br><span class="line">image = cv2.imread(<span class="string">&quot;test/cat.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line">data_shape = (<span class="number">10</span>, <span class="number">3</span>, <span class="number">227</span>, <span class="number">227</span>)</span><br><span class="line"></span><br><span class="line">transformer = caffe.io.Transformer(&#123;<span class="string">&#x27;data&#x27;</span>: data_shape&#125;)</span><br><span class="line">transformer.set_transpose(<span class="string">&#x27;data&#x27;</span>, (<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>)) </span><br><span class="line">transformer.set_mean(<span class="string">&#x27;data&#x27;</span>, mu)     </span><br><span class="line"></span><br><span class="line">transformed_image = transformer.preprocess(<span class="string">&#x27;data&#x27;</span>, image) </span><br><span class="line"><span class="built_in">print</span> </span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;original  image: &#x27;</span>,image.shape,image.dtype             <span class="comment"># (360, 480, 3) float32</span></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;transform image: &#x27;</span>,transformed_image.shape,transformed_image.dtype <span class="comment">#(3, 227, 227) float32</span></span><br><span class="line"><span class="built_in">print</span> transformed_image[<span class="number">0</span>,:<span class="number">5</span>,:<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># By default, using CaffeNet, your net.blobs[&#x27;data&#x27;].data.shape == (10, 3, 227, 227). </span></span><br><span class="line"><span class="comment"># This is because 10 random 227x227 crops are supposed to be extracted from a 256x256 image </span></span><br><span class="line"><span class="comment"># and passed through the net.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># net.blobs[&#x27;data&#x27;].reshape(50,3,227,227) # we can change network input mini-batch to 50 as we like</span></span><br><span class="line"><span class="comment"># net.blobs[&#x27;data&#x27;].data[...] = transformed_image # ---&gt;(50,3,227,227) 50 </span></span><br></pre></td></tr></table></figure>

<h4 id="deprocess-transformed-image"><a href="#deprocess-transformed-image" class="headerlink" title="deprocess transformed_image"></a>deprocess transformed_image</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Helper function for deprocessing preprocessed images, e.g., for display.</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">deprocess_net_image</span>(<span class="params">image</span>):</span><br><span class="line">    <span class="comment"># [(&#x27;B&#x27;, 104.0069879317889), (&#x27;G&#x27;, 116.66876761696767), (&#x27;R&#x27;, 122.6789143406786)]</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># input: (c,h,w), BGR,[lower,upper],float32</span></span><br><span class="line">    <span class="comment"># output: (h,w,c), RGB,[0,255],      uint8</span></span><br><span class="line">    image = image.copy()              <span class="comment"># don&#x27;t modify destructively</span></span><br><span class="line">    image = image[::-<span class="number">1</span>]               <span class="comment"># BGR -&gt; RGB</span></span><br><span class="line">    image = image.transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)  <span class="comment"># CHW -&gt; HWC</span></span><br><span class="line">    image += [<span class="number">123</span>, <span class="number">117</span>, <span class="number">104</span>]          <span class="comment"># (approximately) undo mean subtraction  RGB</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># clamp values in [0, 255]</span></span><br><span class="line">    image[image &lt; <span class="number">0</span>], image[image &gt; <span class="number">255</span>] = <span class="number">0</span>, <span class="number">255</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># round and cast from float32 to uint8</span></span><br><span class="line">    image = np.<span class="built_in">round</span>(image)</span><br><span class="line">    image = np.require(image, dtype=np.uint8)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line">image = deprocess_net_image(transformed_image)</span><br><span class="line"><span class="comment">#(h,w,c), RGB,[0,255],      uint8</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> image.shape,image.dtype <span class="comment"># (227, 227, 3) uint8</span></span><br><span class="line"><span class="built_in">print</span> image[:<span class="number">5</span>,:<span class="number">5</span>,<span class="number">0</span>]</span><br><span class="line">plt.imshow(image)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<pre><code>(227, 227, 3) uint8
[[27 27 29 29 30]
 [26 26 28 27 28]
 [27 27 27 26 28]
 [27 28 25 28 27]
 [26 29 28 28 28]]
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180816102840423-899986139.png" alt="png"></p>
<h4 id="set-3-dim-image-to-4-dim-input-blob-data"><a href="#set-3-dim-image-to-4-dim-input-blob-data" class="headerlink" title="set 3-dim image to 4-dim input blob data"></a>set 3-dim image to 4-dim input blob data</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">data = np.zeros((<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>))</span><br><span class="line"><span class="built_in">print</span> data</span><br><span class="line">image = np.arange(<span class="number">48</span>).reshape(<span class="number">3</span>,<span class="number">4</span>,<span class="number">4</span>) </span><br><span class="line"><span class="built_in">print</span> </span><br><span class="line"><span class="built_in">print</span> image</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;set image to data&#x27;</span></span><br><span class="line">data[...] = image <span class="comment"># auto broadcasting from 3-dims to 4-dims</span></span><br><span class="line"><span class="built_in">print</span> data</span><br></pre></td></tr></table></figure>

<pre><code>[[[[ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]]

  [[ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]]

  [[ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]]]


 [[[ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]]

  [[ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]]

  [[ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]
   [ 0.  0.  0.  0.]]]]

[[[ 0  1  2  3]
  [ 4  5  6  7]
  [ 8  9 10 11]
  [12 13 14 15]]

 [[16 17 18 19]
  [20 21 22 23]
  [24 25 26 27]
  [28 29 30 31]]

 [[32 33 34 35]
  [36 37 38 39]
  [40 41 42 43]
  [44 45 46 47]]]
set image to data
[[[[  0.   1.   2.   3.]
   [  4.   5.   6.   7.]
   [  8.   9.  10.  11.]
   [ 12.  13.  14.  15.]]

  [[ 16.  17.  18.  19.]
   [ 20.  21.  22.  23.]
   [ 24.  25.  26.  27.]
   [ 28.  29.  30.  31.]]

  [[ 32.  33.  34.  35.]
   [ 36.  37.  38.  39.]
   [ 40.  41.  42.  43.]
   [ 44.  45.  46.  47.]]]


 [[[  0.   1.   2.   3.]
   [  4.   5.   6.   7.]
   [  8.   9.  10.  11.]
   [ 12.  13.  14.  15.]]

  [[ 16.  17.  18.  19.]
   [ 20.  21.  22.  23.]
   [ 24.  25.  26.  27.]
   [ 28.  29.  30.  31.]]

  [[ 32.  33.  34.  35.]
   [ 36.  37.  38.  39.]
   [ 40.  41.  42.  43.]
   [ 44.  45.  46.  47.]]]]
</code></pre>
<h3 id="transformer-vs-python-code"><a href="#transformer-vs-python-code" class="headerlink" title="transformer vs. python code"></a>transformer vs. python code</h3><h4 id="caffe-io-load-image-2"><a href="#caffe-io-load-image-2" class="headerlink" title="caffe.io.load_image"></a>caffe.io.load_image</h4><h5 id="transformer"><a href="#transformer" class="headerlink" title="transformer"></a>transformer</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import sys</span><br><span class="line">import cv2</span><br><span class="line">import numpy as np</span><br><span class="line"># Make sure that caffe is on the python path:</span><br><span class="line">caffe_root = &#x27;./&#x27;</span><br><span class="line">os.chdir(caffe_root)</span><br><span class="line">sys.path.insert(0, os.path.join(caffe_root, &#x27;python&#x27;))</span><br><span class="line">import caffe</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># caffe.io.load_image: transformer  + python code</span><br><span class="line">data_shape = [1,3,512,512]</span><br><span class="line"></span><br><span class="line">transformer = caffe.io.Transformer(&#123;&#x27;data&#x27;:data_shape&#125;) # resize</span><br><span class="line">transformer.set_transpose(&#x27;data&#x27;, (2, 0, 1)) # hwc ===&gt; chw</span><br><span class="line">transformer.set_channel_swap(&#x27;data&#x27;, (2, 1, 0))  # rgb===&gt;bgr</span><br><span class="line">transformer.set_raw_scale(&#x27;data&#x27;, 255)  # [0-1]===&gt; [0,255]</span><br><span class="line">transformer.set_mean(&#x27;data&#x27;, np.array([104, 117, 123]))  # bgr mean pixel</span><br><span class="line"></span><br><span class="line">image_file = &quot;./images/1.png&quot;</span><br><span class="line">print(&quot;image_file=&quot;, image_file)</span><br><span class="line">image = caffe.io.load_image(image_file) # hwc, rgb, 0-1 </span><br><span class="line">print(&quot;image.shape=&quot;, image.shape)</span><br><span class="line"></span><br><span class="line">transformed_image = transformer.preprocess(&#x27;data&#x27;, image) #</span><br><span class="line">print(&quot;transformed_image.shape=&quot;, transformed_image.shape) # 3,512,512</span><br><span class="line">b,g,r = transformed_image </span><br><span class="line">print(b.shape) # 512,512</span><br><span class="line">print(g.shape)</span><br><span class="line">print(r.shape)</span><br><span class="line"></span><br><span class="line">print(&quot;&quot;)</span><br><span class="line">print(transformed_image[:,:5,:5])</span><br></pre></td></tr></table></figure>

<p>output </p>
<pre><code>(&#39;image_file=&#39;, &#39;./images/1.png&#39;)
(&#39;image.shape=&#39;, (1080, 1920, 3))
(&#39;transformed_image.shape=&#39;, (3, 512, 512))
(512, 512)
(512, 512)
(512, 512)

[[[ -98.          -98.          -98.          -98.          -98.        ]
  [ -98.          -98.          -98.          -98.          -98.        ]
  [ -23.96776581  -28.58105469  -31.359375    -25.08592987  -28.90721893]
  [  -8.21874237  -12.71092987  -15.46875     -15.27832031  -10.57226562]
  [  -7.75        -12.12499237  -15.          -15.          -10.984375  ]]

 [[-117.         -117.         -117.         -117.         -117.        ]
  [-117.         -117.         -117.         -117.         -117.        ]
  [ -43.96776581  -48.58105469  -51.359375    -45.08592987  -48.90721893]
  [ -26.21874237  -30.71092987  -33.46875     -33.27832031  -33.57226562]
  [ -24.75        -29.12499237  -32.          -32.          -31.984375  ]]

 [[-123.         -123.         -123.         -123.         -123.        ]
  [-123.         -123.         -123.         -123.         -123.        ]
  [ -52.96776581  -57.58105469  -60.359375    -54.08592987  -57.90721893]
  [ -40.21874237  -44.71092987  -47.46875     -47.27832031  -44.572258  ]
  [ -40.75        -45.12499237  -48.          -48.          -47.984375  ]]]
</code></pre>
<h5 id="python-code"><a href="#python-code" class="headerlink" title="python code"></a>python code</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">print(image.shape) # hwc,rgb,0-1   (1080, 1920, 3)</span><br><span class="line">print(image.dtype) # float32</span><br><span class="line"></span><br><span class="line"># resize</span><br><span class="line">image = cv2.resize(image, (512,512)) </span><br><span class="line">print(&quot;image resize = &quot;,image.shape) # (512, 512, 3)</span><br><span class="line"></span><br><span class="line"># hwc,rgb ===&gt; chw, bgr</span><br><span class="line">r,g,b = image[:,:,0],image[:,:,1],image[:,:,2]</span><br><span class="line"></span><br><span class="line">print(b.shape) # (512, 512)</span><br><span class="line">print(g.shape) # (512, 512)</span><br><span class="line">print(r.shape) # (512, 512)</span><br><span class="line"></span><br><span class="line">bgr = np.zeros([3,b.shape[0],b.shape[1]])</span><br><span class="line">print(bgr.shape)</span><br><span class="line">bgr[0,:,:] = b </span><br><span class="line">bgr[1,:,:] = g </span><br><span class="line">bgr[2,:,:] = r </span><br><span class="line"></span><br><span class="line"># 0-1 ===&gt;0-255</span><br><span class="line">bgr = bgr *255.</span><br><span class="line"></span><br><span class="line"># -mean</span><br><span class="line">print(&quot;&quot;)</span><br><span class="line">bgr[0] -= 104</span><br><span class="line">bgr[1] -= 117</span><br><span class="line">bgr[2] -= 123</span><br><span class="line">print(bgr[:,:5,:5])</span><br></pre></td></tr></table></figure>

<p>output </p>
<pre><code>(1080, 1920, 3)
float32
(&#39;image resize = &#39;, (512, 512, 3))
float32
(512, 512)
(512, 512)
(512, 512)
(3, 512, 512)

[[[ -97.99999988  -97.99999988  -97.99999988  -97.99999988  -97.99999988]
  [ -97.99999988  -97.99999988  -97.99999988  -97.99999988  -97.99999988]
  [ -23.9677673   -28.58105415  -31.35937387  -25.0859333   -28.90722105]
  [  -8.21874478  -12.71093214  -15.46874815  -15.27831757  -10.5722701 ]
  [  -7.74999434  -12.12499598  -14.99999771  -14.99999771  -10.98437318]]

 [[-117.         -117.         -117.         -117.         -117.        ]
  [-117.         -117.         -117.         -117.         -117.        ]
  [ -43.96776688  -48.58105373  -51.35937345  -45.08593288  -48.90722823]
  [ -26.21874449  -30.71093184  -33.46874785  -33.27831727  -33.5722695 ]
  [ -24.7499941   -29.12499574  -31.99999747  -31.99999747  -31.98437271]]

 [[-123.         -123.         -123.         -123.         -123.        ]
  [-123.         -123.         -123.         -123.         -123.        ]
  [ -52.9677667   -57.58105356  -60.35937327  -54.0859327   -57.90722805]
  [ -40.21874401  -44.71093136  -47.46874738  -47.2783168   -44.5722692 ]
  [ -40.7499935   -45.12499514  -47.99999687  -47.99999687  -47.98437211]]]
</code></pre>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- kzl in-article ad -->
<p><ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5653382914441020"
     data-ad-slot="7925631830"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>




<h4 id="cv2-imread-1"><a href="#cv2-imread-1" class="headerlink" title="cv2.imread"></a>cv2.imread</h4><h5 id="transformer-1"><a href="#transformer-1" class="headerlink" title="transformer"></a>transformer</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># cv2.imread: transformer  + python code</span></span><br><span class="line">data_shape = [<span class="number">1</span>,<span class="number">3</span>,<span class="number">512</span>,<span class="number">512</span>]</span><br><span class="line"></span><br><span class="line">transformer = caffe.io.Transformer(&#123;<span class="string">&#x27;data&#x27;</span>:data_shape&#125;) <span class="comment"># resize</span></span><br><span class="line">transformer.set_transpose(<span class="string">&#x27;data&#x27;</span>, (<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>)) <span class="comment"># hwc ===&gt; chw</span></span><br><span class="line"><span class="comment">#transformer.set_channel_swap(&#x27;data&#x27;, (2, 1, 0))  # rgb===&gt;bgr</span></span><br><span class="line"><span class="comment">#transformer.set_raw_scale(&#x27;data&#x27;, 255)  # [0-1]===&gt; [0,255]</span></span><br><span class="line">transformer.set_mean(<span class="string">&#x27;data&#x27;</span>, np.array([<span class="number">104</span>, <span class="number">117</span>, <span class="number">123</span>]))  <span class="comment"># bgr mean pixel</span></span><br><span class="line"></span><br><span class="line">image_file = <span class="string">&quot;./images/1.png&quot;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;image_file=&quot;</span>, image_file)</span><br><span class="line">image = cv2.imread(image_file) <span class="comment"># hwc, bgr, 0-255</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;image.shape=&quot;</span>, image.shape)</span><br><span class="line"></span><br><span class="line">transformed_image = transformer.preprocess(<span class="string">&#x27;data&#x27;</span>, image) <span class="comment">#</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;transformed_image.shape=&quot;</span>, transformed_image.shape) <span class="comment"># 3,512,512</span></span><br><span class="line">b,g,r = transformed_image </span><br><span class="line"><span class="built_in">print</span>(b.shape) <span class="comment"># 512,512</span></span><br><span class="line"><span class="built_in">print</span>(g.shape)</span><br><span class="line"><span class="built_in">print</span>(r.shape)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(transformed_image[:,:<span class="number">5</span>,:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<p>output </p>
<pre><code>(&#39;image_file=&#39;, &#39;./images/1.png&#39;)
(&#39;image.shape=&#39;, (1080, 1920, 3))
(&#39;transformed_image.shape=&#39;, (3, 512, 512))
(512, 512)
(512, 512)
(512, 512)

[[[ -98.          -98.          -98.          -98.          -98.        ]
  [ -98.          -98.          -98.          -98.          -98.        ]
  [ -23.96777344  -28.58105469  -31.359375    -25.0859375   -28.90722656]
  [  -8.21875     -12.7109375   -15.46875     -15.27832031  -10.57226562]
  [  -7.75        -12.125       -15.          -15.          -10.984375  ]]

 [[-117.         -117.         -117.         -117.         -117.        ]
  [-117.         -117.         -117.         -117.         -117.        ]
  [ -43.96777344  -48.58105469  -51.359375    -45.0859375   -48.90722656]
  [ -26.21875     -30.7109375   -33.46875     -33.27832031  -33.57226562]
  [ -24.75        -29.125       -32.          -32.          -31.984375  ]]

 [[-123.         -123.         -123.         -123.         -123.        ]
  [-123.         -123.         -123.         -123.         -123.        ]
  [ -52.96777344  -57.58105469  -60.35937119  -54.0859375   -57.90722656]
  [ -40.21875     -44.7109375   -47.46875     -47.27832031  -44.57226562]
  [ -40.75        -45.125       -48.          -48.          -47.984375  ]]]
</code></pre>
<h5 id="python-code-1"><a href="#python-code-1" class="headerlink" title="python code"></a>python code</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">print(image.shape) # hwc,bgr,0-255   (1080, 1920, 3)</span><br><span class="line">print(image.dtype) # uint8</span><br><span class="line"></span><br><span class="line"># int8 ===&gt;float32</span><br><span class="line">image = image.astype(&#x27;float32&#x27;) # key steps</span><br><span class="line">print(image.dtype) # float32</span><br><span class="line"></span><br><span class="line"># resize</span><br><span class="line">image = cv2.resize(image, (512,512)) </span><br><span class="line">print(&quot;image resize = &quot;,image.shape) # (512, 512, 3)</span><br><span class="line">print(image.dtype) # float32</span><br><span class="line"></span><br><span class="line"># hwc ===&gt; chw</span><br><span class="line">b,g,r = image[:,:,0],image[:,:,1],image[:,:,2]</span><br><span class="line"></span><br><span class="line">print(b.shape) # (512, 512)</span><br><span class="line">print(g.shape) # (512, 512)</span><br><span class="line">print(r.shape) # (512, 512)</span><br><span class="line"></span><br><span class="line">bgr = np.zeros([3,b.shape[0],b.shape[1]])</span><br><span class="line">print(bgr.shape)</span><br><span class="line"></span><br><span class="line"># -mean</span><br><span class="line">b -= 104</span><br><span class="line">g -= 117</span><br><span class="line">r -= 123</span><br><span class="line"></span><br><span class="line">bgr[0,:,:] = b </span><br><span class="line">bgr[1,:,:] = g </span><br><span class="line">bgr[2,:,:] = r </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(bgr[:,:5,:5])</span><br></pre></td></tr></table></figure>

<h5 id="python-code-v2"><a href="#python-code-v2" class="headerlink" title="python code v2"></a>python code v2</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">image = cv2.imread(filepath) # hwc, bgr,0-255</span><br><span class="line">print(image.dtype) # uint8</span><br><span class="line">        </span><br><span class="line">image = image.astype(&#x27;float32&#x27;) # key steps</span><br><span class="line">image = cv2.resize(image, (512,512)) </span><br><span class="line">print(&quot;image resize = &quot;,image.shape) # (512, 512, 3)</span><br><span class="line">print(image.dtype) # float32</span><br><span class="line"></span><br><span class="line">image -= np.array((104.00698793,116.66876762,122.67891434)) # bgr mean</span><br><span class="line">image = image.transpose((2,0,1)) # hwc ===&gt;chw</span><br><span class="line"></span><br><span class="line">print(image[:,:5,:5])</span><br></pre></td></tr></table></figure>

<p>output </p>
<pre><code>(1080, 1920, 3)
uint8
float32
(&#39;image resize = &#39;, (512, 512, 3))
float32
(512, 512)
(512, 512)
(512, 512)
(3, 512, 512)

[[[ -98.          -98.          -98.          -98.          -98.        ]
  [ -98.          -98.          -98.          -98.          -98.        ]
  [ -23.96777344  -28.58105469  -31.359375    -25.0859375   -28.90722656]
  [  -8.21875     -12.7109375   -15.46875     -15.27832031  -10.57226562]
  [  -7.75        -12.125       -15.          -15.          -10.984375  ]]

 [[-117.         -117.         -117.         -117.         -117.        ]
  [-117.         -117.         -117.         -117.         -117.        ]
  [ -43.96777344  -48.58105469  -51.359375    -45.0859375   -48.90722656]
  [ -26.21875     -30.7109375   -33.46875     -33.27832031  -33.57226562]
  [ -24.75        -29.125       -32.          -32.          -31.984375  ]]

 [[-123.         -123.         -123.         -123.         -123.        ]
  [-123.         -123.         -123.         -123.         -123.        ]
  [ -52.96777344  -57.58105469  -60.359375    -54.0859375   -57.90722656]
  [ -40.21875     -44.7109375   -47.46875     -47.27832031  -44.57226562]
  [ -40.75        -45.125       -48.          -48.          -47.984375  ]]]
</code></pre>
<h3 id="Conclusions"><a href="#Conclusions" class="headerlink" title="Conclusions"></a>Conclusions</h3><ul>
<li><strong>Matplot.imread</strong>:        dims: (height,width,channels),order: RGB,range: [0,255] dtype: uint8, plot</li>
<li><strong>OpenCV.imread</strong>:         dims: (height,width,channels),order: <strong>BGR</strong>,range: [0,255] dtype: uint8, plot</li>
<li><strong>caffe.io.load_image</strong>:   dims: (height,width,channels),order: RGB,range: <strong>[0,1]</strong>   dtype: float32 (caffe_io_image &#x3D; matplot_image&#x2F;255.0) ,plot</li>
<li><strong>caffe Network Input(Transformer)</strong>:   dims: (m,c,h,w), order: <strong>BGR</strong>, range [0,255],dtype: float32, <strong>PLOT ERROR</strong></li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="https://www.pyimagesearch.com/2014/11/03/display-matplotlib-rgb-image/">display-matplotlib-rgb-image</a></li>
<li><a target="_blank" rel="noopener" href="http://www.bogotobogo.com/python/OpenCV_Python/python_opencv3_matplotlib_rgb_brg_image_load_display_save.php">python_opencv3_matplotlib_rgb_brg_image_load_display_save</a></li>
</ul>
<h2 id="History"><a href="#History" class="headerlink" title="History"></a>History</h2><ul>
<li>20180816: created.</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://kezunlin.me/blog/rcnn-tutorial/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="kezunlin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kezunlin's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/rcnn-tutorial/" class="post-title-link" itemprop="url">a quick guide to rcnn</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-08-16 10:11:00" itemprop="dateCreated datePublished" datetime="2018-08-16T10:11:00+08:00">2018-08-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-10-14 13:39:28" itemprop="dateModified" datetime="2024-10-14T13:39:28+08:00">2024-10-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h2><h3 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h3><p><a target="_blank" rel="noopener" href="https://github.com/rbgirshick/rcnn">R-CNN</a> is a state-of-the-art detector that classifies region proposals by a finetuned Caffe model. For the full details of the R-CNN system and model, refer to its project site and the paper:</p>
<blockquote>
<p><em>Rich feature hierarchies for accurate object detection and semantic segmentation</em>. Ross Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik. CVPR 2014. <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1311.2524">Arxiv 2013</a>.</p>
</blockquote>
<p>In this example, we do detection by a pure Caffe edition of the R-CNN model for ImageNet. The R-CNN detector outputs class scores for the 200 detection classes of ILSVRC13. Keep in mind that these are raw one vs. all SVM scores, so they are not probabilistically calibrated or exactly comparable across classes. Note that this off-the-shelf model is simply for convenience, and is not the full R-CNN model.</p>
<p>Let’s run detection on an image of a bicyclist riding a fish bike in the desert (from the ImageNet challenge—no joke).</p>
<h3 id="selective-search"><a href="#selective-search" class="headerlink" title="selective search"></a>selective search</h3><p>First, we’ll need region proposals and the Caffe R-CNN ImageNet model:</p>
<blockquote>
<p><a target="_blank" rel="noopener" href="http://koen.me/research/selectivesearch/">Selective Search</a> is the region proposer used by R-CNN. The <a target="_blank" rel="noopener" href="https://github.com/sergeyk/selective_search_ijcv_with_python">selective_search_ijcv_with_python</a> Python module takes care of extracting proposals through the selective search MATLAB implementation. </p>
</blockquote>
<h4 id="clone-repo"><a href="#clone-repo" class="headerlink" title="clone repo"></a>clone repo</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> <span class="variable">$CAFFE_ROOT</span>/caffe/python</span><br><span class="line">git <span class="built_in">clone</span> https://github.com/sergeyk/selective_search_ijcv_with_python.git`</span><br><span class="line"></span><br><span class="line">pip install tables</span><br></pre></td></tr></table></figure>

<h4 id="install-matlab"><a href="#install-matlab" class="headerlink" title="install matlab"></a>install matlab</h4><p>Install <code>matlab</code> and run <code>demo.m</code> file to compile functions</p>
<p>see <a href="https://kezunlin.me/post/deab4886/">here</a></p>
<p><strong>Notice: Restart computer for Solving Errors</strong>: </p>
<pre><code>OSError: [Errno 2] No such file or directory
</code></pre>
<h4 id="compile-matlab-functions"><a href="#compile-matlab-functions" class="headerlink" title="compile matlab functions"></a>compile matlab functions</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> caffe/python/caffe/selective_search_ijcv_with_python</span><br><span class="line"><span class="built_in">which</span> matlab</span><br><span class="line"><span class="comment">#/opt/MATLAB/R2016b/bin/matlab</span></span><br><span class="line"></span><br><span class="line">matlab demo.m</span><br></pre></td></tr></table></figure>

<ul>
<li><p>run demo in matlab<br><img src="https://kezunlin.me/images/posts/635233-20180822101918577-1947950229.png" alt="png"></p>
</li>
<li><p>origin image<br><img src="https://kezunlin.me/images/posts/635233-20180822102036279-1691824045.jpg" alt="png"></p>
</li>
<li><p>region results<br><img src="https://kezunlin.me/images/posts/635233-20180822101930740-496243953.png" alt="png"></p>
</li>
</ul>
<h3 id="detect-regions"><a href="#detect-regions" class="headerlink" title="detect regions"></a>detect regions</h3><p>Run scripts to get the Caffe R-CNN ImageNet model.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./scripts/download_model_binary.py models/bvlc_reference_rcnn_ilsvrc13</span><br></pre></td></tr></table></figure>

<p>With that done, we’ll call the bundled <code>detect.py</code> to generate the region proposals and run the network. For an explanation of the arguments, do <code>./detect.py --help</code>.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> caffe/examples/</span><br><span class="line"><span class="built_in">mkdir</span> -p _temp</span><br><span class="line"><span class="built_in">echo</span> `<span class="built_in">pwd</span>`/images/fish-bike.jpg &gt; _temp/det_input.txt</span><br><span class="line">../python/detect.py --crop_mode=selective_search --pretrained_model=../models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel --model_def=../models/bvlc_reference_rcnn_ilsvrc13/deploy.prototxt --gpu --raw_scale=255 _temp/det_input.txt _temp/det_output.h5</span><br></pre></td></tr></table></figure>

<pre><code>...
I1129 15:02:22.498908  3483 net.cpp:242] This network produces output fc-rcnn
I1129 15:02:22.498919  3483 net.cpp:255] Network initialization done.
I1129 15:02:22.577332  3483 upgrade_proto.cpp:53] Attempting to upgrade input file specified using deprecated V1LayerParameter: ../models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel
I1129 15:02:22.685262  3483 upgrade_proto.cpp:61] Successfully upgraded file specified using deprecated V1LayerParameter
I1129 15:02:22.685796  3483 upgrade_proto.cpp:67] Attempting to upgrade input file specified using deprecated input fields: ../models/bvlc_reference_rcnn_ilsvrc13/bvlc_reference_rcnn_ilsvrc13.caffemodel
I1129 15:02:22.685804  3483 upgrade_proto.cpp:70] Successfully upgraded file specified using deprecated input fields.
W1129 15:02:22.685809  3483 upgrade_proto.cpp:72] Note that future Caffe releases will only support input layers and not input fields.
Loading input...
selective_search_rcnn(&#123;&#39;/home/kezunlin/program/caffe/examples/images/fish-bike.jpg&#39;&#125;, &#39;/tmp/tmpkOe6J0.mat&#39;)
/home/kezunlin/program/caffe/python/caffe/detector.py:140: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  crop = im[window[0]:window[2], window[1]:window[3]]
/home/kezunlin/program/caffe/python/caffe/detector.py:174: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  context_crop = im[box[0]:box[2], box[1]:box[3]]
/usr/local/lib/python2.7/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, &#39;constant&#39;, will be changed to &#39;reflect&#39; in skimage 0.15.
  warn(&quot;The default mode, &#39;constant&#39;, will be changed to &#39;reflect&#39; in &quot;
/home/kezunlin/program/caffe/python/caffe/detector.py:177: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future
  crop[pad_y:(pad_y + crop_h), pad_x:(pad_x + crop_w)] = context_crop
Processed 1565 windows in 15.899 s.
/usr/local/lib/python2.7/dist-packages/pandas/core/generic.py:1299: PerformanceWarning: 
your performance may suffer as PyTables will pickle object types that it cannot
map directly to c-types [inferred_type-&gt;mixed,key-&gt;block1_values] [items-&gt;[&#39;prediction&#39;]]

  return pytables.to_hdf(path_or_buf, key, self, **kwargs)
Saved to _temp/det_output.h5 in 0.082 s.
</code></pre>
<p>This run was in GPU mode. For CPU mode detection, call <code>detect.py</code> without the <code>--gpu</code> argument.</p>
<h3 id="process-regions"><a href="#process-regions" class="headerlink" title="process regions"></a>process regions</h3><p>Running this outputs a DataFrame with the filenames, selected windows, and their detection scores to an HDF5 file.<br>(We only ran on one image, so the filenames will all be the same.)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line">df = pd.read_hdf(<span class="string">&#x27;_temp/det_output.h5&#x27;</span>, <span class="string">&#x27;df&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(df.shape)</span><br><span class="line">row = df.iloc[<span class="number">0</span>] <span class="comment"># prediction(200,), bbox as input image</span></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;row &#x27;</span>,row.shape</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;prediction &#x27;</span>,row[<span class="number">0</span>].shape</span><br><span class="line"><span class="built_in">print</span> <span class="built_in">type</span>(row)  <span class="comment"># class &#x27;pandas.core.series.Series</span></span><br><span class="line"><span class="built_in">print</span> row</span><br></pre></td></tr></table></figure>

<pre><code>(1565, 5)
row  (5,)
prediction  (200,)
&lt;class &#39;pandas.core.series.Series&#39;&gt;
prediction    [-2.60202, -2.87814, -3.0061, -2.77251, -2.077...
ymin                                                    152.958
xmin                                                    159.692
ymax                                                    261.702
xmax                                                    340.586
Name: /home/kezunlin/program/caffe/examples/images/fish-bike.jpg, dtype: object
</code></pre>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- kzl in-article ad -->
<p><ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5653382914441020"
     data-ad-slot="7925631830"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>




<p>1570 regions were proposed with the R-CNN configuration of selective search. The number of proposals will vary from image to image based on its contents and size – selective search isn’t scale invariant.</p>
<p>In general, <code>detect.py</code> is most efficient when running on a lot of images: it first extracts window proposals for all of them, batches the windows for efficient GPU processing, and then outputs the results.<br>Simply list an image per line in the <code>images_file</code>, and it will process all of them.</p>
<p>Although this guide gives an example of R-CNN ImageNet detection, <code>detect.py</code> is clever enough to adapt to different Caffe models’ input dimensions, batch size, and output categories. You can switch the model definition and pretrained model as desired. Refer to <code>python detect.py --help</code> for the parameters to describe your data set. There’s no need for hardcoding.</p>
<p>Anyway, let’s now load the ILSVRC13 detection class names and make a DataFrame of the predictions. Note you’ll need the auxiliary ilsvrc2012 data fetched by <code>data/ilsvrc12/get_ilsvrc12_aux.sh</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment">#n01443537 goldfish</span></span><br><span class="line"><span class="comment">#n03445777 golf ball</span></span><br><span class="line"><span class="comment">#...</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;../data/ilsvrc12/det_synset_words.txt&#x27;</span>) <span class="keyword">as</span> f: <span class="comment"># 200 classes from 1000 imagenet classes</span></span><br><span class="line">    labels_df = pd.DataFrame([</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">&#x27;synset_id&#x27;</span>: l.strip().split(<span class="string">&#x27; &#x27;</span>)[<span class="number">0</span>],</span><br><span class="line">            <span class="string">&#x27;name&#x27;</span>: <span class="string">&#x27; &#x27;</span>.join(l.strip().split(<span class="string">&#x27; &#x27;</span>)[<span class="number">1</span>:]).split(<span class="string">&#x27;,&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> l <span class="keyword">in</span> f.readlines()</span><br><span class="line">    ])</span><br><span class="line">labels_df.sort_values(by=<span class="string">&#x27;synset_id&#x27;</span>) <span class="comment"># from a... to z</span></span><br><span class="line"><span class="built_in">print</span> labels_df.shape <span class="comment"># (200, 2)</span></span><br><span class="line"><span class="built_in">print</span> labels_df.head(<span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<pre><code>(200, 2)
        name  synset_id
0  accordion  n02672831
1   airplane  n02691156
2        ant  n02219486
3   antelope  n02419796
4      apple  n07739125
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#print type(df.prediction) # &lt;class &#x27;pandas.core.series.Series&#x27;&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> df.prediction.values.shape <span class="comment"># numpy.ndarray (1565,)</span></span><br><span class="line"><span class="built_in">print</span> df.prediction.values[<span class="number">0</span>].shape <span class="comment"># numpy.ndarray (200,)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> np.vstack(df.prediction.values).shape <span class="comment"># (1565, 200)</span></span><br><span class="line"></span><br><span class="line">predictions_df = pd.DataFrame(np.vstack(df.prediction.values), columns=labels_df[<span class="string">&#x27;name&#x27;</span>])</span><br><span class="line"><span class="comment">#print predictions_df.values.shape # (1565, 200)</span></span><br><span class="line"><span class="built_in">print</span>(predictions_df.iloc[:<span class="number">5</span>,:<span class="number">7</span>])</span><br></pre></td></tr></table></figure>

<pre><code>(1565,)
(200,)
(1565, 200)
name  accordion  airplane       ant  antelope     apple  armadillo  artichoke
0     -2.602018 -2.878137 -3.006104 -2.772514 -2.077227  -2.590448  -2.414262
1     -2.997767 -3.312270 -2.878942 -3.434367 -2.227469  -2.492260  -2.383878
2     -2.476110 -3.145484 -2.377191 -2.684406 -2.289587  -2.428077  -2.390187
3     -2.362699 -2.784188 -1.981096 -2.664146 -2.207042  -2.299127  -2.181105
4     -2.929469 -2.323617 -2.755007 -3.165601 -2.188648  -2.486410  -2.505435
</code></pre>
<p>Let’s look at the activations.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">plt.gray()</span><br><span class="line">plt.matshow(predictions_df.values) <span class="comment"># (1565, 200)</span></span><br><span class="line">plt.xlabel(<span class="string">&#x27;Classes&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;Windows&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="https://kezunlin.me/images/posts/635233-20180816101220026-1212221400.png" alt="png"></p>
<p>Now let’s take max across all windows and plot the top classes.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">max_s = predictions_df.<span class="built_in">max</span>(<span class="number">0</span>)</span><br><span class="line">max_s = max_s.sort_values(ascending=<span class="literal">False</span>)</span><br><span class="line"><span class="built_in">print</span>(max_s[:<span class="number">10</span>])</span><br></pre></td></tr></table></figure>

<pre><code>name
person          1.839882
bicycle         0.855625
unicycle        0.085192
motorcycle      0.003604
turtle         -0.030388
banjo          -0.114999
electric fan   -0.220595
cart           -0.225192
lizard         -0.365949
helmet         -0.477555
dtype: float32
</code></pre>
<p>The top detections are in fact a person and bicycle.<br>Picking good localizations is a work in progress; we pick the top-scoring person and bicycle detections.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">i = predictions_df[<span class="string">&#x27;person&#x27;</span>].argmax() <span class="comment"># 70  rect</span></span><br><span class="line">j = predictions_df[<span class="string">&#x27;bicycle&#x27;</span>].argmax()<span class="comment"># 262 rect</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Show top predictions for top detection.</span></span><br><span class="line">f = pd.Series(df[<span class="string">&#x27;prediction&#x27;</span>].iloc[i], index=labels_df[<span class="string">&#x27;name&#x27;</span>]) <span class="comment"># (200,)</span></span><br><span class="line"><span class="comment">#print f.head(5)</span></span><br><span class="line"><span class="comment">#print </span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Top detection:&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(f.sort_values(ascending=<span class="literal">False</span>)[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show top predictions for second-best detection.</span></span><br><span class="line">f = pd.Series(df[<span class="string">&#x27;prediction&#x27;</span>].iloc[j], index=labels_df[<span class="string">&#x27;name&#x27;</span>]) <span class="comment"># (200,)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Second-best detection:&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(f.sort_values(ascending=<span class="literal">False</span>)[:<span class="number">5</span>])</span><br></pre></td></tr></table></figure>

<pre><code>Top detection:
name
person             1.839882
swimming trunks   -1.157806
turtle            -1.168884
tie               -1.217267
rubber eraser     -1.246662
dtype: float32

Second-best detection:
name
bicycle     0.855625
unicycle   -0.334367
scorpion   -0.824552
lobster    -0.965544
lamp       -1.076224
dtype: float32
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Find, print, and display the top detections: person and bicycle.</span></span><br><span class="line">i = predictions_df[<span class="string">&#x27;person&#x27;</span>].argmax()</span><br><span class="line">j = predictions_df[<span class="string">&#x27;bicycle&#x27;</span>].argmax()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show top predictions for top detection.</span></span><br><span class="line">f = pd.Series(df[<span class="string">&#x27;prediction&#x27;</span>].iloc[i], index=labels_df[<span class="string">&#x27;name&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Top detection:&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(f.sort_values(ascending=<span class="literal">False</span>)[:<span class="number">5</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show top predictions for second-best detection.</span></span><br><span class="line">f = pd.Series(df[<span class="string">&#x27;prediction&#x27;</span>].iloc[j], index=labels_df[<span class="string">&#x27;name&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Second-best detection:&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(f.sort_values(ascending=<span class="literal">False</span>)[:<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Show top detection in red, second-best top detection in blue.</span></span><br><span class="line">im = plt.imread(<span class="string">&#x27;images/fish-bike.jpg&#x27;</span>)</span><br><span class="line">plt.imshow(im)</span><br><span class="line">currentAxis = plt.gca()</span><br><span class="line"></span><br><span class="line">det = df.iloc[i]</span><br><span class="line">coords = (det[<span class="string">&#x27;xmin&#x27;</span>], det[<span class="string">&#x27;ymin&#x27;</span>]), det[<span class="string">&#x27;xmax&#x27;</span>] - det[<span class="string">&#x27;xmin&#x27;</span>], det[<span class="string">&#x27;ymax&#x27;</span>] - det[<span class="string">&#x27;ymin&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span> coords <span class="comment"># ((207.792, 7.6959999999999997), 134.71799999999999, 155.88200000000001)</span></span><br><span class="line">currentAxis.add_patch(plt.Rectangle(*coords, fill=<span class="literal">False</span>, edgecolor=<span class="string">&#x27;r&#x27;</span>, linewidth=<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">det = df.iloc[j]</span><br><span class="line">coords = (det[<span class="string">&#x27;xmin&#x27;</span>], det[<span class="string">&#x27;ymin&#x27;</span>]), det[<span class="string">&#x27;xmax&#x27;</span>] - det[<span class="string">&#x27;xmin&#x27;</span>], det[<span class="string">&#x27;ymax&#x27;</span>] - det[<span class="string">&#x27;ymin&#x27;</span>]</span><br><span class="line"><span class="built_in">print</span> coords <span class="comment"># ((108.706, 184.70400000000001), 284.78999999999996, 127.98399999999998)</span></span><br><span class="line">currentAxis.add_patch(plt.Rectangle(*coords, fill=<span class="literal">False</span>, edgecolor=<span class="string">&#x27;b&#x27;</span>, linewidth=<span class="number">5</span>))</span><br></pre></td></tr></table></figure>

<pre><code>Top detection:
name
person             1.839882
swimming trunks   -1.157806
turtle            -1.168884
tie               -1.217267
rubber eraser     -1.246662
dtype: float32

Second-best detection:
name
bicycle     0.855625
unicycle   -0.334367
scorpion   -0.824552
lobster    -0.965544
lamp       -1.076224
dtype: float32
((207.792, 7.6959999999999997), 134.71799999999999, 155.88200000000001)
((108.706, 184.70400000000001), 284.78999999999996, 127.98399999999998)
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180816101222714-1713668340.png" alt="png"></p>
<p>That’s cool. Let’s take all ‘bicycle’ detections and NMS them to get rid of overlapping windows.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">nms_detections</span>(<span class="params">dets, overlap=<span class="number">0.3</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Non-maximum suppression: Greedily select high-scoring detections and</span></span><br><span class="line"><span class="string">    skip detections that are significantly covered by a previously</span></span><br><span class="line"><span class="string">    selected detection.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    This version is translated from Matlab code by Tomasz Malisiewicz,</span></span><br><span class="line"><span class="string">    who sped up Pedro Felzenszwalb&#x27;s code.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    dets: ndarray</span></span><br><span class="line"><span class="string">        each row is [&#x27;xmin&#x27;, &#x27;ymin&#x27;, &#x27;xmax&#x27;, &#x27;ymax&#x27;, &#x27;score&#x27;]</span></span><br><span class="line"><span class="string">    overlap: float</span></span><br><span class="line"><span class="string">        minimum overlap ratio (0.3 default)  &gt;iou,then drop rect</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Output</span></span><br><span class="line"><span class="string">    ------</span></span><br><span class="line"><span class="string">    dets: ndarray</span></span><br><span class="line"><span class="string">        remaining after suppression.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    x1 = dets[:, <span class="number">0</span>]</span><br><span class="line">    y1 = dets[:, <span class="number">1</span>]</span><br><span class="line">    x2 = dets[:, <span class="number">2</span>]</span><br><span class="line">    y2 = dets[:, <span class="number">3</span>]</span><br><span class="line">    ind = np.argsort(dets[:, <span class="number">4</span>]) <span class="comment"># current ind set (min---&gt;max)</span></span><br><span class="line"></span><br><span class="line">    w = x2 - x1</span><br><span class="line">    h = y2 - y1</span><br><span class="line">    area = (w * h).astype(<span class="built_in">float</span>)</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    dets</span></span><br><span class="line"><span class="string">    pick = []</span></span><br><span class="line"><span class="string">    ind = [a,b,c,d,e,f]</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    while not ind.empty:</span></span><br><span class="line"><span class="string">        f, pick=[f],    ind=[a,b,c,d,e], o=[0.1,0.2,0.5,0.9,0.2],keep_ind=[0,1,4],ind=[a,b,e]</span></span><br><span class="line"><span class="string">        e, pick=[f,e],  ind=[a,b],       o=[0.4,0.1],keep_ind=[1],ind=[b]</span></span><br><span class="line"><span class="string">        b, pick=[f,e,b],ind=[],          o=[],       keep_ind=[], ind=[]</span></span><br><span class="line"><span class="string">    return dets[pick]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    pick = [] <span class="comment"># pick index</span></span><br><span class="line">    <span class="keyword">while</span> <span class="built_in">len</span>(ind) &gt; <span class="number">0</span>:</span><br><span class="line">        i = ind[-<span class="number">1</span>] <span class="comment"># choose last best index</span></span><br><span class="line">        pick.append(i)</span><br><span class="line">        ind = ind[:-<span class="number">1</span>] <span class="comment"># remove last one</span></span><br><span class="line"></span><br><span class="line">        xx1 = np.maximum(x1[i], x1[ind])</span><br><span class="line">        yy1 = np.maximum(y1[i], y1[ind])</span><br><span class="line">        xx2 = np.minimum(x2[i], x2[ind])</span><br><span class="line">        yy2 = np.minimum(y2[i], y2[ind])</span><br><span class="line"></span><br><span class="line">        w = np.maximum(<span class="number">0.</span>, xx2 - xx1)</span><br><span class="line">        h = np.maximum(<span class="number">0.</span>, yy2 - yy1)</span><br><span class="line"></span><br><span class="line">        wh = w * h</span><br><span class="line">        o = wh / (area[i] + area[ind] - wh) <span class="comment"># [0.1,0.2,0.5,0.9,0.2]</span></span><br><span class="line"></span><br><span class="line">        keep_ind = np.nonzero(o &lt;= overlap)[<span class="number">0</span>] <span class="comment"># (array([0, 1, 4]),) ===&gt;[0 1 4]</span></span><br><span class="line">        ind = ind[keep_ind]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dets[pick, :]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scores = predictions_df[<span class="string">&#x27;bicycle&#x27;</span>] <span class="comment"># (1565,)</span></span><br><span class="line">windows = df[[<span class="string">&#x27;xmin&#x27;</span>, <span class="string">&#x27;ymin&#x27;</span>, <span class="string">&#x27;xmax&#x27;</span>, <span class="string">&#x27;ymax&#x27;</span>]].values <span class="comment"># (1565, 4)</span></span><br><span class="line">dets = np.hstack((windows, scores[:, np.newaxis])) <span class="comment"># (1565, 4) (1565,1)===&gt;(1565,5) xmin,ymin,xmax,ymax,score</span></span><br><span class="line">nms_dets = nms_detections(dets,<span class="number">0.3</span>)</span><br><span class="line"><span class="built_in">print</span> dets.shape <span class="comment"># (1565, 5)</span></span><br><span class="line"><span class="built_in">print</span> nms_dets.shape <span class="comment"># (181, 5)</span></span><br></pre></td></tr></table></figure>

<pre><code>(1565, 5)
(181, 5)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> nms_dets[:<span class="number">3</span>]</span><br></pre></td></tr></table></figure>

<pre><code>[[ 108.706       184.704       393.496       312.688         0.85562503]
 [   0.           14.43        397.344       323.27         -0.73134482]
 [ 131.794       202.982       249.196       290.562        -1.26836455]]
</code></pre>
<p>Show top 3 NMS’d detections for ‘bicycle’ in the image and note the gap between the top scoring box (red) and the remaining boxes.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(im)</span><br><span class="line">currentAxis = plt.gca()</span><br><span class="line">colors = [<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;y&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> c, det <span class="keyword">in</span> <span class="built_in">zip</span>(colors, nms_dets[:<span class="number">3</span>]):</span><br><span class="line">    currentAxis.add_patch(</span><br><span class="line">        plt.Rectangle((det[<span class="number">0</span>], det[<span class="number">1</span>]), det[<span class="number">2</span>]-det[<span class="number">0</span>], det[<span class="number">3</span>]-det[<span class="number">1</span>],</span><br><span class="line">        fill=<span class="literal">False</span>, edgecolor=c, linewidth=<span class="number">5</span>)</span><br><span class="line">    )</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;scores:&#x27;</span>, nms_dets[:<span class="number">3</span>, <span class="number">4</span>]</span><br></pre></td></tr></table></figure>

<pre><code>scores: [ 0.85562503 -0.73134482 -1.26836455]
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180816101225186-628963131.png" alt="png"></p>
<p>This was an easy instance for bicycle as it was in the class’s training set. However, the person result is a true detection since this was not in the set for that class.</p>
<p>You should try out detection on an image of your own next!</p>
<p>(Remove the temp directory to clean up, and we’re done.)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!rm -rf _temp</span><br></pre></td></tr></table></figure>

<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="http://demo.vislab.berkeleyvision.org/">demo</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/BVLC/caffe">caffe git</a></li>
</ul>
<h2 id="History"><a href="#History" class="headerlink" title="History"></a>History</h2><ul>
<li>20180816: created.</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://kezunlin.me/blog/Multilabel-classification-on-PASCAL-using-python-data-layers/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="kezunlin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kezunlin's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/Multilabel-classification-on-PASCAL-using-python-data-layers/" class="post-title-link" itemprop="url">Multilabel classification on PASCAL using python data-layers</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-08-16 09:55:00" itemprop="dateCreated datePublished" datetime="2018-08-16T09:55:00+08:00">2018-08-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-10-14 13:39:28" itemprop="dateModified" datetime="2024-10-14T13:39:28+08:00">2024-10-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Tutorial"><a href="#Tutorial" class="headerlink" title="Tutorial"></a>Tutorial</h2><p>In this tutorial we will do multilabel classification on PASCAL VOC 2012.</p>
<p>Multilabel classification is a generalization of multiclass classification, where each instance (image) can belong to many classes. For example, an image may both belong to a “beach” category and a “vacation pictures” category. In multiclass classification, on the other hand, each image belongs to a single class.</p>
<p>Caffe supports multilabel classification through the SigmoidCrossEntropyLoss layer, and we will load data using a Python data layer. Data could also be provided through HDF5 or LMDB data layers, but the python data layer provides endless flexibility, so that’s what we will use.</p>
<h2 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h2><ul>
<li><p>First, make sure you compile caffe using<br>WITH_PYTHON_LAYER :&#x3D; 1</p>
</li>
<li><p>Second, download PASCAL VOC 2012. It’s available <a target="_blank" rel="noopener" href="http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html">here:</a></p>
</li>
<li><p>Third, import modules:</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys </span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os.path <span class="keyword">as</span> osp</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> copy <span class="keyword">import</span> copy</span><br><span class="line"></span><br><span class="line">% matplotlib inline</span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">6</span>, <span class="number">6</span>)</span><br><span class="line"></span><br><span class="line">caffe_root = <span class="string">&#x27;../&#x27;</span>  <span class="comment"># this file is expected to be in &#123;caffe_root&#125;/examples</span></span><br><span class="line">sys.path.append(caffe_root + <span class="string">&#x27;python&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> caffe <span class="comment"># If you get &quot;No module named _caffe&quot;, either you have not built pycaffe or you have the wrong path.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> caffe <span class="keyword">import</span> layers <span class="keyword">as</span> L, params <span class="keyword">as</span> P <span class="comment"># Shortcuts to define the net prototxt.</span></span><br><span class="line"></span><br><span class="line">sys.path.append(<span class="string">&quot;pycaffe/layers&quot;</span>) <span class="comment"># the datalayers we will use are in this directory.</span></span><br><span class="line">sys.path.append(<span class="string">&quot;pycaffe&quot;</span>) <span class="comment"># the tools file is in this folder</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> tools <span class="comment">#this contains some tools that we need</span></span><br></pre></td></tr></table></figure>

<ul>
<li>Fourth, set data directories and initialize caffe</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set data root directory, e.g:</span></span><br><span class="line">pascal_root = osp.join(caffe_root, <span class="string">&#x27;data/pascal/VOC2012&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># these are the PASCAL classes, we&#x27;ll need them later.</span></span><br><span class="line">classes = np.asarray([<span class="string">&#x27;aeroplane&#x27;</span>, <span class="string">&#x27;bicycle&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;boat&#x27;</span>, <span class="string">&#x27;bottle&#x27;</span>, </span><br><span class="line">                      <span class="string">&#x27;bus&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>, <span class="string">&#x27;chair&#x27;</span>, <span class="string">&#x27;cow&#x27;</span>, <span class="string">&#x27;diningtable&#x27;</span>,</span><br><span class="line">                      <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;motorbike&#x27;</span>, <span class="string">&#x27;person&#x27;</span>, <span class="string">&#x27;pottedplant&#x27;</span>, </span><br><span class="line">                      <span class="string">&#x27;sheep&#x27;</span>, <span class="string">&#x27;sofa&#x27;</span>, <span class="string">&#x27;train&#x27;</span>, <span class="string">&#x27;tvmonitor&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># make sure we have the caffenet weight downloaded.</span></span><br><span class="line"><span class="comment">#if not os.path.isfile(caffe_root + &#x27;models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel&#x27;):</span></span><br><span class="line"><span class="comment">#    print(&quot;Downloading pre-trained CaffeNet model...&quot;)</span></span><br><span class="line"><span class="comment">#    !../scripts/download_model_binary.py ../models/bvlc_reference_caffenet</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># initialize caffe for gpu mode</span></span><br><span class="line">caffe.set_mode_gpu()</span><br><span class="line">caffe.set_device(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h2 id="Define-network-prototxts"><a href="#Define-network-prototxts" class="headerlink" title="Define network prototxts"></a>Define network prototxts</h2><ul>
<li>Let’s start by defining the nets using caffe.NetSpec. Note how we used the SigmoidCrossEntropyLoss layer. This is the right loss for multilabel classification. Also note how the data layer is defined.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># helper function for common structures</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv_relu</span>(<span class="params">bottom, ks, nout, stride=<span class="number">1</span>, pad=<span class="number">0</span>, group=<span class="number">1</span></span>):</span><br><span class="line">    conv = L.Convolution(bottom, kernel_size=ks, stride=stride,</span><br><span class="line">                                num_output=nout, pad=pad, group=group)</span><br><span class="line">    <span class="keyword">return</span> conv, L.ReLU(conv, in_place=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># another helper function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fc_relu</span>(<span class="params">bottom, nout</span>):</span><br><span class="line">    fc = L.InnerProduct(bottom, num_output=nout)</span><br><span class="line">    <span class="keyword">return</span> fc, L.ReLU(fc, in_place=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># yet another helper function</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">max_pool</span>(<span class="params">bottom, ks, stride=<span class="number">1</span></span>):</span><br><span class="line">    <span class="keyword">return</span> L.Pooling(bottom, pool=P.Pooling.MAX, kernel_size=ks, stride=stride)</span><br><span class="line"></span><br><span class="line"><span class="comment"># main netspec wrapper</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">caffenet_multilabel</span>(<span class="params">data_layer_params, datalayer</span>):</span><br><span class="line">    <span class="comment"># setup the python data layer </span></span><br><span class="line">    n = caffe.NetSpec()</span><br><span class="line">    n.data, n.label = L.Python(module = <span class="string">&#x27;pascal_multilabel_datalayers&#x27;</span>, layer = datalayer, </span><br><span class="line">                               ntop = <span class="number">2</span>, param_str=<span class="built_in">str</span>(data_layer_params))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># the net itself</span></span><br><span class="line">    n.conv1, n.relu1 = conv_relu(n.data, <span class="number">11</span>, <span class="number">96</span>, stride=<span class="number">4</span>)</span><br><span class="line">    n.pool1 = max_pool(n.relu1, <span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line">    n.norm1 = L.LRN(n.pool1, local_size=<span class="number">5</span>, alpha=<span class="number">1e-4</span>, beta=<span class="number">0.75</span>)</span><br><span class="line">    n.conv2, n.relu2 = conv_relu(n.norm1, <span class="number">5</span>, <span class="number">256</span>, pad=<span class="number">2</span>, group=<span class="number">2</span>)</span><br><span class="line">    n.pool2 = max_pool(n.relu2, <span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line">    n.norm2 = L.LRN(n.pool2, local_size=<span class="number">5</span>, alpha=<span class="number">1e-4</span>, beta=<span class="number">0.75</span>)</span><br><span class="line">    n.conv3, n.relu3 = conv_relu(n.norm2, <span class="number">3</span>, <span class="number">384</span>, pad=<span class="number">1</span>)</span><br><span class="line">    n.conv4, n.relu4 = conv_relu(n.relu3, <span class="number">3</span>, <span class="number">384</span>, pad=<span class="number">1</span>, group=<span class="number">2</span>)</span><br><span class="line">    n.conv5, n.relu5 = conv_relu(n.relu4, <span class="number">3</span>, <span class="number">256</span>, pad=<span class="number">1</span>, group=<span class="number">2</span>)</span><br><span class="line">    n.pool5 = max_pool(n.relu5, <span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line">    n.fc6, n.relu6 = fc_relu(n.pool5, <span class="number">4096</span>)</span><br><span class="line">    n.drop6 = L.Dropout(n.relu6, in_place=<span class="literal">True</span>)</span><br><span class="line">    n.fc7, n.relu7 = fc_relu(n.drop6, <span class="number">4096</span>)</span><br><span class="line">    n.drop7 = L.Dropout(n.relu7, in_place=<span class="literal">True</span>)</span><br><span class="line">    n.score = L.InnerProduct(n.drop7, num_output=<span class="number">20</span>) <span class="comment"># z value</span></span><br><span class="line">    n.loss = L.SigmoidCrossEntropyLoss(n.score, n.label) <span class="comment"># a = sigmoid(z)</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">str</span>(n.to_proto())</span><br></pre></td></tr></table></figure>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- kzl in-article ad -->
<p><ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5653382914441020"
     data-ad-slot="7925631830"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>




<h2 id="Write-nets-and-solver-files"><a href="#Write-nets-and-solver-files" class="headerlink" title="Write nets and solver files"></a>Write nets and solver files</h2><ul>
<li>Now we can crete net and solver prototxts. For the solver, we use the CaffeSolver class from the “tools” module</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">workdir = <span class="string">&#x27;./pascal_multilabel_with_datalayer&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isdir(workdir):</span><br><span class="line">    os.makedirs(workdir)</span><br><span class="line"></span><br><span class="line">solverprototxt = tools.CaffeSolver(trainnet_prototxt_path = osp.join(workdir, <span class="string">&quot;trainnet.prototxt&quot;</span>), </span><br><span class="line">                                   testnet_prototxt_path = osp.join(workdir, <span class="string">&quot;valnet.prototxt&quot;</span>))</span><br><span class="line">solverprototxt.sp[<span class="string">&#x27;display&#x27;</span>] = <span class="string">&quot;1&quot;</span></span><br><span class="line">solverprototxt.sp[<span class="string">&#x27;base_lr&#x27;</span>] = <span class="string">&quot;0.0001&quot;</span></span><br><span class="line">solverprototxt.write(osp.join(workdir, <span class="string">&#x27;solver.prototxt&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># write train net.</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(osp.join(workdir, <span class="string">&#x27;trainnet.prototxt&#x27;</span>), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="comment"># provide parameters to the data layer as a python dictionary. Easy as pie!</span></span><br><span class="line">    data_layer_params = <span class="built_in">dict</span>(batch_size = <span class="number">128</span>, im_shape = [<span class="number">227</span>, <span class="number">227</span>], split = <span class="string">&#x27;train&#x27;</span>, pascal_root = pascal_root)</span><br><span class="line">    f.write(caffenet_multilabel(data_layer_params, <span class="string">&#x27;PascalMultilabelDataLayerSync&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># write validation net.</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(osp.join(workdir, <span class="string">&#x27;valnet.prototxt&#x27;</span>), <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    data_layer_params = <span class="built_in">dict</span>(batch_size = <span class="number">128</span>, im_shape = [<span class="number">227</span>, <span class="number">227</span>], split = <span class="string">&#x27;val&#x27;</span>, pascal_root = pascal_root)</span><br><span class="line">    f.write(caffenet_multilabel(data_layer_params, <span class="string">&#x27;PascalMultilabelDataLayerSync&#x27;</span>))</span><br></pre></td></tr></table></figure>

<ul>
<li><p>This net uses a python datalayer: ‘PascalMultilabelDataLayerSync’, which is defined in ‘.&#x2F;pycaffe&#x2F;layers&#x2F;pascal_multilabel_datalayers.py’. </p>
</li>
<li><p>Take a look at the code. It’s quite straight-forward, and gives you full control over data and labels.</p>
</li>
<li><p>Now we can load the caffe solver as usual.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">solver = caffe.SGDSolver(osp.join(workdir, <span class="string">&#x27;solver.prototxt&#x27;</span>))</span><br><span class="line">solver.net.copy_from(caffe_root + <span class="string">&#x27;models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel&#x27;</span>)</span><br><span class="line">solver.test_nets[<span class="number">0</span>].share_with(solver.net)</span><br><span class="line">solver.step(<span class="number">1</span>) <span class="comment"># load 128 train images</span></span><br><span class="line"><span class="comment"># 5717 train images; 5823 val images</span></span><br></pre></td></tr></table></figure>

<pre><code>BatchLoader initialized with 5717 images
PascalMultilabelDataLayerSync initialized for split: train, with bs: 128, im_shape: [227, 227].
BatchLoader initialized with 5823 images
PascalMultilabelDataLayerSync initialized for split: val, with bs: 128, im_shape: [227, 227].
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span> solver.net.blobs[<span class="string">&#x27;data&#x27;</span>].data.shape <span class="comment"># (128, 3, 227, 227)</span></span><br><span class="line"><span class="built_in">print</span> solver.net.blobs[<span class="string">&#x27;label&#x27;</span>].data.shape <span class="comment"># (128, 20)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#print solver.net.blobs[&#x27;loss&#x27;].data   # 13.8629436493</span></span><br><span class="line"><span class="comment">#print solver.test_nets[0].blobs[&#x27;data&#x27;].data.shape # (128, 3, 227, 227) no test images loaded</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#print solver.net.params[&#x27;score&#x27;][0].data.shape # (20, 4096)  filled weights</span></span><br><span class="line"><span class="comment">#print solver.net.params[&#x27;score&#x27;][0].data[:20,:5]</span></span><br></pre></td></tr></table></figure>

<pre><code>(128, 3, 227, 227)
(128, 20)
</code></pre>
<ul>
<li>Let’s check the data we have loaded.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">transformer = tools.SimpleTransformer() <span class="comment"># This is simply to add back the bias, re-shuffle the color channels to RGB, and so on...</span></span><br><span class="line">image_index = <span class="number">0</span> <span class="comment"># First image in the batch.</span></span><br><span class="line">image = solver.net.blobs[<span class="string">&#x27;data&#x27;</span>].data[image_index, ...]</span><br><span class="line"><span class="built_in">print</span> image.shape <span class="comment"># (3, 227, 227) BGR [0,255]</span></span><br><span class="line"><span class="comment">#print image[0,:10,:10]</span></span><br><span class="line"></span><br><span class="line">plot_image = transformer.deprocess(copy(image))</span><br><span class="line"><span class="comment">#print plot_image.shape #(227, 227, 3) RGB [0,255]</span></span><br><span class="line"><span class="comment">#print plot_image[:10,:10,0]</span></span><br><span class="line"></span><br><span class="line">image_labels = solver.net.blobs[<span class="string">&#x27;label&#x27;</span>].data[image_index]</span><br><span class="line"><span class="built_in">print</span> image_labels.shape <span class="comment"># (20,)</span></span><br><span class="line"><span class="built_in">print</span> image_labels <span class="comment">#float32 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.  0.  0.]</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.imshow(plot_image)</span><br><span class="line">gtlist = image_labels.astype(np.<span class="built_in">int</span>) <span class="comment"># float32-&gt;int labels</span></span><br><span class="line">plt.title(<span class="string">&#x27;GT: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(classes[np.where(gtlist)])) <span class="comment"># ground truth label list</span></span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>(3, 227, 227)
(20,)
[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  1.  0.  0.  0.
  1.  0.]
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180816100831322-968218798.png" alt="png"></p>
<ul>
<li>NOTE: we are readin the image from the data layer, so the resolution is lower than the original PASCAL image.</li>
</ul>
<h2 id="Train-a-net"><a href="#Train-a-net" class="headerlink" title="Train a net"></a>Train a net</h2><ul>
<li>Let’s train the net. First, though, we need some way to measure the accuracy. Hamming distance is commonly used in multilabel problems. We also need a simple test loop. Let’s write that down.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">hamming_distance</span>(<span class="params">gt, est</span>):</span><br><span class="line">    <span class="comment"># accu for only one image</span></span><br><span class="line">    <span class="comment">#   gt(20,) [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]</span></span><br><span class="line">    <span class="comment">#  est(20,) [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1]</span></span><br><span class="line">    <span class="comment"># accu = 19/20 = 0.95</span></span><br><span class="line">    <span class="comment">#print gt.shape,est.shape</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>([<span class="number">1</span> <span class="keyword">for</span> (g, e) <span class="keyword">in</span> <span class="built_in">zip</span>(gt, est) <span class="keyword">if</span> g == e]) / <span class="built_in">float</span>(<span class="built_in">len</span>(gt))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_accuracy</span>(<span class="params">net, num_batches, batch_size = <span class="number">128</span></span>):</span><br><span class="line">    acc = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(num_batches):</span><br><span class="line">        net.forward() <span class="comment"># load 128 batch images from test_nets</span></span><br><span class="line">        gts = net.blobs[<span class="string">&#x27;label&#x27;</span>].data <span class="comment"># (128,20)</span></span><br><span class="line">        gts = gts.astype(np.<span class="built_in">int</span>) <span class="comment"># float32-&gt;int</span></span><br><span class="line">        </span><br><span class="line">        ests = net.blobs[<span class="string">&#x27;score&#x27;</span>].data &gt; <span class="number">0</span> <span class="comment"># (128,20)  z-score&gt;0===&gt;1,otherwise ===&gt;0</span></span><br><span class="line">        ests = ests.astype(np.<span class="built_in">int</span>) <span class="comment"># bool-&gt;int</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> gt, est <span class="keyword">in</span> <span class="built_in">zip</span>(gts, ests): <span class="comment">#for each ground truth and estimated label vector</span></span><br><span class="line">            acc += hamming_distance(gt, est) <span class="comment"># gt(20,) est(20,) for 1 image</span></span><br><span class="line">    <span class="keyword">return</span> acc / (num_batches * batch_size)</span><br></pre></td></tr></table></figure>

<ul>
<li>Alright, now let’s train for a while</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line"><span class="keyword">for</span> itt <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">    solver.step(<span class="number">100</span>)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;itt:&#123;:3d&#125;&#x27;</span>.<span class="built_in">format</span>((itt + <span class="number">1</span>) * <span class="number">100</span>), <span class="string">&#x27;accuracy:&#123;0:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(check_accuracy(solver.test_nets[<span class="number">0</span>], <span class="number">50</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#itt:100 accuracy:0.9591</span></span><br><span class="line"><span class="comment">#itt:200 accuracy:0.9599</span></span><br><span class="line"><span class="comment">#itt:300 accuracy:0.9596</span></span><br><span class="line"><span class="comment">#itt:400 accuracy:0.9584</span></span><br><span class="line"><span class="comment">#itt:500 accuracy:0.9598</span></span><br><span class="line"><span class="comment">#itt:600 accuracy:0.9590</span></span><br></pre></td></tr></table></figure>

<pre><code>itt:100 accuracy:0.9591
itt:200 accuracy:0.9599
itt:300 accuracy:0.9596
itt:400 accuracy:0.9584
itt:500 accuracy:0.9598
itt:600 accuracy:0.9590
</code></pre>
<ul>
<li>Great, the accuracy is increasing, and it seems to converge rather quickly. It may seem strange that it starts off so high but <strong>it is because the ground truth is sparse. There are 20 classes in PASCAL, and usually only one or two is present. So predicting all zeros yields rather high accuracy</strong>. Let’s check to make sure.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line">num_train_images = <span class="number">5717</span></span><br><span class="line">num_val_images = <span class="number">5823</span></span><br><span class="line">num_batches = num_val_images/<span class="number">128</span> <span class="comment"># 45</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">check_baseline_accuracy</span>(<span class="params">net, num_batches, batch_size = <span class="number">128</span></span>):</span><br><span class="line">    acc = <span class="number">0.0</span></span><br><span class="line">    <span class="keyword">for</span> t <span class="keyword">in</span> <span class="built_in">range</span>(num_batches):</span><br><span class="line">        net.forward()</span><br><span class="line">        gts = net.blobs[<span class="string">&#x27;label&#x27;</span>].data        <span class="comment"># (128,20)  labels</span></span><br><span class="line">        ests = np.zeros((batch_size, <span class="number">20</span>))       <span class="comment"># (128,20)  set to [0,0,0,...0,0]</span></span><br><span class="line">        <span class="keyword">for</span> gt, est <span class="keyword">in</span> <span class="built_in">zip</span>(gts, ests): <span class="comment">#for each ground truth and estimated label vector</span></span><br><span class="line">            acc += hamming_distance(gt, est)</span><br><span class="line">    <span class="keyword">return</span> acc / (num_batches * batch_size)</span><br><span class="line"></span><br><span class="line"><span class="comment"># gts 19 + 1, est 20, accu = 19/20 = 0.95</span></span><br><span class="line"><span class="comment"># gts 18 + 2, est 20, accu = 18/20 = 0.90</span></span><br><span class="line"><span class="comment"># avg cases: 0.925</span></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Baseline accuracy:&#123;0:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(check_baseline_accuracy(solver.test_nets[<span class="number">0</span>], num_batches))</span><br></pre></td></tr></table></figure>

<pre><code>Baseline accuracy:0.9241
CPU times: user 40.4 s, sys: 864 ms, total: 41.3 s
Wall time: 41.3 s
</code></pre>
<h2 id="Look-at-some-prediction-results"><a href="#Look-at-some-prediction-results" class="headerlink" title="Look at some prediction results"></a>Look at some prediction results</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">test_net = solver.test_nets[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span> classes</span><br><span class="line"><span class="keyword">for</span> image_index <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span> </span><br><span class="line">    plt.figure()</span><br><span class="line">    plot_image = transformer.deprocess(copy(test_net.blobs[<span class="string">&#x27;data&#x27;</span>].data[image_index,...]))</span><br><span class="line">    plt.imshow(plot_image)</span><br><span class="line">    gtlist = test_net.blobs[<span class="string">&#x27;label&#x27;</span>].data[image_index, ...].astype(np.<span class="built_in">int</span>)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;gt&#x27;</span>,gtlist</span><br><span class="line">    estlist = test_net.blobs[<span class="string">&#x27;score&#x27;</span>].data[image_index, ...] &gt; <span class="number">0</span></span><br><span class="line">    estlist = estlist.astype(np.<span class="built_in">int</span>)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;est&#x27;</span>,estlist</span><br><span class="line">    plt.title(<span class="string">&#x27;GT: &#123;&#125; \n EST: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(classes[np.where(gtlist)], classes[np.where(estlist)]))</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>[&#39;aeroplane&#39; &#39;bicycle&#39; &#39;bird&#39; &#39;boat&#39; &#39;bottle&#39; &#39;bus&#39; &#39;car&#39; &#39;cat&#39; &#39;chair&#39;
 &#39;cow&#39; &#39;diningtable&#39; &#39;dog&#39; &#39;horse&#39; &#39;motorbike&#39; &#39;person&#39; &#39;pottedplant&#39;
 &#39;sheep&#39; &#39;sofa&#39; &#39;train&#39; &#39;tvmonitor&#39;]

gt [0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0]
est [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]

gt [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]
est [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]

gt [0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]
est [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]

gt [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]
est [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]

gt [0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0]
est [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180816100834890-529897754.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180816100834890-529897754.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180816100841701-574240140.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180816100844564-748953554.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180816100848263-751780307.png" alt="png"></p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><ul>
<li><a target="_blank" rel="noopener" href="http://demo.vislab.berkeleyvision.org/">demo</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/BVLC/caffe">caffe git</a></li>
</ul>
<h1 id="History"><a href="#History" class="headerlink" title="History"></a>History</h1><ul>
<li>20180816: created.</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://kezunlin.me/blog/Net-Surgery/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="kezunlin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kezunlin's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/Net-Surgery/" class="post-title-link" itemprop="url">Net Surgery with Caffe and Python</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-08-16 09:48:00" itemprop="dateCreated datePublished" datetime="2018-08-16T09:48:00+08:00">2018-08-16</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-10-14 13:39:28" itemprop="dateModified" datetime="2024-10-14T13:39:28+08:00">2024-10-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Tutorial"><a href="#Tutorial" class="headerlink" title="Tutorial"></a>Tutorial</h2><p>Caffe networks can be transformed to your particular needs by editing the model parameters. The data, diffs, and parameters of a net are all exposed in pycaffe.</p>
<p>Roll up your sleeves for net surgery with pycaffe!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># Make sure that caffe is on the python path:</span></span><br><span class="line">caffe_root = <span class="string">&#x27;../&#x27;</span>  <span class="comment"># this file is expected to be in &#123;caffe_root&#125;/examples</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.insert(<span class="number">0</span>, caffe_root + <span class="string">&#x27;python&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> caffe</span><br><span class="line"></span><br><span class="line"><span class="comment"># configure plotting</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">10</span>, <span class="number">10</span>)</span><br><span class="line">plt.rcParams[<span class="string">&#x27;image.interpolation&#x27;</span>] = <span class="string">&#x27;nearest&#x27;</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;image.cmap&#x27;</span>] = <span class="string">&#x27;gray&#x27;</span></span><br></pre></td></tr></table></figure>

<h3 id="Designer-Filters"><a href="#Designer-Filters" class="headerlink" title="Designer Filters"></a>Designer Filters</h3><p>To show how to load, manipulate, and save parameters we’ll design our own filters into a simple network that’s only a single convolution layer. This net has two blobs, <code>data</code> for the input and <code>conv</code> for the convolution output and one parameter <code>conv</code> for the convolution filter weights and biases.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load the net, list its data and params, and filter an example image.</span></span><br><span class="line">caffe.set_mode_cpu()</span><br><span class="line">net = caffe.Net(<span class="string">&#x27;net_surgery/conv.prototxt&#x27;</span>, caffe.TEST)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;blobs &#123;&#125;\nparams &#123;&#125;&quot;</span>.<span class="built_in">format</span>(net.blobs.keys(), net.params.keys()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># load image and prepare as a single input batch for Caffe</span></span><br><span class="line">im = np.array(caffe.io.load_image(<span class="string">&#x27;images/cat_gray.jpg&#x27;</span>, color=<span class="literal">False</span>)).squeeze()</span><br><span class="line"><span class="comment"># caffe.io.load_image: dims: (height,width,channels),order: RGB,range: [0,1] dtype: float32</span></span><br><span class="line"><span class="comment">#(360, 480, 1)--&gt;(360, 480)  </span></span><br><span class="line"><span class="comment">#print im[:5,:5]</span></span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;original image&quot;</span>)</span><br><span class="line">plt.imshow(im)</span><br><span class="line">plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line">im_input = im[np.newaxis, np.newaxis, :, :] <span class="comment">#(1, 1, 360, 480) (c,h,w) [0,1] float32</span></span><br><span class="line"></span><br><span class="line">net.blobs[<span class="string">&#x27;data&#x27;</span>].reshape(*im_input.shape) <span class="comment"># (1, 1, 100, 100) ---&gt;(1, 1, 360, 480)</span></span><br><span class="line"><span class="built_in">print</span> net.blobs[<span class="string">&#x27;data&#x27;</span>].data.shape </span><br><span class="line">net.blobs[<span class="string">&#x27;data&#x27;</span>].data[...] = im_input</span><br></pre></td></tr></table></figure>

<pre><code>blobs [&#39;data&#39;, &#39;conv&#39;]
params [&#39;conv&#39;]
[[ 0.10196079  0.10588235  0.09803922  0.10980392  0.11372549]
 [ 0.10196079  0.10588235  0.09803922  0.10196079  0.10980392]
 [ 0.10196079  0.10588235  0.10196079  0.10196079  0.10588235]
 [ 0.10588235  0.10196079  0.10588235  0.10980392  0.11372549]
 [ 0.11764706  0.10196079  0.10196079  0.10588235  0.10980392]]
(1, 1, 360, 480)
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180816095053371-613196163.png" alt="png"></p>
<p>The convolution weights are initialized from Gaussian noise while the biases are initialized to zero. These random filters give output somewhat like edge detections.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># helper show filter outputs</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_filters</span>(<span class="params">net</span>):</span><br><span class="line">    net.forward()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> name,blob <span class="keyword">in</span> net.blobs.iteritems():</span><br><span class="line">        <span class="built_in">print</span> name,blob.data.shape</span><br><span class="line">    <span class="comment"># data (1, 1, 360, 480)   o = (i+2*p-k)/s+1 -&gt;360-5+1=356, 480-5+1=476 </span></span><br><span class="line">    <span class="comment"># conv (1, 3, 356, 476)</span></span><br><span class="line">    <span class="built_in">print</span> </span><br><span class="line">    <span class="keyword">for</span> name,param <span class="keyword">in</span> net.params.iteritems():</span><br><span class="line">        <span class="built_in">print</span> name,param[<span class="number">0</span>].data.shape  <span class="comment"># conv (3, 1, 5, 5)</span></span><br><span class="line">        </span><br><span class="line">    plt.figure()</span><br><span class="line">    filt_count = <span class="number">3</span></span><br><span class="line">    filt_min, filt_max = net.blobs[<span class="string">&#x27;conv&#x27;</span>].data.<span class="built_in">min</span>(), net.blobs[<span class="string">&#x27;conv&#x27;</span>].data.<span class="built_in">max</span>()</span><br><span class="line">    <span class="built_in">print</span> filt_min,filt_max</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">        plt.subplot(<span class="number">1</span>,<span class="number">4</span>,i+<span class="number">2</span>)</span><br><span class="line">        plt.title(<span class="string">&quot;filter #&#123;&#125; output&quot;</span>.<span class="built_in">format</span>(i))</span><br><span class="line">        </span><br><span class="line">        plt.imshow(net.blobs[<span class="string">&#x27;conv&#x27;</span>].data[<span class="number">0</span>, i], vmin=filt_min, vmax=filt_max)</span><br><span class="line">        <span class="comment">#plt.imshow(net.blobs[&#x27;conv&#x27;].data[0, i])</span></span><br><span class="line">        <span class="comment">#cbar = plt.colorbar() # depends on vmin,vmax</span></span><br><span class="line">        </span><br><span class="line">        plt.tight_layout()</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># filter the image with initial </span></span><br><span class="line">show_filters(net)</span><br></pre></td></tr></table></figure>

<pre><code>data (1, 1, 360, 480)
conv (1, 3, 356, 476)

conv (3, 1, 5, 5)
-0.0651154 0.097207
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180816095057441-58520598.png" alt="png"></p>
<p>Raising the bias of a filter will correspondingly raise its output:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pick first filter output</span></span><br><span class="line">conv0 = net.blobs[<span class="string">&#x27;conv&#x27;</span>].data[<span class="number">0</span>, <span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;pre-surgery output mean &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(conv0.mean()))</span><br><span class="line"><span class="comment"># set first filter bias to 1</span></span><br><span class="line"><span class="comment">#print net.params[&#x27;conv&#x27;][1].data.shape</span></span><br><span class="line">net.params[<span class="string">&#x27;conv&#x27;</span>][<span class="number">1</span>].data[<span class="number">0</span>] = <span class="number">1.</span> <span class="comment">#(3,)</span></span><br><span class="line">net.forward()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;post-surgery output mean &#123;:.2f&#125;&quot;</span>.<span class="built_in">format</span>(conv0.mean()))</span><br><span class="line"><span class="comment"># for conv data,z = wx+b</span></span><br><span class="line"><span class="comment"># z = wx+0, z = wx+1</span></span><br></pre></td></tr></table></figure>

<pre><code>pre-surgery output mean 0.04
(3,)
post-surgery output mean 1.04
</code></pre>
<p>Altering the filter weights is more exciting since we can assign any kernel like Gaussian blur, the Sobel operator for edges, and so on. The following surgery turns the 0th filter into a Gaussian blur and the 1st and 2nd filters into the horizontal and vertical gradient parts of the Sobel operator.</p>
<p>See how the 0th output is blurred, the 1st picks up horizontal edges, and the 2nd picks up vertical edges.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ksize = net.params[<span class="string">&#x27;conv&#x27;</span>][<span class="number">0</span>].data.shape[<span class="number">2</span>:] <span class="comment"># conv (3, 1, 5, 5)---&gt;(5,5)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># make Gaussian blur</span></span><br><span class="line">sigma = <span class="number">1.</span></span><br><span class="line">y, x = np.mgrid[-ksize[<span class="number">0</span>]//<span class="number">2</span> + <span class="number">1</span>:ksize[<span class="number">0</span>]//<span class="number">2</span> + <span class="number">1</span>, -ksize[<span class="number">1</span>]//<span class="number">2</span> + <span class="number">1</span>:ksize[<span class="number">1</span>]//<span class="number">2</span> + <span class="number">1</span>]</span><br><span class="line">g = np.exp(-((x**<span class="number">2</span> + y**<span class="number">2</span>)/(<span class="number">2.0</span>*sigma**<span class="number">2</span>)))</span><br><span class="line">gaussian = (g / g.<span class="built_in">sum</span>()).astype(np.float32)</span><br><span class="line"></span><br><span class="line">net.params[<span class="string">&#x27;conv&#x27;</span>][<span class="number">0</span>].data[<span class="number">0</span>] = gaussian</span><br><span class="line"></span><br><span class="line"><span class="comment"># make Sobel operator for edge detection</span></span><br><span class="line">net.params[<span class="string">&#x27;conv&#x27;</span>][<span class="number">0</span>].data[<span class="number">1</span>:] = <span class="number">0.</span></span><br><span class="line">sobel = np.array((-<span class="number">1</span>, -<span class="number">2</span>, -<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>), dtype=np.float32).reshape((<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">net.params[<span class="string">&#x27;conv&#x27;</span>][<span class="number">0</span>].data[<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>:-<span class="number">1</span>, <span class="number">1</span>:-<span class="number">1</span>] = sobel  <span class="comment"># horizontal</span></span><br><span class="line">net.params[<span class="string">&#x27;conv&#x27;</span>][<span class="number">0</span>].data[<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>:-<span class="number">1</span>, <span class="number">1</span>:-<span class="number">1</span>] = sobel.T  <span class="comment"># vertical</span></span><br><span class="line">show_filters(net)</span><br></pre></td></tr></table></figure>

<pre><code>data (1, 1, 360, 480)
conv (1, 3, 356, 476)

conv (3, 1, 5, 5)
-3.67843 3.77647
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180816095102256-537112316.png" alt="png"></p>
<p>With net surgery, parameters can be transplanted across nets, regularized by custom per-parameter operations, and transformed according to your schemes.</p>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- kzl in-article ad -->
<p><ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5653382914441020"
     data-ad-slot="7925631830"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h3 id="Casting-a-Classifier-into-a-Fully-Convolutional-Network"><a href="#Casting-a-Classifier-into-a-Fully-Convolutional-Network" class="headerlink" title="Casting a Classifier into a Fully Convolutional Network"></a>Casting a Classifier into a Fully Convolutional Network</h3><p>Let’s take the standard Caffe Reference ImageNet model “CaffeNet” and transform it into a fully convolutional net for efficient, dense inference on large inputs. This model generates a classification map that covers a given input size instead of a single classification. In particular a 8 $\times$ 8 classification map on a 451 $\times$ 451 input gives 64x the output in only 3x the time. The computation exploits a natural efficiency of convolutional network (convnet) structure by amortizing the computation of overlapping receptive fields.</p>
<p>To do so we translate the <code>InnerProduct</code> matrix multiplication layers of CaffeNet into <code>Convolutional</code> layers. This is the only change: the other layer types are agnostic to spatial size. Convolution is translation-invariant, activations are elementwise operations, and so on. The <code>fc6</code> inner product when carried out as convolution by <code>fc6-conv</code> turns into a 6 $\times$ 6 filter with stride 1 on <code>pool5</code>. Back in image space this gives a classification for each 227 $\times$ 227 box with stride 32 in pixels. Remember the equation for output map &#x2F; receptive field size, output &#x3D; (input - kernel_size) &#x2F; stride + 1, and work out the indexing details for a clear understanding.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!diff net_surgery/bvlc_caffenet_full_conv.prototxt ../models/bvlc_reference_caffenet/deploy.prototxt</span><br></pre></td></tr></table></figure>

<pre><code>1,2c1
&lt; # Fully convolutional network version of CaffeNet.
&lt; name: &quot;CaffeNetConv&quot;
---
&gt; name: &quot;CaffeNet&quot;
7,11c6
&lt;   input_param &#123;
&lt;     # initial shape for a fully convolutional network:
&lt;     # the shape can be set for each input by reshape.
&lt;     shape: &#123; dim: 1 dim: 3 dim: 451 dim: 451 &#125;
&lt;   &#125;
---
&gt;   input_param &#123; shape: &#123; dim: 10 dim: 3 dim: 227 dim: 227 &#125; &#125;
157,158c152,153
&lt;   name: &quot;fc6-conv&quot;
&lt;   type: &quot;Convolution&quot;
---
&gt;   name: &quot;fc6&quot;
&gt;   type: &quot;InnerProduct&quot;
160,161c155,156
&lt;   top: &quot;fc6-conv&quot;
&lt;   convolution_param &#123;
---
&gt;   top: &quot;fc6&quot;
&gt;   inner_product_param &#123;
163d157
&lt;     kernel_size: 6
169,170c163,164
&lt;   bottom: &quot;fc6-conv&quot;
&lt;   top: &quot;fc6-conv&quot;
---
&gt;   bottom: &quot;fc6&quot;
&gt;   top: &quot;fc6&quot;
175,176c169,170
&lt;   bottom: &quot;fc6-conv&quot;
&lt;   top: &quot;fc6-conv&quot;
---
&gt;   bottom: &quot;fc6&quot;
&gt;   top: &quot;fc6&quot;
182,186c176,180
&lt;   name: &quot;fc7-conv&quot;
&lt;   type: &quot;Convolution&quot;
&lt;   bottom: &quot;fc6-conv&quot;
&lt;   top: &quot;fc7-conv&quot;
&lt;   convolution_param &#123;
---
&gt;   name: &quot;fc7&quot;
&gt;   type: &quot;InnerProduct&quot;
&gt;   bottom: &quot;fc6&quot;
&gt;   top: &quot;fc7&quot;
&gt;   inner_product_param &#123;
188d181
&lt;     kernel_size: 1
194,195c187,188
&lt;   bottom: &quot;fc7-conv&quot;
&lt;   top: &quot;fc7-conv&quot;
---
&gt;   bottom: &quot;fc7&quot;
&gt;   top: &quot;fc7&quot;
200,201c193,194
&lt;   bottom: &quot;fc7-conv&quot;
&lt;   top: &quot;fc7-conv&quot;
---
&gt;   bottom: &quot;fc7&quot;
&gt;   top: &quot;fc7&quot;
207,211c200,204
&lt;   name: &quot;fc8-conv&quot;
&lt;   type: &quot;Convolution&quot;
&lt;   bottom: &quot;fc7-conv&quot;
&lt;   top: &quot;fc8-conv&quot;
&lt;   convolution_param &#123;
---
&gt;   name: &quot;fc8&quot;
&gt;   type: &quot;InnerProduct&quot;
&gt;   bottom: &quot;fc7&quot;
&gt;   top: &quot;fc8&quot;
&gt;   inner_product_param &#123;
213d205
&lt;     kernel_size: 1
219c211
&lt;   bottom: &quot;fc8-conv&quot;
---
&gt;   bottom: &quot;fc8&quot;
</code></pre>
<p>The only differences needed in the architecture are to change the fully connected classifier inner product layers into convolutional layers with the right filter size – 6 x 6, since the reference model classifiers take the 36 elements of <code>pool5</code> as input – and stride 1 for dense classification. Note that the layers are renamed so that Caffe does not try to blindly load the old parameters when it maps layer names to the pretrained model.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load the original network and extract the fully connected layers&#x27; parameters.</span></span><br><span class="line">net = caffe.Net(<span class="string">&#x27;../models/bvlc_reference_caffenet/deploy.prototxt&#x27;</span>, </span><br><span class="line">                <span class="string">&#x27;../models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel&#x27;</span>, </span><br><span class="line">                caffe.TEST)</span><br><span class="line">params = [<span class="string">&#x27;fc6&#x27;</span>, <span class="string">&#x27;fc7&#x27;</span>, <span class="string">&#x27;fc8&#x27;</span>]</span><br><span class="line"><span class="comment"># fc_params = &#123;name: (weights, biases)&#125;</span></span><br><span class="line">fc_params = &#123;pr: (net.params[pr][<span class="number">0</span>].data, net.params[pr][<span class="number">1</span>].data) <span class="keyword">for</span> pr <span class="keyword">in</span> params&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> pr <span class="keyword">in</span> params:</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;&#123;&#125; weights are &#123;&#125; dimensional and biases are &#123;&#125; dimensional&#x27;</span>.<span class="built_in">format</span>(pr, fc_params[pr][<span class="number">0</span>].shape, fc_params[pr][<span class="number">1</span>].shape)</span><br><span class="line">    </span><br><span class="line">pr = <span class="string">&#x27;fc6&#x27;</span></span><br><span class="line"><span class="built_in">print</span> net.params[pr][<span class="number">0</span>].data[<span class="number">0</span>,:<span class="number">6</span>*<span class="number">6</span>]  <span class="comment"># no weight_filler,loaded from weights file  </span></span><br><span class="line"><span class="built_in">print</span> net.params[pr][<span class="number">1</span>].data[<span class="number">0</span>]       <span class="comment"># no bias_filler,loaded from weights file  </span></span><br></pre></td></tr></table></figure>

<pre><code>fc6 weights are (4096, 9216) dimensional and biases are (4096,) dimensional
fc7 weights are (4096, 4096) dimensional and biases are (4096,) dimensional
fc8 weights are (1000, 4096) dimensional and biases are (1000,) dimensional
[ 0.00639847  0.00915686  0.00467043  0.00118941  0.00083305  0.00249258
  0.00249609 -0.00354958 -0.00502381 -0.00660044 -0.00810635 -0.00120969
 -0.00182751 -0.00181385 -0.00327348 -0.00657627 -0.01059825 -0.00223066
  0.00023664  0.00040984 -0.00052619 -0.00124062 -0.00269398 -0.00051081
  0.0014997   0.00123309 -0.00013806 -0.00111619  0.00321043  0.00284487
  0.00051387 -0.00087142 -0.00038937 -0.0008678   0.0049024   0.00155215]
0.983698
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> layer_name, blob <span class="keyword">in</span> net.blobs.iteritems():</span><br><span class="line">    <span class="built_in">print</span> layer_name + <span class="string">&#x27;\t&#x27;</span> + <span class="built_in">str</span>(blob.data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>data	(10, 3, 227, 227)
conv1	(10, 96, 55, 55)
pool1	(10, 96, 27, 27)
norm1	(10, 96, 27, 27)
conv2	(10, 256, 27, 27)
pool2	(10, 256, 13, 13)
norm2	(10, 256, 13, 13)
conv3	(10, 384, 13, 13)
conv4	(10, 384, 13, 13)
conv5	(10, 256, 13, 13)
pool5	(10, 256, 6, 6)
fc6	(10, 4096)
fc7	(10, 4096)
fc8	(10, 1000)
prob	(10, 1000)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> layer_name, param <span class="keyword">in</span> net.params.iteritems():</span><br><span class="line">    <span class="built_in">print</span> layer_name + <span class="string">&#x27;\t&#x27;</span> + <span class="built_in">str</span>(param[<span class="number">0</span>].data.shape), <span class="built_in">str</span>(param[<span class="number">1</span>].data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>conv1	(96, 3, 11, 11) (96,)
conv2	(256, 48, 5, 5) (256,)
conv3	(384, 256, 3, 3) (384,)
conv4	(384, 192, 3, 3) (384,)
conv5	(256, 192, 3, 3) (256,)
fc6	(4096, 9216) (4096,)
fc7	(4096, 4096) (4096,)
fc8	(1000, 4096) (1000,)
</code></pre>
<p>Consider the shapes of the inner product parameters. The weight dimensions are the output and input sizes while the bias dimension is the output size.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load the fully convolutional network to transplant the parameters.</span></span><br><span class="line">net_full_conv = caffe.Net(<span class="string">&#x27;net_surgery/bvlc_caffenet_full_conv.prototxt&#x27;</span>, </span><br><span class="line">                          <span class="string">&#x27;../models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel&#x27;</span>,</span><br><span class="line">                          caffe.TEST)</span><br><span class="line">params_full_conv = [<span class="string">&#x27;fc6-conv&#x27;</span>, <span class="string">&#x27;fc7-conv&#x27;</span>, <span class="string">&#x27;fc8-conv&#x27;</span>]</span><br><span class="line"><span class="comment"># conv_params = &#123;name: (weights, biases)&#125;</span></span><br><span class="line">conv_params = &#123;pr: (net_full_conv.params[pr][<span class="number">0</span>].data, net_full_conv.params[pr][<span class="number">1</span>].data) <span class="keyword">for</span> pr <span class="keyword">in</span> params_full_conv&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> pr <span class="keyword">in</span> params_full_conv:</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;&#123;&#125; weights are &#123;&#125; dimensional and biases are &#123;&#125; dimensional&#x27;</span>.<span class="built_in">format</span>(pr, conv_params[pr][<span class="number">0</span>].shape, conv_params[pr][<span class="number">1</span>].shape)</span><br><span class="line"></span><br><span class="line">pr = <span class="string">&#x27;fc6-conv&#x27;</span></span><br><span class="line"><span class="built_in">print</span> net_full_conv.params[pr][<span class="number">0</span>].data[<span class="number">0</span>,<span class="number">0</span>,:,:] <span class="comment"># no weight_filler,default to 0s</span></span><br><span class="line"><span class="built_in">print</span> net_full_conv.params[pr][<span class="number">1</span>].data[<span class="number">0</span>]      <span class="comment"># no bias_filler,default to 0s</span></span><br></pre></td></tr></table></figure>

<pre><code>fc6-conv weights are (4096, 256, 6, 6) dimensional and biases are (4096,) dimensional
fc7-conv weights are (4096, 4096, 1, 1) dimensional and biases are (4096,) dimensional
fc8-conv weights are (1000, 4096, 1, 1) dimensional and biases are (1000,) dimensional
[[ 0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.]]
0.0
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> layer_name, blob <span class="keyword">in</span> net_full_conv.blobs.iteritems():</span><br><span class="line">    <span class="built_in">print</span> layer_name + <span class="string">&#x27;\t&#x27;</span> + <span class="built_in">str</span>(blob.data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>data	(1, 3, 451, 451)
conv1	(1, 96, 111, 111)
pool1	(1, 96, 55, 55)
norm1	(1, 96, 55, 55)
conv2	(1, 256, 55, 55)
pool2	(1, 256, 27, 27)
norm2	(1, 256, 27, 27)
conv3	(1, 384, 27, 27)
conv4	(1, 384, 27, 27)
conv5	(1, 256, 27, 27)
pool5	(1, 256, 13, 13)
fc6-conv	(1, 4096, 8, 8)
fc7-conv	(1, 4096, 8, 8)
fc8-conv	(1, 1000, 8, 8)
prob	(1, 1000, 8, 8)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> layer_name, param <span class="keyword">in</span> net_full_conv.params.iteritems():</span><br><span class="line">    <span class="built_in">print</span> layer_name + <span class="string">&#x27;\t&#x27;</span> + <span class="built_in">str</span>(param[<span class="number">0</span>].data.shape), <span class="built_in">str</span>(param[<span class="number">1</span>].data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>conv1	(96, 3, 11, 11) (96,)
conv2	(256, 48, 5, 5) (256,)
conv3	(384, 256, 3, 3) (384,)
conv4	(384, 192, 3, 3) (384,)
conv5	(256, 192, 3, 3) (256,)
fc6-conv	(4096, 256, 6, 6) (4096,)
fc7-conv	(4096, 4096, 1, 1) (4096,)
fc8-conv	(1000, 4096, 1, 1) (1000,)
</code></pre>
<p>The convolution weights are arranged in output $\times$ input $\times$ height $\times$ width dimensions. To map the inner product weights to convolution filters, we could roll the flat inner product vectors into channel $\times$ height $\times$ width filter matrices, but actually these are identical in memory (as row major arrays) so we can assign them directly.</p>
<p>The biases are identical to those of the inner product.</p>
<p>Let’s transplant!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">print_params</span>():</span><br><span class="line">    <span class="keyword">for</span> pr <span class="keyword">in</span> params:</span><br><span class="line">        <span class="built_in">print</span> pr, fc_params[pr][<span class="number">0</span>].shape, fc_params[pr][<span class="number">1</span>].shape</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> pr <span class="keyword">in</span> params_full_conv:</span><br><span class="line">        <span class="built_in">print</span> pr, conv_params[pr][<span class="number">0</span>].shape, conv_params[pr][<span class="number">1</span>].shape</span><br><span class="line">    </span><br><span class="line">    pr = <span class="string">&#x27;fc6-conv&#x27;</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;params value for &#x27;</span>,pr</span><br><span class="line">    <span class="built_in">print</span> net_full_conv.params[pr][<span class="number">0</span>].data[<span class="number">0</span>,<span class="number">0</span>,:,:] </span><br><span class="line">    <span class="built_in">print</span> net_full_conv.params[pr][<span class="number">1</span>].data[<span class="number">0</span>] </span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;*&#x27;</span>*<span class="number">50</span></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;(1) before updated by fc&#x27;</span></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;*&#x27;</span>*<span class="number">50</span></span><br><span class="line">print_params()</span><br><span class="line"></span><br><span class="line"><span class="comment">#print type(conv_params[pr_conv][0]) # ndarray  ndarray.flat</span></span><br><span class="line"><span class="comment">#conv_params[pr_conv][0].flat = fc_params[pr][0].flat</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># set w6,w7,w8 of conv from fc w6,w7,w8</span></span><br><span class="line"><span class="keyword">for</span> pr, pr_conv <span class="keyword">in</span> <span class="built_in">zip</span>(params, params_full_conv):</span><br><span class="line">    conv_params[pr_conv][<span class="number">0</span>].flat = fc_params[pr][<span class="number">0</span>].flat  <span class="comment"># flat unrolls the arrays</span></span><br><span class="line">    conv_params[pr_conv][<span class="number">1</span>][...] = fc_params[pr][<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">print_conv_params = <span class="literal">True</span></span><br><span class="line">print_conv_params = <span class="literal">False</span></span><br><span class="line"><span class="keyword">if</span> print_conv_params:</span><br><span class="line">    pr = <span class="string">&#x27;fc6&#x27;</span></span><br><span class="line">    <span class="built_in">print</span> net.params[pr][<span class="number">0</span>].data[<span class="number">0</span>,:<span class="number">6</span>*<span class="number">6</span>]  <span class="comment"># no weight_filler,loaded from weights file  </span></span><br><span class="line">    <span class="built_in">print</span> net.params[pr][<span class="number">1</span>].data[<span class="number">0</span>]       <span class="comment"># no bias_filler,loaded from weights file  </span></span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span> </span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;after init from fc&#x27;</span></span><br><span class="line">    pr = <span class="string">&#x27;fc6-conv&#x27;</span></span><br><span class="line">    <span class="built_in">print</span> net_full_conv.params[pr][<span class="number">0</span>].data[<span class="number">0</span>,<span class="number">0</span>,:,:] <span class="comment"># no weight_filler,default to 0s, here updated by fc</span></span><br><span class="line">    <span class="built_in">print</span> net_full_conv.params[pr][<span class="number">1</span>].data[<span class="number">0</span>]      <span class="comment"># no bias_filler,default to 0s , here updated by fc</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;*&#x27;</span>*<span class="number">50</span></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;(2) after updated by  fc&#x27;</span></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;*&#x27;</span>*<span class="number">50</span></span><br><span class="line">print_params()</span><br></pre></td></tr></table></figure>

<pre><code>**************************************************
(1) before updated by fc
**************************************************
fc6 (4096, 9216) (4096,)
fc7 (4096, 4096) (4096,)
fc8 (1000, 4096) (1000,)
fc6-conv (4096, 256, 6, 6) (4096,)
fc7-conv (4096, 4096, 1, 1) (4096,)
fc8-conv (1000, 4096, 1, 1) (1000,)
params value for  fc6-conv
[[ 0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.]
 [ 0.  0.  0.  0.  0.  0.]]
0.0
**************************************************
(2) after updated by  fc
**************************************************
fc6 (4096, 9216) (4096,)
fc7 (4096, 4096) (4096,)
fc8 (1000, 4096) (1000,)
fc6-conv (4096, 256, 6, 6) (4096,)
fc7-conv (4096, 4096, 1, 1) (4096,)
fc8-conv (1000, 4096, 1, 1) (1000,)
params value for  fc6-conv
[[ 0.00639847  0.00915686  0.00467043  0.00118941  0.00083305  0.00249258]
 [ 0.00249609 -0.00354958 -0.00502381 -0.00660044 -0.00810635 -0.00120969]
 [-0.00182751 -0.00181385 -0.00327348 -0.00657627 -0.01059825 -0.00223066]
 [ 0.00023664  0.00040984 -0.00052619 -0.00124062 -0.00269398 -0.00051081]
 [ 0.0014997   0.00123309 -0.00013806 -0.00111619  0.00321043  0.00284487]
 [ 0.00051387 -0.00087142 -0.00038937 -0.0008678   0.0049024   0.00155215]]
0.983698
</code></pre>
<p>Next, save the new model weights.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net_full_conv.save(<span class="string">&#x27;net_surgery/bvlc_caffenet_full_conv.caffemodel&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>To conclude, let’s make a classification map from the example cat image and visualize the confidence of “tiger cat” as a probability heatmap. This gives an 8-by-8 prediction on overlapping regions of the 451 $\times$ 451 input.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># load input and configure preprocessing</span></span><br><span class="line">im = caffe.io.load_image(<span class="string">&#x27;images/cat.jpg&#x27;</span>)</span><br><span class="line">transformer = caffe.io.Transformer(&#123;<span class="string">&#x27;data&#x27;</span>: net_full_conv.blobs[<span class="string">&#x27;data&#x27;</span>].data.shape&#125;) <span class="comment"># (1,3,451,451)</span></span><br><span class="line">transformer.set_mean(<span class="string">&#x27;data&#x27;</span>, np.load(<span class="string">&#x27;../python/caffe/imagenet/ilsvrc_2012_mean.npy&#x27;</span>).mean(<span class="number">1</span>).mean(<span class="number">1</span>))</span><br><span class="line">transformer.set_transpose(<span class="string">&#x27;data&#x27;</span>, (<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>))</span><br><span class="line">transformer.set_channel_swap(<span class="string">&#x27;data&#x27;</span>, (<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>))</span><br><span class="line">transformer.set_raw_scale(<span class="string">&#x27;data&#x27;</span>, <span class="number">255.0</span>)</span><br><span class="line"></span><br><span class="line">transformed_image = transformer.preprocess(<span class="string">&#x27;data&#x27;</span>, im)</span><br><span class="line"><span class="comment">#print transformed_image.shape #(3, 451, 451)</span></span><br><span class="line">net_full_conv.blobs[<span class="string">&#x27;data&#x27;</span>].data[...] = transformed_image <span class="comment"># (1, 3, 451, 451)</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#out = net_full_conv.forward_all(data=np.asarray([transformer.preprocess(&#x27;data&#x27;, im)]))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># make classification map by forward and print prediction indices at each location</span></span><br><span class="line">out = net_full_conv.forward()</span><br><span class="line">prob = out[<span class="string">&#x27;prob&#x27;</span>][<span class="number">0</span>] <span class="comment"># (1, 1000, 8, 8)--&gt;(1000, 8, 8)</span></span><br><span class="line">classification_map = out[<span class="string">&#x27;prob&#x27;</span>][<span class="number">0</span>].argmax(axis=<span class="number">0</span>) </span><br><span class="line"><span class="built_in">print</span> classification_map <span class="comment"># (8,8)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># show net input and confidence map (probability of the top prediction at each location)</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.imshow(transformer.deprocess(<span class="string">&#x27;data&#x27;</span>, net_full_conv.blobs[<span class="string">&#x27;data&#x27;</span>].data[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.imshow(out[<span class="string">&#x27;prob&#x27;</span>][<span class="number">0</span>,<span class="number">281</span>]) <span class="comment"># correct class = 281</span></span><br><span class="line">plt.colorbar()</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br></pre></td></tr></table></figure>

<pre><code>[[282 282 281 281 281 281 277 282]
 [281 283 283 281 281 281 281 282]
 [283 283 283 283 283 283 287 282]
 [283 283 283 281 283 283 283 259]
 [283 283 283 283 283 283 283 259]
 [283 283 283 283 283 283 259 259]
 [283 283 283 283 259 259 259 277]
 [335 335 283 259 263 263 263 277]]
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180816095105836-233219882.png" alt="png"></p>
<p>The classifications include various cats – 282 &#x3D; tiger cat, 281 &#x3D; tabby, 283 &#x3D; persian – and foxes and other mammals.</p>
<p>In this way the fully connected layers can be extracted as dense features across an image (see <code>net_full_conv.blobs[&#39;fc6&#39;].data</code> for instance), which is perhaps more useful than the classification map itself.</p>
<p>Note that this model isn’t totally appropriate for sliding-window detection since it was trained for whole-image classification. Nevertheless it can work just fine. Sliding-window training and finetuning can be done by defining a sliding-window ground truth and loss such that a loss map is made for every location and solving as usual. (This is an exercise for the reader.)</p>
<p><em>A thank you to Rowland Depp for first suggesting this trick.</em></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net_full_conv.blobs[<span class="string">&#x27;fc6-conv&#x27;</span>].data[<span class="number">0</span>,<span class="number">176</span>,:,:] <span class="comment"># (1, 4096, 8, 8)</span></span><br></pre></td></tr></table></figure>




<pre><code>array([[  0.        ,   3.78561878,   4.91759014,  11.89788914,
         14.29053116,  16.50216484,   3.7467947 ,   0.        ],
       [  0.        ,  17.67206573,  25.0014534 ,  39.59349442,
         39.08831787,  29.11470604,   9.98679352,   0.        ],
       [  1.67216611,  18.15454102,  24.08405876,  39.18917847,
         37.54191971,  15.41128445,   0.        ,   0.        ],
       [  0.        ,   3.00706673,   5.87482309,  15.25675011,
         12.55344582,   0.        ,   0.        ,   0.        ],
       [  0.        ,   0.        ,   0.        ,   0.        ,
          1.        ,   0.        ,   0.        ,   0.        ],
       [  0.        ,   0.        ,   0.        ,   0.        ,
          1.        ,   0.        ,   0.        ,   0.        ],
       [  0.        ,   0.        ,   0.        ,   0.        ,
          1.        ,   0.        ,   0.        ,   0.        ],
       [  0.        ,   0.        ,   0.        ,   0.        ,
          1.        ,   0.        ,   0.        ,   0.        ]], dtype=float32)
</code></pre>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="http://demo.vislab.berkeleyvision.org/">demo</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/BVLC/caffe">caffe git</a></li>
</ul>
<h2 id="History"><a href="#History" class="headerlink" title="History"></a>History</h2><ul>
<li>20180816: created.</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://kezunlin.me/blog/Fine-tuning-a-Pretrained-Network-for-Style-Recognition/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="kezunlin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kezunlin's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/Fine-tuning-a-Pretrained-Network-for-Style-Recognition/" class="post-title-link" itemprop="url">Fine-tuning a Pretrained Network for Style Recognition</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-08-08 10:18:00" itemprop="dateCreated datePublished" datetime="2018-08-08T10:18:00+08:00">2018-08-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-10-14 13:39:28" itemprop="dateModified" datetime="2024-10-14T13:39:28+08:00">2024-10-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Tutorial"><a href="#Tutorial" class="headerlink" title="Tutorial"></a>Tutorial</h2><p>In this example, we’ll explore a common approach that is particularly useful in real-world applications: take a pre-trained Caffe network and fine-tune the parameters on your custom data.</p>
<p>The advantage of this approach is that, since pre-trained networks are learned on a large set of images, the intermediate layers capture the “semantics” of the general visual appearance. Think of it as a very powerful generic visual feature that you can treat as a black box. On top of that, only a relatively small amount of data is needed for good performance on the target task.</p>
<p>First, we will need to prepare the data. This involves the following parts:<br>(1) Get the ImageNet ilsvrc pretrained model with the provided shell scripts.<br>(2) Download a subset of the overall Flickr style dataset for this demo.<br>(3) Compile the downloaded Flickr dataset into a database that Caffe can then consume.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">caffe_root = <span class="string">&#x27;../&#x27;</span>  <span class="comment"># this file should be run from &#123;caffe_root&#125;/examples (otherwise change this line)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.insert(<span class="number">0</span>, caffe_root + <span class="string">&#x27;python&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> caffe</span><br><span class="line"></span><br><span class="line">caffe.set_device(<span class="number">0</span>)</span><br><span class="line">caffe.set_mode_gpu()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> *</span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> tempfile</span><br><span class="line"></span><br><span class="line"><span class="comment"># Helper function for deprocessing preprocessed images, e.g., for display.</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">deprocess_net_image</span>(<span class="params">image</span>):</span><br><span class="line">    image = image.copy()              <span class="comment"># don&#x27;t modify destructively</span></span><br><span class="line">    image = image[::-<span class="number">1</span>]               <span class="comment"># BGR -&gt; RGB</span></span><br><span class="line">    image = image.transpose(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>)  <span class="comment"># CHW -&gt; HWC</span></span><br><span class="line">    image += [<span class="number">123</span>, <span class="number">117</span>, <span class="number">104</span>]          <span class="comment"># (approximately) undo mean subtraction</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># clamp values in [0, 255]</span></span><br><span class="line">    image[image &lt; <span class="number">0</span>], image[image &gt; <span class="number">255</span>] = <span class="number">0</span>, <span class="number">255</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># round and cast from float32 to uint8</span></span><br><span class="line">    image = np.<span class="built_in">round</span>(image)</span><br><span class="line">    image = np.require(image, dtype=np.uint8)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> image</span><br></pre></td></tr></table></figure>

<h3 id="Setup-and-dataset-download"><a href="#Setup-and-dataset-download" class="headerlink" title="Setup and dataset download"></a>Setup and dataset download</h3><p>Download data required for this exercise.</p>
<ul>
<li><code>get_ilsvrc_aux.sh</code> to download the ImageNet data mean, labels, etc.</li>
<li><code>download_model_binary.py</code> to download the pretrained reference model</li>
<li><code>finetune_flickr_style/assemble_data.py</code> downloads the style training and testing data</li>
</ul>
<p>We’ll download just a small subset of the full dataset for this exercise: just 2000 of the 80K images, from 5 of the 20 style categories.  (To download the full dataset, set <code>full_dataset = True</code> in the cell below.)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Download just a small subset of the data for this exercise.</span></span><br><span class="line"><span class="comment"># (2000 of 80K images, 5 of 20 labels.)</span></span><br><span class="line"><span class="comment"># To download the entire dataset, set `full_dataset = True`.</span></span><br><span class="line">full_dataset = <span class="literal">False</span></span><br><span class="line"><span class="keyword">if</span> full_dataset:</span><br><span class="line">    NUM_STYLE_IMAGES = NUM_STYLE_LABELS = -<span class="number">1</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    NUM_STYLE_IMAGES = <span class="number">2000</span></span><br><span class="line">    NUM_STYLE_LABELS = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># This downloads the ilsvrc auxiliary data (mean file, etc),</span></span><br><span class="line"><span class="comment"># and a subset of 2000 images for the style recognition task.</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.chdir(caffe_root)  <span class="comment"># run scripts from caffe root</span></span><br><span class="line">!data/ilsvrc12/get_ilsvrc_aux.sh</span><br><span class="line">!scripts/download_model_binary.py models/bvlc_reference_caffenet</span><br><span class="line">!python examples/finetune_flickr_style/assemble_data.py \</span><br><span class="line">    --workers=-<span class="number">1</span>  --seed=<span class="number">1701</span> \</span><br><span class="line">    --images=$NUM_STYLE_IMAGES  --label=$NUM_STYLE_LABELS</span><br><span class="line"><span class="comment"># back to examples</span></span><br><span class="line">os.chdir(<span class="string">&#x27;examples&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Downloading...
--2016-02-24 00:28:36--  http://dl.caffe.berkeleyvision.org/caffe_ilsvrc12.tar.gz
Resolving dl.caffe.berkeleyvision.org (dl.caffe.berkeleyvision.org)... 169.229.222.251
Connecting to dl.caffe.berkeleyvision.org (dl.caffe.berkeleyvision.org)|169.229.222.251|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 17858008 (17M) [application/octet-stream]
Saving to: ‘caffe_ilsvrc12.tar.gz’

100%[======================================&gt;] 17,858,008   112MB/s   in 0.2s   

2016-02-24 00:28:36 (112 MB/s) - ‘caffe_ilsvrc12.tar.gz’ saved [17858008/17858008]

Unzipping...
Done.
Model already exists.
Downloading 2000 images with 7 workers...
Writing train/val for 1996 successfully downloaded images.
</code></pre>
<p>Define <code>weights</code>, the path to the ImageNet pretrained weights we just downloaded, and make sure it exists.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">weights = os.path.join(caffe_root, <span class="string">&#x27;models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel&#x27;</span>)</span><br><span class="line"><span class="keyword">assert</span> os.path.exists(weights)</span><br></pre></td></tr></table></figure>

<p>Load the 1000 ImageNet labels from <code>ilsvrc12/synset_words.txt</code>, and the 5 style labels from <code>finetune_flickr_style/style_names.txt</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Load ImageNet labels to imagenet_labels</span></span><br><span class="line">imagenet_label_file = caffe_root + <span class="string">&#x27;data/ilsvrc12/synset_words.txt&#x27;</span></span><br><span class="line">imagenet_labels = <span class="built_in">list</span>(np.loadtxt(imagenet_label_file, <span class="built_in">str</span>, delimiter=<span class="string">&#x27;\t&#x27;</span>))</span><br><span class="line"><span class="keyword">assert</span> <span class="built_in">len</span>(imagenet_labels) == <span class="number">1000</span></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Loaded ImageNet labels:\n&#x27;</span>, <span class="string">&#x27;\n&#x27;</span>.join(imagenet_labels[:<span class="number">10</span>] + [<span class="string">&#x27;...&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load style labels to style_labels</span></span><br><span class="line">style_label_file = caffe_root + <span class="string">&#x27;examples/finetune_flickr_style/style_names.txt&#x27;</span></span><br><span class="line">style_labels = <span class="built_in">list</span>(np.loadtxt(style_label_file, <span class="built_in">str</span>, delimiter=<span class="string">&#x27;\n&#x27;</span>))</span><br><span class="line"><span class="keyword">if</span> NUM_STYLE_LABELS &gt; <span class="number">0</span>:</span><br><span class="line">    style_labels = style_labels[:NUM_STYLE_LABELS]</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;\nLoaded style labels:\n&#x27;</span>, <span class="string">&#x27;, &#x27;</span>.join(style_labels)</span><br></pre></td></tr></table></figure>

<pre><code>Loaded ImageNet labels:
n01440764 tench, Tinca tinca
n01443537 goldfish, Carassius auratus
n01484850 great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias
n01491361 tiger shark, Galeocerdo cuvieri
n01494475 hammerhead, hammerhead shark
n01496331 electric ray, crampfish, numbfish, torpedo
n01498041 stingray
n01514668 cock
n01514859 hen
n01518878 ostrich, Struthio camelus
...

Loaded style labels:
Detailed, Pastel, Melancholy, Noir, HDR
</code></pre>
<h3 id="Defining-and-running-the-nets"><a href="#Defining-and-running-the-nets" class="headerlink" title="Defining and running the nets"></a>Defining and running the nets</h3><p>We’ll start by defining <code>caffenet</code>, a function which initializes the <em>CaffeNet</em> architecture (a minor variant on <em>AlexNet</em>), taking arguments specifying the data and number of output classes.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> caffe <span class="keyword">import</span> layers <span class="keyword">as</span> L</span><br><span class="line"><span class="keyword">from</span> caffe <span class="keyword">import</span> params <span class="keyword">as</span> P</span><br><span class="line"></span><br><span class="line">weight_param = <span class="built_in">dict</span>(lr_mult=<span class="number">1</span>, decay_mult=<span class="number">1</span>)</span><br><span class="line">bias_param   = <span class="built_in">dict</span>(lr_mult=<span class="number">2</span>, decay_mult=<span class="number">0</span>)</span><br><span class="line">learned_param = [weight_param, bias_param]</span><br><span class="line"></span><br><span class="line">frozen_param = [<span class="built_in">dict</span>(lr_mult=<span class="number">0</span>)] * <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">conv_relu</span>(<span class="params">bottom, ks, nout, stride=<span class="number">1</span>, pad=<span class="number">0</span>, group=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">              param=learned_param,</span></span><br><span class="line"><span class="params">              weight_filler=<span class="built_in">dict</span>(<span class="params"><span class="built_in">type</span>=<span class="string">&#x27;gaussian&#x27;</span>, std=<span class="number">0.01</span></span>),</span></span><br><span class="line"><span class="params">              bias_filler=<span class="built_in">dict</span>(<span class="params"><span class="built_in">type</span>=<span class="string">&#x27;constant&#x27;</span>, value=<span class="number">0.1</span></span>)</span>):</span><br><span class="line">    conv = L.Convolution(bottom, kernel_size=ks, stride=stride,</span><br><span class="line">                         num_output=nout, pad=pad, group=group,</span><br><span class="line">                         param=param, weight_filler=weight_filler,</span><br><span class="line">                         bias_filler=bias_filler)</span><br><span class="line">    <span class="keyword">return</span> conv, L.ReLU(conv, in_place=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fc_relu</span>(<span class="params">bottom, nout, param=learned_param,</span></span><br><span class="line"><span class="params">            weight_filler=<span class="built_in">dict</span>(<span class="params"><span class="built_in">type</span>=<span class="string">&#x27;gaussian&#x27;</span>, std=<span class="number">0.005</span></span>),</span></span><br><span class="line"><span class="params">            bias_filler=<span class="built_in">dict</span>(<span class="params"><span class="built_in">type</span>=<span class="string">&#x27;constant&#x27;</span>, value=<span class="number">0.1</span></span>)</span>):</span><br><span class="line">    fc = L.InnerProduct(bottom, num_output=nout, param=param,</span><br><span class="line">                        weight_filler=weight_filler,</span><br><span class="line">                        bias_filler=bias_filler)</span><br><span class="line">    <span class="keyword">return</span> fc, L.ReLU(fc, in_place=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">max_pool</span>(<span class="params">bottom, ks, stride=<span class="number">1</span></span>):</span><br><span class="line">    <span class="keyword">return</span> L.Pooling(bottom, pool=P.Pooling.MAX, kernel_size=ks, stride=stride)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">caffenet</span>(<span class="params">data, label=<span class="literal">None</span>, train=<span class="literal">True</span>, num_classes=<span class="number">1000</span>,</span></span><br><span class="line"><span class="params">             classifier_name=<span class="string">&#x27;fc8&#x27;</span>, learn_all=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Returns a NetSpec specifying CaffeNet, following the original proto text</span></span><br><span class="line"><span class="string">       specification (./models/bvlc_reference_caffenet/train_val.prototxt).&quot;&quot;&quot;</span></span><br><span class="line">    n = caffe.NetSpec()</span><br><span class="line">    n.data = data</span><br><span class="line">    param = learned_param <span class="keyword">if</span> learn_all <span class="keyword">else</span> frozen_param</span><br><span class="line">    n.conv1, n.relu1 = conv_relu(n.data, <span class="number">11</span>, <span class="number">96</span>, stride=<span class="number">4</span>, param=param)</span><br><span class="line">    n.pool1 = max_pool(n.relu1, <span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line">    n.norm1 = L.LRN(n.pool1, local_size=<span class="number">5</span>, alpha=<span class="number">1e-4</span>, beta=<span class="number">0.75</span>)</span><br><span class="line">    n.conv2, n.relu2 = conv_relu(n.norm1, <span class="number">5</span>, <span class="number">256</span>, pad=<span class="number">2</span>, group=<span class="number">2</span>, param=param)</span><br><span class="line">    n.pool2 = max_pool(n.relu2, <span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line">    n.norm2 = L.LRN(n.pool2, local_size=<span class="number">5</span>, alpha=<span class="number">1e-4</span>, beta=<span class="number">0.75</span>)</span><br><span class="line">    n.conv3, n.relu3 = conv_relu(n.norm2, <span class="number">3</span>, <span class="number">384</span>, pad=<span class="number">1</span>, param=param)</span><br><span class="line">    n.conv4, n.relu4 = conv_relu(n.relu3, <span class="number">3</span>, <span class="number">384</span>, pad=<span class="number">1</span>, group=<span class="number">2</span>, param=param)</span><br><span class="line">    n.conv5, n.relu5 = conv_relu(n.relu4, <span class="number">3</span>, <span class="number">256</span>, pad=<span class="number">1</span>, group=<span class="number">2</span>, param=param)</span><br><span class="line">    n.pool5 = max_pool(n.relu5, <span class="number">3</span>, stride=<span class="number">2</span>)</span><br><span class="line">    n.fc6, n.relu6 = fc_relu(n.pool5, <span class="number">4096</span>, param=param)</span><br><span class="line">    <span class="keyword">if</span> train:</span><br><span class="line">        n.drop6 = fc7input = L.Dropout(n.relu6, in_place=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        fc7input = n.relu6</span><br><span class="line">    n.fc7, n.relu7 = fc_relu(fc7input, <span class="number">4096</span>, param=param)</span><br><span class="line">    <span class="keyword">if</span> train:</span><br><span class="line">        n.drop7 = fc8input = L.Dropout(n.relu7, in_place=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        fc8input = n.relu7</span><br><span class="line">    <span class="comment"># always learn fc8 (param=learned_param)</span></span><br><span class="line">    fc8 = L.InnerProduct(fc8input, num_output=num_classes, param=learned_param)</span><br><span class="line">    <span class="comment"># give fc8 the name specified by argument `classifier_name`</span></span><br><span class="line">    n.__setattr__(classifier_name, fc8)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> train:</span><br><span class="line">        n.probs = L.Softmax(fc8)</span><br><span class="line">    <span class="keyword">if</span> label <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        n.label = label</span><br><span class="line">        n.loss = L.SoftmaxWithLoss(fc8, n.label)</span><br><span class="line">        n.acc = L.Accuracy(fc8, n.label)</span><br><span class="line">    <span class="comment"># write the net to a temporary file and return its filename</span></span><br><span class="line">    <span class="keyword">with</span> tempfile.NamedTemporaryFile(delete=<span class="literal">False</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(<span class="built_in">str</span>(n.to_proto()))</span><br><span class="line">        <span class="keyword">return</span> f.name</span><br></pre></td></tr></table></figure>

<p>Now, let’s create a <em>CaffeNet</em> that takes unlabeled “dummy data” as input, allowing us to set its input images externally and see what ImageNet classes it predicts.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dummy_data = L.DummyData(shape=<span class="built_in">dict</span>(dim=[<span class="number">1</span>, <span class="number">3</span>, <span class="number">227</span>, <span class="number">227</span>]))</span><br><span class="line">imagenet_net_filename = caffenet(data=dummy_data, train=<span class="literal">False</span>)</span><br><span class="line">imagenet_net = caffe.Net(imagenet_net_filename, weights, caffe.TEST)</span><br></pre></td></tr></table></figure>

<p>Define a function <code>style_net</code> which calls <code>caffenet</code> on data from the Flickr style dataset.</p>
<p>The new network will also have the <em>CaffeNet</em> architecture, with differences in the input and output:</p>
<ul>
<li>the input is the Flickr style data we downloaded, provided by an <code>ImageData</code> layer</li>
<li>the output is a distribution over 20 classes rather than the original 1000 ImageNet classes</li>
<li>the classification layer is renamed from <code>fc8</code> to <code>fc8_flickr</code> to tell Caffe not to load the original classifier (<code>fc8</code>) weights from the ImageNet-pretrained model</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">style_net</span>(<span class="params">train=<span class="literal">True</span>, learn_all=<span class="literal">False</span>, subset=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="keyword">if</span> subset <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        subset = <span class="string">&#x27;train&#x27;</span> <span class="keyword">if</span> train <span class="keyword">else</span> <span class="string">&#x27;test&#x27;</span></span><br><span class="line">    source = caffe_root + <span class="string">&#x27;data/flickr_style/%s.txt&#x27;</span> % subset</span><br><span class="line">    transform_param = <span class="built_in">dict</span>(mirror=train, crop_size=<span class="number">227</span>,</span><br><span class="line">        mean_file=caffe_root + <span class="string">&#x27;data/ilsvrc12/imagenet_mean.binaryproto&#x27;</span>)</span><br><span class="line">    style_data, style_label = L.ImageData(</span><br><span class="line">        transform_param=transform_param, source=source,</span><br><span class="line">        batch_size=<span class="number">50</span>, new_height=<span class="number">256</span>, new_width=<span class="number">256</span>, ntop=<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> caffenet(data=style_data, label=style_label, train=train,</span><br><span class="line">                    num_classes=NUM_STYLE_LABELS,</span><br><span class="line">                    classifier_name=<span class="string">&#x27;fc8_flickr&#x27;</span>,</span><br><span class="line">                    learn_all=learn_all)</span><br></pre></td></tr></table></figure>

<p>Use the <code>style_net</code> function defined above to initialize <code>untrained_style_net</code>, a <em>CaffeNet</em> with input images from the style dataset and weights from the pretrained ImageNet model.</p>
<p>Call <code>forward</code> on <code>untrained_style_net</code> to get a batch of style training data.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">untrained_style_net = caffe.Net(style_net(train=<span class="literal">False</span>, subset=<span class="string">&#x27;train&#x27;</span>),</span><br><span class="line">                                weights, caffe.TEST)</span><br><span class="line">untrained_style_net.forward()</span><br><span class="line">style_data_batch = untrained_style_net.blobs[<span class="string">&#x27;data&#x27;</span>].data.copy()</span><br><span class="line">style_label_batch = np.array(untrained_style_net.blobs[<span class="string">&#x27;label&#x27;</span>].data, dtype=np.int32)</span><br></pre></td></tr></table></figure>

<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- kzl in-article ad -->
<p><ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5653382914441020"
     data-ad-slot="7925631830"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<p>Pick one of the style net training images from the batch of 50 (we’ll arbitrarily choose #8 here).  Display it, then run it through <code>imagenet_net</code>, the ImageNet-pretrained network to view its top 5 predicted classes from the 1000 ImageNet classes.</p>
<p>Below we chose an image where the network’s predictions happen to be reasonable, as the image is of a beach, and “sandbar” and “seashore” both happen to be ImageNet-1000 categories.  For other images, the predictions won’t be this good, sometimes due to the network actually failing to recognize the object(s) present in the image, but perhaps even more often due to the fact that not all images contain an object from the (somewhat arbitrarily chosen) 1000 ImageNet categories. Modify the <code>batch_index</code> variable by changing its default setting of 8 to another value from 0-49 (since the batch size is 50) to see predictions for other images in the batch.  (To go beyond this batch of 50 images, first rerun the <em>above</em> cell to load a fresh batch of data into <code>style_net</code>.)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">disp_preds</span>(<span class="params">net, image, labels, k=<span class="number">5</span>, name=<span class="string">&#x27;ImageNet&#x27;</span></span>):</span><br><span class="line">    input_blob = net.blobs[<span class="string">&#x27;data&#x27;</span>]</span><br><span class="line">    net.blobs[<span class="string">&#x27;data&#x27;</span>].data[<span class="number">0</span>, ...] = image</span><br><span class="line">    probs = net.forward(start=<span class="string">&#x27;conv1&#x27;</span>)[<span class="string">&#x27;probs&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">    top_k = (-probs).argsort()[:k]</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;top %d predicted %s labels =&#x27;</span> % (k, name)</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;\n&#x27;</span>.join(<span class="string">&#x27;\t(%d) %5.2f%% %s&#x27;</span> % (i+<span class="number">1</span>, <span class="number">100</span>*probs[p], labels[p])</span><br><span class="line">                    <span class="keyword">for</span> i, p <span class="keyword">in</span> <span class="built_in">enumerate</span>(top_k))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">disp_imagenet_preds</span>(<span class="params">net, image</span>):</span><br><span class="line">    disp_preds(net, image, imagenet_labels, name=<span class="string">&#x27;ImageNet&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">disp_style_preds</span>(<span class="params">net, image</span>):</span><br><span class="line">    disp_preds(net, image, style_labels, name=<span class="string">&#x27;style&#x27;</span>)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">batch_index = <span class="number">8</span></span><br><span class="line">image = style_data_batch[batch_index]</span><br><span class="line">plt.imshow(deprocess_net_image(image))</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;actual label =&#x27;</span>, style_labels[style_label_batch[batch_index]]</span><br></pre></td></tr></table></figure>

<pre><code>actual label = Melancholy
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180808102003231-729149953.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">disp_imagenet_preds(imagenet_net, image)</span><br></pre></td></tr></table></figure>

<pre><code>top 5 predicted ImageNet labels =
    (1) 69.89% n09421951 sandbar, sand bar
    (2) 21.76% n09428293 seashore, coast, seacoast, sea-coast
    (3)  3.22% n02894605 breakwater, groin, groyne, mole, bulwark, seawall, jetty
    (4)  1.89% n04592741 wing
    (5)  1.23% n09332890 lakeside, lakeshore
</code></pre>
<p>We can also look at <code>untrained_style_net</code>‘s predictions, but we won’t see anything interesting as its classifier hasn’t been trained yet.</p>
<p>In fact, since we zero-initialized the classifier (see <code>caffenet</code> definition – no <code>weight_filler</code> is passed to the final <code>InnerProduct</code> layer), the softmax inputs should be all zero and we should therefore see a predicted probability of 1&#x2F;N for each label (for N labels).  Since we set N &#x3D; 5, we get a predicted probability of 20% for each class.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">disp_style_preds(untrained_style_net, image)</span><br></pre></td></tr></table></figure>

<pre><code>top 5 predicted style labels =
    (1) 20.00% Detailed
    (2) 20.00% Pastel
    (3) 20.00% Melancholy
    (4) 20.00% Noir
    (5) 20.00% HDR
</code></pre>
<p>We can also verify that the activations in layer <code>fc7</code> immediately before the classification layer are the same as (or very close to) those in the ImageNet-pretrained model, since both models are using the same pretrained weights in the <code>conv1</code> through <code>fc7</code> layers.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">diff = untrained_style_net.blobs[<span class="string">&#x27;fc7&#x27;</span>].data[<span class="number">0</span>] - imagenet_net.blobs[<span class="string">&#x27;fc7&#x27;</span>].data[<span class="number">0</span>]</span><br><span class="line">error = (diff ** <span class="number">2</span>).<span class="built_in">sum</span>()</span><br><span class="line"><span class="keyword">assert</span> error &lt; <span class="number">1e-8</span></span><br></pre></td></tr></table></figure>

<p>Delete <code>untrained_style_net</code> to save memory.  (Hang on to <code>imagenet_net</code> as we’ll use it again later.)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">del</span> untrained_style_net</span><br></pre></td></tr></table></figure>

<h3 id="Training-the-style-classifier"><a href="#Training-the-style-classifier" class="headerlink" title="Training the style classifier"></a>Training the style classifier</h3><p>Now, we’ll define a function <code>solver</code> to create our Caffe solvers, which are used to train the network (learn its weights).  In this function we’ll set values for various parameters used for learning, display, and “snapshotting” – see the inline comments for explanations of what they mean.  You may want to play with some of the learning parameters to see if you can improve on the results here!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> caffe.proto <span class="keyword">import</span> caffe_pb2</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">solver</span>(<span class="params">train_net_path, test_net_path=<span class="literal">None</span>, base_lr=<span class="number">0.001</span></span>):</span><br><span class="line">    s = caffe_pb2.SolverParameter()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Specify locations of the train and (maybe) test networks.</span></span><br><span class="line">    s.train_net = train_net_path</span><br><span class="line">    <span class="keyword">if</span> test_net_path <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        s.test_net.append(test_net_path)</span><br><span class="line">        s.test_interval = <span class="number">1000</span>  <span class="comment"># Test after every 1000 training iterations.</span></span><br><span class="line">        s.test_iter.append(<span class="number">100</span>) <span class="comment"># Test on 100 batches each time we test.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># The number of iterations over which to average the gradient.</span></span><br><span class="line">    <span class="comment"># Effectively boosts the training batch size by the given factor, without</span></span><br><span class="line">    <span class="comment"># affecting memory utilization.</span></span><br><span class="line">    s.iter_size = <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    s.max_iter = <span class="number">100000</span>     <span class="comment"># # of times to update the net (training iterations)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Solve using the stochastic gradient descent (SGD) algorithm.</span></span><br><span class="line">    <span class="comment"># Other choices include &#x27;Adam&#x27; and &#x27;RMSProp&#x27;.</span></span><br><span class="line">    s.<span class="built_in">type</span> = <span class="string">&#x27;SGD&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set the initial learning rate for SGD.</span></span><br><span class="line">    s.base_lr = base_lr</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set `lr_policy` to define how the learning rate changes during training.</span></span><br><span class="line">    <span class="comment"># Here, we &#x27;step&#x27; the learning rate by multiplying it by a factor `gamma`</span></span><br><span class="line">    <span class="comment"># every `stepsize` iterations.</span></span><br><span class="line">    s.lr_policy = <span class="string">&#x27;step&#x27;</span></span><br><span class="line">    s.gamma = <span class="number">0.1</span></span><br><span class="line">    s.stepsize = <span class="number">20000</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Set other SGD hyperparameters. Setting a non-zero `momentum` takes a</span></span><br><span class="line">    <span class="comment"># weighted average of the current gradient and previous gradients to make</span></span><br><span class="line">    <span class="comment"># learning more stable. L2 weight decay regularizes learning, to help prevent</span></span><br><span class="line">    <span class="comment"># the model from overfitting.</span></span><br><span class="line">    s.momentum = <span class="number">0.9</span></span><br><span class="line">    s.weight_decay = <span class="number">5e-4</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Display the current training loss and accuracy every 1000 iterations.</span></span><br><span class="line">    s.display = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Snapshots are files used to store networks we&#x27;ve trained.  Here, we&#x27;ll</span></span><br><span class="line">    <span class="comment"># snapshot every 10K iterations -- ten times during training.</span></span><br><span class="line">    s.snapshot = <span class="number">10000</span></span><br><span class="line">    s.snapshot_prefix = caffe_root + <span class="string">&#x27;models/finetune_flickr_style/finetune_flickr_style&#x27;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Train on the GPU.  Using the CPU to train large networks is very slow.</span></span><br><span class="line">    s.solver_mode = caffe_pb2.SolverParameter.GPU</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Write the solver to a temporary file and return its filename.</span></span><br><span class="line">    <span class="keyword">with</span> tempfile.NamedTemporaryFile(delete=<span class="literal">False</span>) <span class="keyword">as</span> f:</span><br><span class="line">        f.write(<span class="built_in">str</span>(s))</span><br><span class="line">        <span class="keyword">return</span> f.name</span><br></pre></td></tr></table></figure>

<p>Now we’ll invoke the solver to train the style net’s classification layer.</p>
<p>For the record, if you want to train the network using only the command line tool, this is the command:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">build/tools/caffe train \</span><br><span class="line">-solver models/finetune_flickr_style/solver.prototxt \</span><br><span class="line">-weights models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel \</span><br><span class="line">-gpu 0</span><br></pre></td></tr></table></figure>

<p>However, we will train using Python in this example.</p>
<p>We’ll first define <code>run_solvers</code>, a function that takes a list of solvers and steps each one in a round robin manner, recording the accuracy and loss values each iteration.  At the end, the learned weights are saved to a file.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">run_solvers</span>(<span class="params">niter, solvers, disp_interval=<span class="number">10</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Run solvers for niter iterations,</span></span><br><span class="line"><span class="string">       returning the loss and accuracy recorded each iteration.</span></span><br><span class="line"><span class="string">       `solvers` is a list of (name, solver) tuples.&quot;&quot;&quot;</span></span><br><span class="line">    blobs = (<span class="string">&#x27;loss&#x27;</span>, <span class="string">&#x27;acc&#x27;</span>)</span><br><span class="line">    loss, acc = (&#123;name: np.zeros(niter) <span class="keyword">for</span> name, _ <span class="keyword">in</span> solvers&#125;</span><br><span class="line">                 <span class="keyword">for</span> _ <span class="keyword">in</span> blobs)</span><br><span class="line">    <span class="keyword">for</span> it <span class="keyword">in</span> <span class="built_in">range</span>(niter):</span><br><span class="line">        <span class="keyword">for</span> name, s <span class="keyword">in</span> solvers:</span><br><span class="line">            s.step(<span class="number">1</span>)  <span class="comment"># run a single SGD step in Caffe</span></span><br><span class="line">            loss[name][it], acc[name][it] = (s.net.blobs[b].data.copy()</span><br><span class="line">                                             <span class="keyword">for</span> b <span class="keyword">in</span> blobs)</span><br><span class="line">        <span class="keyword">if</span> it % disp_interval == <span class="number">0</span> <span class="keyword">or</span> it + <span class="number">1</span> == niter:</span><br><span class="line">            loss_disp = <span class="string">&#x27;; &#x27;</span>.join(<span class="string">&#x27;%s: loss=%.3f, acc=%2d%%&#x27;</span> %</span><br><span class="line">                                  (n, loss[n][it], np.<span class="built_in">round</span>(<span class="number">100</span>*acc[n][it]))</span><br><span class="line">                                  <span class="keyword">for</span> n, _ <span class="keyword">in</span> solvers)</span><br><span class="line">            <span class="built_in">print</span> <span class="string">&#x27;%3d) %s&#x27;</span> % (it, loss_disp)     </span><br><span class="line">    <span class="comment"># Save the learned weights from both nets.</span></span><br><span class="line">    weight_dir = tempfile.mkdtemp()</span><br><span class="line">    weights = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> name, s <span class="keyword">in</span> solvers:</span><br><span class="line">        filename = <span class="string">&#x27;weights.%s.caffemodel&#x27;</span> % name</span><br><span class="line">        weights[name] = os.path.join(weight_dir, filename)</span><br><span class="line">        s.net.save(weights[name])</span><br><span class="line">    <span class="keyword">return</span> loss, acc, weights</span><br></pre></td></tr></table></figure>

<p>Let’s create and run solvers to train nets for the style recognition task.  We’ll create two solvers – one (<code>style_solver</code>) will have its train net initialized to the ImageNet-pretrained weights (this is done by the call to the <code>copy_from</code> method), and the other (<code>scratch_style_solver</code>) will start from a <em>randomly</em> initialized net.</p>
<p>During training, we should see that the ImageNet pretrained net is learning faster and attaining better accuracies than the scratch net.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">niter = <span class="number">200</span>  <span class="comment"># number of iterations to train</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Reset style_solver as before.</span></span><br><span class="line">style_solver_filename = solver(style_net(train=<span class="literal">True</span>))</span><br><span class="line">style_solver = caffe.get_solver(style_solver_filename)</span><br><span class="line">style_solver.net.copy_from(weights)</span><br><span class="line"></span><br><span class="line"><span class="comment"># For reference, we also create a solver that isn&#x27;t initialized from</span></span><br><span class="line"><span class="comment"># the pretrained ImageNet weights.</span></span><br><span class="line">scratch_style_solver_filename = solver(style_net(train=<span class="literal">True</span>))</span><br><span class="line">scratch_style_solver = caffe.get_solver(scratch_style_solver_filename)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Running solvers for %d iterations...&#x27;</span> % niter</span><br><span class="line">solvers = [(<span class="string">&#x27;pretrained&#x27;</span>, style_solver),</span><br><span class="line">           (<span class="string">&#x27;scratch&#x27;</span>, scratch_style_solver)]</span><br><span class="line">loss, acc, weights = run_solvers(niter, solvers)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Done.&#x27;</span></span><br><span class="line"></span><br><span class="line">train_loss, scratch_train_loss = loss[<span class="string">&#x27;pretrained&#x27;</span>], loss[<span class="string">&#x27;scratch&#x27;</span>]</span><br><span class="line">train_acc, scratch_train_acc = acc[<span class="string">&#x27;pretrained&#x27;</span>], acc[<span class="string">&#x27;scratch&#x27;</span>]</span><br><span class="line">style_weights, scratch_style_weights = weights[<span class="string">&#x27;pretrained&#x27;</span>], weights[<span class="string">&#x27;scratch&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Delete solvers to save memory.</span></span><br><span class="line"><span class="keyword">del</span> style_solver, scratch_style_solver, solvers</span><br></pre></td></tr></table></figure>

<pre><code>Running solvers for 200 iterations...
  1) pretrained: loss=1.609, acc=28%; scratch: loss=1.609, acc=28%
 1)  pretrained: loss=1.293, acc=52%; scratch: loss=1.626, acc=14%
 2)  pretrained: loss=1.110, acc=56%; scratch: loss=1.646, acc=10%
 3)  pretrained: loss=1.084, acc=60%; scratch: loss=1.616, acc=20%
 4)  pretrained: loss=0.898, acc=64%; scratch: loss=1.588, acc=26%
 5)  pretrained: loss=1.024, acc=54%; scratch: loss=1.607, acc=32%
 6)  pretrained: loss=0.925, acc=66%; scratch: loss=1.616, acc=20%
 7)  pretrained: loss=0.861, acc=74%; scratch: loss=1.598, acc=24%
 8)  pretrained: loss=0.967, acc=60%; scratch: loss=1.588, acc=30%
 9)  pretrained: loss=1.274, acc=52%; scratch: loss=1.608, acc=20%
1)   pretrained: loss=1.113, acc=62%; scratch: loss=1.588, acc=30%
2)   pretrained: loss=0.922, acc=62%; scratch: loss=1.578, acc=36%
3)   pretrained: loss=0.918, acc=62%; scratch: loss=1.599, acc=20%
4)   pretrained: loss=0.959, acc=58%; scratch: loss=1.594, acc=22%
5)   pretrained: loss=1.228, acc=50%; scratch: loss=1.608, acc=14%
6)   pretrained: loss=0.727, acc=76%; scratch: loss=1.623, acc=16%
7)   pretrained: loss=1.074, acc=66%; scratch: loss=1.607, acc=20%
8)   pretrained: loss=0.887, acc=60%; scratch: loss=1.614, acc=20%
9)   pretrained: loss=0.961, acc=62%; scratch: loss=1.614, acc=18%
10)  pretrained: loss=0.737, acc=76%; scratch: loss=1.613, acc=18%
11)  pretrained: loss=0.836, acc=70%; scratch: loss=1.614, acc=16%
Done.
</code></pre>
<p>Let’s look at the training loss and accuracy produced by the two training procedures.  Notice how quickly the ImageNet pretrained model’s loss value (blue) drops, and that the randomly initialized model’s loss value (green) barely (if at all) improves from training only the classifier layer.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plot(np.vstack([train_loss, scratch_train_loss]).T)</span><br><span class="line">xlabel(<span class="string">&#x27;Iteration #&#x27;</span>)</span><br><span class="line">ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.text.Text at 0x7f75d49e1090&gt;
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180808102005756-1000541529.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plot(np.vstack([train_acc, scratch_train_acc]).T)</span><br><span class="line">xlabel(<span class="string">&#x27;Iteration #&#x27;</span>)</span><br><span class="line">ylabel(<span class="string">&#x27;Accuracy&#x27;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.text.Text at 0x7f75d49e1a90&gt;
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180808102008709-1558718778.png" alt="png"></p>
<p>Let’s take a look at the testing accuracy after running 200 iterations of training. Note that we’re classifying among 5 classes, giving chance accuracy of 20%. We expect both results to be better than chance accuracy (20%), and we further expect the result from training using the ImageNet pretraining initialization to be much better than the one from training from scratch. Let’s see.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">eval_style_net</span>(<span class="params">weights, test_iters=<span class="number">10</span></span>):</span><br><span class="line">    test_net = caffe.Net(style_net(train=<span class="literal">False</span>), weights, caffe.TEST)</span><br><span class="line">    accuracy = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> it <span class="keyword">in</span> xrange(test_iters):</span><br><span class="line">        accuracy += test_net.forward()[<span class="string">&#x27;acc&#x27;</span>]</span><br><span class="line">    accuracy /= test_iters</span><br><span class="line">    <span class="keyword">return</span> test_net, accuracy</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">test_net, accuracy = eval_style_net(style_weights)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Accuracy, trained from ImageNet initialization: %3.1f%%&#x27;</span> % (<span class="number">100</span>*accuracy, )</span><br><span class="line">scratch_test_net, scratch_accuracy = eval_style_net(scratch_style_weights)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Accuracy, trained from   random initialization: %3.1f%%&#x27;</span> % (<span class="number">100</span>*scratch_accuracy, )</span><br></pre></td></tr></table></figure>

<pre><code>Accuracy, trained from ImageNet initialization: 50.0%
Accuracy, trained from   random initialization: 23.6%
</code></pre>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- kzl in-article ad -->
<p><ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5653382914441020"
     data-ad-slot="7925631830"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>


<h3 id="End-to-end-finetuning-for-style"><a href="#End-to-end-finetuning-for-style" class="headerlink" title="End-to-end finetuning for style"></a>End-to-end finetuning for style</h3><p>Finally, we’ll train both nets again, starting from the weights we just learned.  The only difference this time is that we’ll be learning the weights “end-to-end” by turning on learning in <em>all</em> layers of the network, starting from the RGB <code>conv1</code> filters directly applied to the input image.  We pass the argument <code>learn_all=True</code> to the <code>style_net</code> function defined earlier in this notebook, which tells the function to apply a positive (non-zero) <code>lr_mult</code> value for all parameters.  Under the default, <code>learn_all=False</code>, all parameters in the pretrained layers (<code>conv1</code> through <code>fc7</code>) are frozen (<code>lr_mult = 0</code>), and we learn only the classifier layer <code>fc8_flickr</code>.</p>
<p>Note that both networks start at roughly the accuracy achieved at the end of the previous training session, and improve significantly with end-to-end training.  To be more scientific, we’d also want to follow the same additional training procedure <em>without</em> the end-to-end training, to ensure that our results aren’t better simply because we trained for twice as long.  Feel free to try this yourself!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">end_to_end_net = style_net(train=<span class="literal">True</span>, learn_all=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set base_lr to 1e-3, the same as last time when learning only the classifier.</span></span><br><span class="line"><span class="comment"># You may want to play around with different values of this or other</span></span><br><span class="line"><span class="comment"># optimization parameters when fine-tuning.  For example, if learning diverges</span></span><br><span class="line"><span class="comment"># (e.g., the loss gets very large or goes to infinity/NaN), you should try</span></span><br><span class="line"><span class="comment"># decreasing base_lr (e.g., to 1e-4, then 1e-5, etc., until you find a value</span></span><br><span class="line"><span class="comment"># for which learning does not diverge).</span></span><br><span class="line">base_lr = <span class="number">0.001</span></span><br><span class="line"></span><br><span class="line">style_solver_filename = solver(end_to_end_net, base_lr=base_lr)</span><br><span class="line">style_solver = caffe.get_solver(style_solver_filename)</span><br><span class="line">style_solver.net.copy_from(style_weights)</span><br><span class="line"></span><br><span class="line">scratch_style_solver_filename = solver(end_to_end_net, base_lr=base_lr)</span><br><span class="line">scratch_style_solver = caffe.get_solver(scratch_style_solver_filename)</span><br><span class="line">scratch_style_solver.net.copy_from(scratch_style_weights)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Running solvers for %d iterations...&#x27;</span> % niter</span><br><span class="line">solvers = [(<span class="string">&#x27;pretrained, end-to-end&#x27;</span>, style_solver),</span><br><span class="line">           (<span class="string">&#x27;scratch, end-to-end&#x27;</span>, scratch_style_solver)]</span><br><span class="line">_, _, finetuned_weights = run_solvers(niter, solvers)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Done.&#x27;</span></span><br><span class="line"></span><br><span class="line">style_weights_ft = finetuned_weights[<span class="string">&#x27;pretrained, end-to-end&#x27;</span>]</span><br><span class="line">scratch_style_weights_ft = finetuned_weights[<span class="string">&#x27;scratch, end-to-end&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Delete solvers to save memory.</span></span><br><span class="line"><span class="keyword">del</span> style_solver, scratch_style_solver, solvers</span><br></pre></td></tr></table></figure>

<pre><code>Running solvers for 200 iterations...
  1) pretrained, end-to-end: loss=0.781, acc=64%; scratch, end-to-end: loss=1.585, acc=28%
 1)  pretrained, end-to-end: loss=1.178, acc=62%; scratch, end-to-end: loss=1.638, acc=14%
 2)  pretrained, end-to-end: loss=1.084, acc=60%; scratch, end-to-end: loss=1.637, acc= 8%
 3)  pretrained, end-to-end: loss=0.902, acc=76%; scratch, end-to-end: loss=1.600, acc=20%
 4)  pretrained, end-to-end: loss=0.865, acc=64%; scratch, end-to-end: loss=1.574, acc=26%
 5)  pretrained, end-to-end: loss=0.888, acc=60%; scratch, end-to-end: loss=1.604, acc=26%
 6)  pretrained, end-to-end: loss=0.538, acc=78%; scratch, end-to-end: loss=1.555, acc=34%
 7)  pretrained, end-to-end: loss=0.717, acc=72%; scratch, end-to-end: loss=1.563, acc=30%
 8)  pretrained, end-to-end: loss=0.695, acc=74%; scratch, end-to-end: loss=1.502, acc=42%
 9)  pretrained, end-to-end: loss=0.708, acc=68%; scratch, end-to-end: loss=1.523, acc=26%
1)   pretrained, end-to-end: loss=0.432, acc=78%; scratch, end-to-end: loss=1.500, acc=38%
2)   pretrained, end-to-end: loss=0.611, acc=78%; scratch, end-to-end: loss=1.618, acc=18%
3)   pretrained, end-to-end: loss=0.610, acc=76%; scratch, end-to-end: loss=1.473, acc=30%
4)   pretrained, end-to-end: loss=0.471, acc=78%; scratch, end-to-end: loss=1.488, acc=26%
5)   pretrained, end-to-end: loss=0.500, acc=76%; scratch, end-to-end: loss=1.514, acc=38%
6)   pretrained, end-to-end: loss=0.476, acc=80%; scratch, end-to-end: loss=1.452, acc=46%
7)   pretrained, end-to-end: loss=0.368, acc=82%; scratch, end-to-end: loss=1.419, acc=34%
8)   pretrained, end-to-end: loss=0.556, acc=76%; scratch, end-to-end: loss=1.583, acc=36%
9)   pretrained, end-to-end: loss=0.574, acc=72%; scratch, end-to-end: loss=1.556, acc=22%
10)  pretrained, end-to-end: loss=0.360, acc=88%; scratch, end-to-end: loss=1.429, acc=44%
11)  pretrained, end-to-end: loss=0.458, acc=78%; scratch, end-to-end: loss=1.370, acc=44%
Done.
</code></pre>
<p>Let’s now test the end-to-end finetuned models.  Since all layers have been optimized for the style recognition task at hand, we expect both nets to get better results than the ones above, which were achieved by nets with only their classifier layers trained for the style task (on top of either ImageNet pretrained or randomly initialized weights).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">test_net, accuracy = eval_style_net(style_weights_ft)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Accuracy, finetuned from ImageNet initialization: %3.1f%%&#x27;</span> % (<span class="number">100</span>*accuracy, )</span><br><span class="line">scratch_test_net, scratch_accuracy = eval_style_net(scratch_style_weights_ft)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;Accuracy, finetuned from   random initialization: %3.1f%%&#x27;</span> % (<span class="number">100</span>*scratch_accuracy, )</span><br></pre></td></tr></table></figure>

<pre><code>Accuracy, finetuned from ImageNet initialization: 53.6%
Accuracy, finetuned from   random initialization: 39.2%
</code></pre>
<p>We’ll first look back at the image we started with and check our end-to-end trained model’s predictions.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">plt.imshow(deprocess_net_image(image))</span><br><span class="line">disp_style_preds(test_net, image)</span><br></pre></td></tr></table></figure>

<pre><code>top 5 predicted style labels =
    (1) 55.67% Melancholy
    (2) 27.21% HDR
    (3) 16.46% Pastel
    (4)  0.63% Detailed
    (5)  0.03% Noir
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180808102011453-804222341.png" alt="png"></p>
<p>Whew, that looks a lot better than before!  But note that this image was from the training set, so the net got to see its label at training time.</p>
<p>Finally, we’ll pick an image from the test set (an image the model hasn’t seen) and look at our end-to-end finetuned style model’s predictions for it.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">batch_index = <span class="number">1</span></span><br><span class="line">image = test_net.blobs[<span class="string">&#x27;data&#x27;</span>].data[batch_index]</span><br><span class="line">plt.imshow(deprocess_net_image(image))</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;actual label =&#x27;</span>, style_labels[<span class="built_in">int</span>(test_net.blobs[<span class="string">&#x27;label&#x27;</span>].data[batch_index])]</span><br></pre></td></tr></table></figure>

<pre><code>actual label = Pastel
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180808102014230-1327642113.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">disp_style_preds(test_net, image)</span><br></pre></td></tr></table></figure>

<pre><code>top 5 predicted style labels =
    (1) 99.76% Pastel
    (2)  0.13% HDR
    (3)  0.11% Detailed
    (4)  0.00% Melancholy
    (5)  0.00% Noir
</code></pre>
<p>We can also look at the predictions of the network trained from scratch.  We see that in this case, the scratch network also predicts the correct label for the image (<em>Pastel</em>), but is much less confident in its prediction than the pretrained net.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">disp_style_preds(scratch_test_net, image)</span><br></pre></td></tr></table></figure>

<pre><code>top 5 predicted style labels =
    (1) 49.81% Pastel
    (2) 19.76% Detailed
    (3) 17.06% Melancholy
    (4) 11.66% HDR
    (5)  1.72% Noir
</code></pre>
<p>Of course, we can again look at the ImageNet model’s predictions for the above image:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">disp_imagenet_preds(imagenet_net, image)</span><br></pre></td></tr></table></figure>

<pre><code>top 5 predicted ImageNet labels =
    (1) 34.90% n07579787 plate
    (2) 21.63% n04263257 soup bowl
    (3) 17.75% n07875152 potpie
    (4)  5.72% n07711569 mashed potato
    (5)  5.27% n07584110 consomme
</code></pre>
<p>So we did finetuning and it is awesome. Let’s take a look at what kind of results we are able to get with a longer, more complete run of the style recognition dataset. Note: the below URL might be occasionally down because it is run on a research machine.</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="http://demo.vislab.berkeleyvision.org/">demo</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/BVLC/caffe">caffe git</a></li>
</ul>
<h2 id="History"><a href="#History" class="headerlink" title="History"></a>History</h2><ul>
<li>20180808: created.</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://kezunlin.me/blog/learning-lenet/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="kezunlin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kezunlin's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/learning-lenet/" class="post-title-link" itemprop="url">learning lenet with caffe and python</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-08-08 09:37:00" itemprop="dateCreated datePublished" datetime="2018-08-08T09:37:00+08:00">2018-08-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-10-14 13:39:28" itemprop="dateModified" datetime="2024-10-14T13:39:28+08:00">2024-10-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Solving-in-Python-with-LeNet"><a href="#Solving-in-Python-with-LeNet" class="headerlink" title="Solving in Python with LeNet"></a>Solving in Python with LeNet</h2><p>In this example, we’ll explore learning with Caffe in Python, using the fully-exposed <code>Solver</code> interface.</p>
<h3 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h3><ul>
<li>Set up the Python environment: we’ll use the <code>pylab</code> import for numpy and plot inline.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> *</span><br><span class="line">%matplotlib inline</span><br></pre></td></tr></table></figure>

<ul>
<li>Import <code>caffe</code>, adding it to <code>sys.path</code> if needed. Make sure you’ve built pycaffe.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">caffe_root = <span class="string">&#x27;../&#x27;</span>  <span class="comment"># this file should be run from &#123;caffe_root&#125;/examples (otherwise change this line)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">sys.path.insert(<span class="number">0</span>, caffe_root + <span class="string">&#x27;python&#x27;</span>)</span><br><span class="line"><span class="keyword">import</span> caffe</span><br></pre></td></tr></table></figure>

<ul>
<li>We’ll be using the provided LeNet example data and networks (make sure you’ve downloaded the data and created the databases, as below).</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># run scripts from caffe root</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.chdir(caffe_root)</span><br><span class="line"><span class="comment"># Download data</span></span><br><span class="line">!data/mnist/get_mnist.sh</span><br><span class="line"><span class="comment"># Prepare data</span></span><br><span class="line">!examples/mnist/create_mnist.sh</span><br><span class="line"><span class="comment"># back to examples</span></span><br><span class="line">os.chdir(<span class="string">&#x27;examples&#x27;</span>)</span><br></pre></td></tr></table></figure>

<pre><code>Downloading...
Creating lmdb...
Done.
</code></pre>
<h3 id="Creating-the-net"><a href="#Creating-the-net" class="headerlink" title="Creating the net"></a>Creating the net</h3><p>Now let’s make a variant of LeNet, the classic 1989 convnet architecture.</p>
<p>We’ll need two external files to help out:</p>
<ul>
<li>the net <code>prototxt</code>, defining the architecture and pointing to the train&#x2F;test data</li>
<li>the solver <code>prototxt</code>, defining the learning parameters</li>
</ul>
<p>We start by creating the net. We’ll write the net in a succinct and natural way as Python code that serializes to Caffe’s protobuf model format.</p>
<p>This network expects to read from pregenerated LMDBs, but reading directly from <code>ndarray</code>s is also possible using <code>MemoryDataLayer</code>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> caffe <span class="keyword">import</span> layers <span class="keyword">as</span> L, params <span class="keyword">as</span> P</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">lenet</span>(<span class="params">lmdb, batch_size</span>):</span><br><span class="line">    <span class="comment"># our version of LeNet: a series of linear and simple nonlinear transformations</span></span><br><span class="line">    n = caffe.NetSpec()</span><br><span class="line">    </span><br><span class="line">    n.data, n.label = L.Data(batch_size=batch_size, backend=P.Data.LMDB, source=lmdb,</span><br><span class="line">                             transform_param=<span class="built_in">dict</span>(scale=<span class="number">1.</span>/<span class="number">255</span>), ntop=<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    n.conv1 = L.Convolution(n.data, kernel_size=<span class="number">5</span>, num_output=<span class="number">20</span>, weight_filler=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;xavier&#x27;</span>))</span><br><span class="line">    n.pool1 = L.Pooling(n.conv1, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, pool=P.Pooling.MAX)</span><br><span class="line">    n.conv2 = L.Convolution(n.pool1, kernel_size=<span class="number">5</span>, num_output=<span class="number">50</span>, weight_filler=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;xavier&#x27;</span>))</span><br><span class="line">    n.pool2 = L.Pooling(n.conv2, kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, pool=P.Pooling.MAX)</span><br><span class="line">    n.fc1 =   L.InnerProduct(n.pool2, num_output=<span class="number">500</span>, weight_filler=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;xavier&#x27;</span>))</span><br><span class="line">    n.relu1 = L.ReLU(n.fc1, in_place=<span class="literal">True</span>)</span><br><span class="line">    n.score = L.InnerProduct(n.relu1, num_output=<span class="number">10</span>, weight_filler=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;xavier&#x27;</span>))</span><br><span class="line">    n.loss =  L.SoftmaxWithLoss(n.score, n.label)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> n.to_proto()</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;mnist/lenet_auto_train.prototxt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="built_in">str</span>(lenet(<span class="string">&#x27;mnist/mnist_train_lmdb&#x27;</span>, <span class="number">64</span>)))</span><br><span class="line">    </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;mnist/lenet_auto_test.prototxt&#x27;</span>, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="built_in">str</span>(lenet(<span class="string">&#x27;mnist/mnist_test_lmdb&#x27;</span>, <span class="number">100</span>)))</span><br></pre></td></tr></table></figure>

<p>The net has been written to disk in a more verbose but human-readable serialization format using Google’s protobuf library. You can read, write, and modify this description directly. Let’s take a look at the train net.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!cat mnist/lenet_auto_train.prototxt</span><br></pre></td></tr></table></figure>

<pre><code>layer &#123;
  name: &quot;data&quot;
  type: &quot;Data&quot;
  top: &quot;data&quot;
  top: &quot;label&quot;
  transform_param &#123;
    scale: 0.00392156862745
  &#125;
  data_param &#123;
    source: &quot;mnist/mnist_train_lmdb&quot;
    batch_size: 64
    backend: LMDB
  &#125;
&#125;
layer &#123;
  name: &quot;conv1&quot;
  type: &quot;Convolution&quot;
  bottom: &quot;data&quot;
  top: &quot;conv1&quot;
  convolution_param &#123;
    num_output: 20
    kernel_size: 5
    weight_filler &#123;
      type: &quot;xavier&quot;
    &#125;
  &#125;
&#125;
layer &#123;
  name: &quot;pool1&quot;
  type: &quot;Pooling&quot;
  bottom: &quot;conv1&quot;
  top: &quot;pool1&quot;
  pooling_param &#123;
    pool: MAX
    kernel_size: 2
    stride: 2
  &#125;
&#125;
layer &#123;
  name: &quot;conv2&quot;
  type: &quot;Convolution&quot;
  bottom: &quot;pool1&quot;
  top: &quot;conv2&quot;
  convolution_param &#123;
    num_output: 50
    kernel_size: 5
    weight_filler &#123;
      type: &quot;xavier&quot;
    &#125;
  &#125;
&#125;
layer &#123;
  name: &quot;pool2&quot;
  type: &quot;Pooling&quot;
  bottom: &quot;conv2&quot;
  top: &quot;pool2&quot;
  pooling_param &#123;
    pool: MAX
    kernel_size: 2
    stride: 2
  &#125;
&#125;
layer &#123;
  name: &quot;fc1&quot;
  type: &quot;InnerProduct&quot;
  bottom: &quot;pool2&quot;
  top: &quot;fc1&quot;
  inner_product_param &#123;
    num_output: 500
    weight_filler &#123;
      type: &quot;xavier&quot;
    &#125;
  &#125;
&#125;
layer &#123;
  name: &quot;relu1&quot;
  type: &quot;ReLU&quot;
  bottom: &quot;fc1&quot;
  top: &quot;fc1&quot;
&#125;
layer &#123;
  name: &quot;score&quot;
  type: &quot;InnerProduct&quot;
  bottom: &quot;fc1&quot;
  top: &quot;score&quot;
  inner_product_param &#123;
    num_output: 10
    weight_filler &#123;
      type: &quot;xavier&quot;
    &#125;
  &#125;
&#125;
layer &#123;
  name: &quot;loss&quot;
  type: &quot;SoftmaxWithLoss&quot;
  bottom: &quot;score&quot;
  bottom: &quot;label&quot;
  top: &quot;loss&quot;
&#125;
</code></pre>
<p>Now let’s see the learning parameters, which are also written as a <code>prototxt</code> file (already provided on disk). We’re using SGD with momentum, weight decay, and a specific learning rate schedule.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">!cat mnist/lenet_auto_solver.prototxt</span><br></pre></td></tr></table></figure>

<pre><code># The train/test net protocol buffer definition
train_net: &quot;mnist/lenet_auto_train.prototxt&quot;
test_net: &quot;mnist/lenet_auto_test.prototxt&quot;
# test_iter specifies how many forward passes the test should carry out.
# In the case of MNIST, we have test batch size 100 and 100 test iterations,
# covering the full 10,000 testing images.
test_iter: 100
# Carry out testing every 500 training iterations.
test_interval: 500
# The base learning rate, momentum and the weight decay of the network.
base_lr: 0.01
momentum: 0.9
weight_decay: 0.0005
# The learning rate policy
lr_policy: &quot;inv&quot;
gamma: 0.0001
power: 0.75
# Display every 100 iterations
display: 100
# The maximum number of iterations
max_iter: 10000
# snapshot intermediate results
snapshot: 5000
snapshot_prefix: &quot;mnist/lenet&quot;
</code></pre>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- kzl in-article ad -->
<p><ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5653382914441020"
     data-ad-slot="7925631830"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>




<h3 id="Loading-and-checking-the-solver"><a href="#Loading-and-checking-the-solver" class="headerlink" title="Loading and checking the solver"></a>Loading and checking the solver</h3><ul>
<li>Let’s pick a device and load the solver. We’ll use SGD (with momentum), but other methods (such as Adagrad and Nesterov’s accelerated gradient) are also available.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">caffe.set_device(<span class="number">0</span>)</span><br><span class="line">caffe.set_mode_gpu()</span><br><span class="line"></span><br><span class="line"><span class="comment">### load the solver and create train and test nets</span></span><br><span class="line">solver = <span class="literal">None</span>  <span class="comment"># ignore this workaround for lmdb data (can&#x27;t instantiate two solvers on the same data)</span></span><br><span class="line">solver = caffe.SGDSolver(<span class="string">&#x27;mnist/lenet_auto_solver.prototxt&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>To get an idea of the architecture of our net, we can check the dimensions of the intermediate features (blobs) and parameters (these will also be useful to refer to when manipulating data later).</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># each output is (batch size, feature dim, spatial dim)</span></span><br><span class="line">[(k, v.data.shape) <span class="keyword">for</span> k, v <span class="keyword">in</span> solver.net.blobs.items()]</span><br></pre></td></tr></table></figure>




<pre><code>[(&#39;data&#39;, (64, 1, 28, 28)),
 (&#39;label&#39;, (64,)),
 (&#39;conv1&#39;, (64, 20, 24, 24)),
 (&#39;pool1&#39;, (64, 20, 12, 12)),
 (&#39;conv2&#39;, (64, 50, 8, 8)),
 (&#39;pool2&#39;, (64, 50, 4, 4)),
 (&#39;fc1&#39;, (64, 500)),
 (&#39;score&#39;, (64, 10)),
 (&#39;loss&#39;, ())]
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># just print the weight sizes (we&#x27;ll omit the biases)</span></span><br><span class="line">[(k, v[<span class="number">0</span>].data.shape) <span class="keyword">for</span> k, v <span class="keyword">in</span> solver.net.params.items()]</span><br></pre></td></tr></table></figure>




<pre><code>[(&#39;conv1&#39;, (20, 1, 5, 5)),
 (&#39;conv2&#39;, (50, 20, 5, 5)),
 (&#39;fc1&#39;, (500, 800)),
 (&#39;score&#39;, (10, 500))]
</code></pre>
<ul>
<li>Before taking off, let’s check that everything is loaded as we expect. We’ll run a forward pass on the train and test nets and check that they contain our data.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">solver.net.forward()  <span class="comment"># train net</span></span><br><span class="line">solver.test_nets[<span class="number">0</span>].forward()  <span class="comment"># test net (there can be more than one)</span></span><br></pre></td></tr></table></figure>




<pre><code>&#123;&#39;loss&#39;: array(2.365971088409424, dtype=float32)&#125;
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># we use a little trick to tile the first eight images</span></span><br><span class="line">imshow(solver.net.blobs[<span class="string">&#x27;data&#x27;</span>].data[:<span class="number">8</span>, <span class="number">0</span>].transpose(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>).reshape(<span class="number">28</span>, <span class="number">8</span>*<span class="number">28</span>), cmap=<span class="string">&#x27;gray&#x27;</span>); axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;train labels:&#x27;</span>, solver.net.blobs[<span class="string">&#x27;label&#x27;</span>].data[:<span class="number">8</span>]</span><br></pre></td></tr></table></figure>

<pre><code>train labels: [ 5.  0.  4.  1.  9.  2.  1.  3.]
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094007919-402598205.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">imshow(solver.test_nets[<span class="number">0</span>].blobs[<span class="string">&#x27;data&#x27;</span>].data[:<span class="number">8</span>, <span class="number">0</span>].transpose(<span class="number">1</span>, <span class="number">0</span>, <span class="number">2</span>).reshape(<span class="number">28</span>, <span class="number">8</span>*<span class="number">28</span>), cmap=<span class="string">&#x27;gray&#x27;</span>); axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;test labels:&#x27;</span>, solver.test_nets[<span class="number">0</span>].blobs[<span class="string">&#x27;label&#x27;</span>].data[:<span class="number">8</span>]</span><br></pre></td></tr></table></figure>

<pre><code>test labels: [ 7.  2.  1.  0.  4.  1.  4.  9.]
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094011687-911149908.png" alt="png"></p>
<h3 id="Stepping-the-solver"><a href="#Stepping-the-solver" class="headerlink" title="Stepping the solver"></a>Stepping the solver</h3><p>Both train and test nets seem to be loading data, and to have correct labels.</p>
<ul>
<li>Let’s take one step of (minibatch) SGD and see what happens.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">solver.step(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>Do we have gradients propagating through our filters? Let’s see the updates to the first layer, shown here as a $4 \times 5$ grid of $5 \times 5$ filters.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">imshow(solver.net.params[<span class="string">&#x27;conv1&#x27;</span>][<span class="number">0</span>].diff[:, <span class="number">0</span>].reshape(<span class="number">4</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">5</span>)</span><br><span class="line">       .transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>).reshape(<span class="number">4</span>*<span class="number">5</span>, <span class="number">5</span>*<span class="number">5</span>), cmap=<span class="string">&#x27;gray&#x27;</span>); axis(<span class="string">&#x27;off&#x27;</span>)</span><br></pre></td></tr></table></figure>




<pre><code>(-0.5, 24.5, 19.5, -0.5)
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094015260-1011851543.png" alt="png"></p>
<h3 id="Writing-a-custom-training-loop"><a href="#Writing-a-custom-training-loop" class="headerlink" title="Writing a custom training loop"></a>Writing a custom training loop</h3><p>Something is happening. Let’s run the net for a while, keeping track of a few things as it goes.<br>Note that this process will be the same as if training through the <code>caffe</code> binary. In particular:</p>
<ul>
<li>logging will continue to happen as normal</li>
<li>snapshots will be taken at the interval specified in the solver prototxt (here, every 5000 iterations)</li>
<li>testing will happen at the interval specified (here, every 500 iterations)</li>
</ul>
<p>Since we have control of the loop in Python, we’re free to compute additional things as we go, as we show below. We can do many other things as well, for example:</p>
<ul>
<li>write a custom stopping criterion</li>
<li>change the solving process by updating the net in the loop</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">%%time</span><br><span class="line">niter = <span class="number">200</span></span><br><span class="line">test_interval = <span class="number">25</span></span><br><span class="line"><span class="comment"># losses will also be stored in the log</span></span><br><span class="line">train_loss = zeros(niter)</span><br><span class="line">test_acc = zeros(<span class="built_in">int</span>(np.ceil(niter / test_interval)))</span><br><span class="line">output = zeros((niter, <span class="number">8</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># the main solver loop</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> <span class="built_in">range</span>(niter):</span><br><span class="line">    solver.step(<span class="number">1</span>)  <span class="comment"># SGD by Caffe</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># store the train loss</span></span><br><span class="line">    train_loss[it] = solver.net.blobs[<span class="string">&#x27;loss&#x27;</span>].data</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># store the output on the first test batch</span></span><br><span class="line">    <span class="comment"># (start the forward pass at conv1 to avoid loading new data)</span></span><br><span class="line">    solver.test_nets[<span class="number">0</span>].forward(start=<span class="string">&#x27;conv1&#x27;</span>)</span><br><span class="line">    output[it] = solver.test_nets[<span class="number">0</span>].blobs[<span class="string">&#x27;score&#x27;</span>].data[:<span class="number">8</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># run a full test every so often</span></span><br><span class="line">    <span class="comment"># (Caffe can also do this for us and write to a log, but we show here</span></span><br><span class="line">    <span class="comment">#  how to do it directly in Python, where more complicated things are easier.)</span></span><br><span class="line">    <span class="keyword">if</span> it % test_interval == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;Iteration&#x27;</span>, it, <span class="string">&#x27;testing...&#x27;</span></span><br><span class="line">        correct = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> test_it <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">            solver.test_nets[<span class="number">0</span>].forward()</span><br><span class="line">            correct += <span class="built_in">sum</span>(solver.test_nets[<span class="number">0</span>].blobs[<span class="string">&#x27;score&#x27;</span>].data.argmax(<span class="number">1</span>)</span><br><span class="line">                           == solver.test_nets[<span class="number">0</span>].blobs[<span class="string">&#x27;label&#x27;</span>].data)</span><br><span class="line">        test_acc[it // test_interval] = correct / <span class="number">1e4</span></span><br></pre></td></tr></table></figure>

<pre><code>Iteration 0 testing...
Iteration 25 testing...
Iteration 50 testing...
Iteration 75 testing...
Iteration 100 testing...
Iteration 125 testing...
Iteration 150 testing...
Iteration 175 testing...
CPU times: user 12.6 s, sys: 2.4 s, total: 15 s
Wall time: 14.4 s
</code></pre>
<ul>
<li>Let’s plot the train loss and test accuracy.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">_, ax1 = subplots()</span><br><span class="line">ax2 = ax1.twinx()</span><br><span class="line">ax1.plot(arange(niter), train_loss)</span><br><span class="line">ax2.plot(test_interval * arange(<span class="built_in">len</span>(test_acc)), test_acc, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;iteration&#x27;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;train loss&#x27;</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&#x27;test accuracy&#x27;</span>)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;Test Accuracy: &#123;:.2f&#125;&#x27;</span>.<span class="built_in">format</span>(test_acc[-<span class="number">1</span>]))</span><br></pre></td></tr></table></figure>




<pre><code>&lt;matplotlib.text.Text at 0x7f5199b33610&gt;
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094018680-398130560.png" alt="png"></p>
<p>The loss seems to have dropped quickly and coverged (except for stochasticity), while the accuracy rose correspondingly. Hooray!</p>
<ul>
<li>Since we saved the results on the first test batch, we can watch how our prediction scores evolved. We’ll plot time on the $x$ axis and each possible label on the $y$, with lightness indicating confidence.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):</span><br><span class="line">    figure(figsize=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">    imshow(solver.test_nets[<span class="number">0</span>].blobs[<span class="string">&#x27;data&#x27;</span>].data[i, <span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    figure(figsize=(<span class="number">10</span>, <span class="number">2</span>))</span><br><span class="line">    imshow(output[:<span class="number">50</span>, i].T, interpolation=<span class="string">&#x27;nearest&#x27;</span>, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    xlabel(<span class="string">&#x27;iteration&#x27;</span>)</span><br><span class="line">    ylabel(<span class="string">&#x27;label&#x27;</span>)</span><br></pre></td></tr></table></figure>


<p><img src="https://kezunlin.me/images/posts/635233-20180808094024721-1595689994.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094029552-416345653.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094034649-822966977.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094311497-1449576622.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094314887-1994925148.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094317536-26566385.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094335122-926095188.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094337980-697149050.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094432007-708264326.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094434566-1643487577.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094437895-820163270.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094440686-873638921.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094443597-1649048206.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094538529-1155732317.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094541236-1763457969.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094544775-920829401.png" alt="png"></p>
<p>We started with little idea about any of these digits, and ended up with correct classifications for each. If you’ve been following along, you’ll see the last digit is the most difficult, a slanted “9” that’s (understandably) most confused with “4”.</p>
<ul>
<li>Note that these are the “raw” output scores rather than the softmax-computed probability vectors. The latter, shown below, make it easier to see the confidence of our net (but harder to see the scores for less likely digits).</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):</span><br><span class="line">    figure(figsize=(<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">    imshow(solver.test_nets[<span class="number">0</span>].blobs[<span class="string">&#x27;data&#x27;</span>].data[i, <span class="number">0</span>], cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    figure(figsize=(<span class="number">10</span>, <span class="number">2</span>))</span><br><span class="line">    imshow(exp(output[:<span class="number">50</span>, i].T) / exp(output[:<span class="number">50</span>, i].T).<span class="built_in">sum</span>(<span class="number">0</span>), interpolation=<span class="string">&#x27;nearest&#x27;</span>, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    xlabel(<span class="string">&#x27;iteration&#x27;</span>)</span><br><span class="line">    ylabel(<span class="string">&#x27;label&#x27;</span>)</span><br></pre></td></tr></table></figure>


<p><img src="https://kezunlin.me/images/posts/635233-20180808094547389-452464521.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094550416-1980646715.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094643633-1555377796.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094646089-423286443.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094648806-227199948.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094652998-1285471219.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094655636-2019663924.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094801120-1382644570.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094803553-433970977.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094806318-876599599.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094808993-1657424066.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094812363-210748808.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094910532-638562904.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094913556-1116095260.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094916138-1679934767.png" alt="png"></p>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094919214-1696881500.png" alt="png"></p>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- kzl in-article ad -->
<p><ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5653382914441020"
     data-ad-slot="7925631830"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>



<h3 id="Experiment-with-architecture-and-optimization"><a href="#Experiment-with-architecture-and-optimization" class="headerlink" title="Experiment with architecture and optimization"></a>Experiment with architecture and optimization</h3><p>Now that we’ve defined, trained, and tested LeNet there are many possible next steps:</p>
<ul>
<li>Define new architectures for comparison</li>
<li>Tune optimization by setting <code>base_lr</code> and the like or simply training longer</li>
<li>Switching the solver type from <code>SGD</code> to an adaptive method like <code>AdaDelta</code> or <code>Adam</code></li>
</ul>
<p>Feel free to explore these directions by editing the all-in-one example that follows.<br>Look for “<code>EDIT HERE</code>“ comments for suggested choice points.</p>
<p>By default this defines a simple linear classifier as a baseline.</p>
<p>In case your coffee hasn’t kicked in and you’d like inspiration, try out</p>
<ol>
<li>Switch the nonlinearity from <code>ReLU</code> to <code>ELU</code> or a saturing nonlinearity like <code>Sigmoid</code></li>
<li>Stack more fully connected and nonlinear layers</li>
<li>Search over learning rate 10x at a time (trying <code>0.1</code> and <code>0.001</code>)</li>
<li>Switch the solver type to <code>Adam</code> (this adaptive solver type should be less sensitive to hyperparameters, but no guarantees…)</li>
<li>Solve for longer by setting <code>niter</code> higher (to 500 or 1,000 for instance) to better show training differences</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br></pre></td><td class="code"><pre><span class="line">train_net_path = <span class="string">&#x27;mnist/custom_auto_train.prototxt&#x27;</span></span><br><span class="line">test_net_path = <span class="string">&#x27;mnist/custom_auto_test.prototxt&#x27;</span></span><br><span class="line">solver_config_path = <span class="string">&#x27;mnist/custom_auto_solver.prototxt&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### define net</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">custom_net</span>(<span class="params">lmdb, batch_size</span>):</span><br><span class="line">    <span class="comment"># define your own net!</span></span><br><span class="line">    n = caffe.NetSpec()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># keep this data layer for all networks</span></span><br><span class="line">    n.data, n.label = L.Data(batch_size=batch_size, backend=P.Data.LMDB, source=lmdb,</span><br><span class="line">                             transform_param=<span class="built_in">dict</span>(scale=<span class="number">1.</span>/<span class="number">255</span>), ntop=<span class="number">2</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># EDIT HERE to try different networks</span></span><br><span class="line">    <span class="comment"># this single layer defines a simple linear classifier</span></span><br><span class="line">    <span class="comment"># (in particular this defines a multiway logistic regression)</span></span><br><span class="line">    n.score =   L.InnerProduct(n.data, num_output=<span class="number">10</span>, weight_filler=<span class="built_in">dict</span>(<span class="built_in">type</span>=<span class="string">&#x27;xavier&#x27;</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># EDIT HERE this is the LeNet variant we have already tried</span></span><br><span class="line">    <span class="comment"># n.conv1 = L.Convolution(n.data, kernel_size=5, num_output=20, weight_filler=dict(type=&#x27;xavier&#x27;))</span></span><br><span class="line">    <span class="comment"># n.pool1 = L.Pooling(n.conv1, kernel_size=2, stride=2, pool=P.Pooling.MAX)</span></span><br><span class="line">    <span class="comment"># n.conv2 = L.Convolution(n.pool1, kernel_size=5, num_output=50, weight_filler=dict(type=&#x27;xavier&#x27;))</span></span><br><span class="line">    <span class="comment"># n.pool2 = L.Pooling(n.conv2, kernel_size=2, stride=2, pool=P.Pooling.MAX)</span></span><br><span class="line">    <span class="comment"># n.fc1 =   L.InnerProduct(n.pool2, num_output=500, weight_filler=dict(type=&#x27;xavier&#x27;))</span></span><br><span class="line">    <span class="comment"># EDIT HERE consider L.ELU or L.Sigmoid for the nonlinearity</span></span><br><span class="line">    <span class="comment"># n.relu1 = L.ReLU(n.fc1, in_place=True)</span></span><br><span class="line">    <span class="comment"># n.score =   L.InnerProduct(n.fc1, num_output=10, weight_filler=dict(type=&#x27;xavier&#x27;))</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># keep this loss layer for all networks</span></span><br><span class="line">    n.loss =  L.SoftmaxWithLoss(n.score, n.label)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> n.to_proto()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(train_net_path, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="built_in">str</span>(custom_net(<span class="string">&#x27;mnist/mnist_train_lmdb&#x27;</span>, <span class="number">64</span>)))    </span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(test_net_path, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="built_in">str</span>(custom_net(<span class="string">&#x27;mnist/mnist_test_lmdb&#x27;</span>, <span class="number">100</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment">### define solver</span></span><br><span class="line"><span class="keyword">from</span> caffe.proto <span class="keyword">import</span> caffe_pb2</span><br><span class="line">s = caffe_pb2.SolverParameter()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set a seed for reproducible experiments:</span></span><br><span class="line"><span class="comment"># this controls for randomization in training.</span></span><br><span class="line">s.random_seed = <span class="number">0xCAFFE</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Specify locations of the train and (maybe) test networks.</span></span><br><span class="line">s.train_net = train_net_path</span><br><span class="line">s.test_net.append(test_net_path)</span><br><span class="line">s.test_interval = <span class="number">500</span>  <span class="comment"># Test after every 500 training iterations.</span></span><br><span class="line">s.test_iter.append(<span class="number">100</span>) <span class="comment"># Test on 100 batches each time we test.</span></span><br><span class="line"></span><br><span class="line">s.max_iter = <span class="number">10000</span>     <span class="comment"># no. of times to update the net (training iterations)</span></span><br><span class="line"> </span><br><span class="line"><span class="comment"># EDIT HERE to try different solvers</span></span><br><span class="line"><span class="comment"># solver types include &quot;SGD&quot;, &quot;Adam&quot;, and &quot;Nesterov&quot; among others.</span></span><br><span class="line">s.<span class="built_in">type</span> = <span class="string">&quot;SGD&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the initial learning rate for SGD.</span></span><br><span class="line">s.base_lr = <span class="number">0.01</span>  <span class="comment"># EDIT HERE to try different learning rates</span></span><br><span class="line"><span class="comment"># Set momentum to accelerate learning by</span></span><br><span class="line"><span class="comment"># taking weighted average of current and previous updates.</span></span><br><span class="line">s.momentum = <span class="number">0.9</span></span><br><span class="line"><span class="comment"># Set weight decay to regularize and prevent overfitting</span></span><br><span class="line">s.weight_decay = <span class="number">5e-4</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Set `lr_policy` to define how the learning rate changes during training.</span></span><br><span class="line"><span class="comment"># This is the same policy as our default LeNet.</span></span><br><span class="line">s.lr_policy = <span class="string">&#x27;inv&#x27;</span></span><br><span class="line">s.gamma = <span class="number">0.0001</span></span><br><span class="line">s.power = <span class="number">0.75</span></span><br><span class="line"><span class="comment"># EDIT HERE to try the fixed rate (and compare with adaptive solvers)</span></span><br><span class="line"><span class="comment"># `fixed` is the simplest policy that keeps the learning rate constant.</span></span><br><span class="line"><span class="comment"># s.lr_policy = &#x27;fixed&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Display the current training loss and accuracy every 1000 iterations.</span></span><br><span class="line">s.display = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Snapshots are files used to store networks we&#x27;ve trained.</span></span><br><span class="line"><span class="comment"># We&#x27;ll snapshot every 5K iterations -- twice during training.</span></span><br><span class="line">s.snapshot = <span class="number">5000</span></span><br><span class="line">s.snapshot_prefix = <span class="string">&#x27;mnist/custom_net&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Train on the GPU</span></span><br><span class="line">s.solver_mode = caffe_pb2.SolverParameter.GPU</span><br><span class="line"></span><br><span class="line"><span class="comment"># Write the solver to a temporary file and return its filename.</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(solver_config_path, <span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(<span class="built_in">str</span>(s))</span><br><span class="line"></span><br><span class="line"><span class="comment">### load the solver and create train and test nets</span></span><br><span class="line">solver = <span class="literal">None</span>  <span class="comment"># ignore this workaround for lmdb data (can&#x27;t instantiate two solvers on the same data)</span></span><br><span class="line">solver = caffe.get_solver(solver_config_path)</span><br><span class="line"></span><br><span class="line"><span class="comment">### solve</span></span><br><span class="line">niter = <span class="number">250</span>  <span class="comment"># EDIT HERE increase to train for longer</span></span><br><span class="line">test_interval = niter / <span class="number">10</span></span><br><span class="line"><span class="comment"># losses will also be stored in the log</span></span><br><span class="line">train_loss = zeros(niter)</span><br><span class="line">test_acc = zeros(<span class="built_in">int</span>(np.ceil(niter / test_interval)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># the main solver loop</span></span><br><span class="line"><span class="keyword">for</span> it <span class="keyword">in</span> <span class="built_in">range</span>(niter):</span><br><span class="line">    solver.step(<span class="number">1</span>)  <span class="comment"># SGD by Caffe</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># store the train loss</span></span><br><span class="line">    train_loss[it] = solver.net.blobs[<span class="string">&#x27;loss&#x27;</span>].data</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># run a full test every so often</span></span><br><span class="line">    <span class="comment"># (Caffe can also do this for us and write to a log, but we show here</span></span><br><span class="line">    <span class="comment">#  how to do it directly in Python, where more complicated things are easier.)</span></span><br><span class="line">    <span class="keyword">if</span> it % test_interval == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&#x27;Iteration&#x27;</span>, it, <span class="string">&#x27;testing...&#x27;</span></span><br><span class="line">        correct = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> test_it <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">            solver.test_nets[<span class="number">0</span>].forward()</span><br><span class="line">            correct += <span class="built_in">sum</span>(solver.test_nets[<span class="number">0</span>].blobs[<span class="string">&#x27;score&#x27;</span>].data.argmax(<span class="number">1</span>)</span><br><span class="line">                           == solver.test_nets[<span class="number">0</span>].blobs[<span class="string">&#x27;label&#x27;</span>].data)</span><br><span class="line">        test_acc[it // test_interval] = correct / <span class="number">1e4</span></span><br><span class="line"></span><br><span class="line">_, ax1 = subplots()</span><br><span class="line">ax2 = ax1.twinx()</span><br><span class="line">ax1.plot(arange(niter), train_loss)</span><br><span class="line">ax2.plot(test_interval * arange(<span class="built_in">len</span>(test_acc)), test_acc, <span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">ax1.set_xlabel(<span class="string">&#x27;iteration&#x27;</span>)</span><br><span class="line">ax1.set_ylabel(<span class="string">&#x27;train loss&#x27;</span>)</span><br><span class="line">ax2.set_ylabel(<span class="string">&#x27;test accuracy&#x27;</span>)</span><br><span class="line">ax2.set_title(<span class="string">&#x27;Custom Test Accuracy: &#123;:.2f&#125;&#x27;</span>.<span class="built_in">format</span>(test_acc[-<span class="number">1</span>]))</span><br></pre></td></tr></table></figure>

<pre><code>Iteration 0 testing...
Iteration 25 testing...
Iteration 50 testing...
Iteration 75 testing...
Iteration 100 testing...
Iteration 125 testing...
Iteration 150 testing...
Iteration 175 testing...
Iteration 200 testing...
Iteration 225 testing...





&lt;matplotlib.text.Text at 0x7f5199af9f50&gt;
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180808094922779-1511591853.png" alt="png"></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="http://demo.vislab.berkeleyvision.org/">demo</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/BVLC/caffe">caffe git</a></li>
</ul>
<h2 id="History"><a href="#History" class="headerlink" title="History"></a>History</h2><ul>
<li>20180808: created.</li>
</ul>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/11/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/11/">11</a><span class="page-number current">12</span><a class="page-number" href="/page/13/">13</a><span class="space">&hellip;</span><a class="page-number" href="/page/19/">19</a><a class="extend next" rel="next" href="/page/13/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">kezunlin</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">181</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">213</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">kezunlin</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
