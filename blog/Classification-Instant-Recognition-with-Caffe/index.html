<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">


  <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({
      google_ad_client: "ca-pub-5653382914441020",
      enable_page_level_ads: true
    });
  </script>

  <meta name="google-site-verification" content="WSpJFvfcmIPBX_iK8uPbmCHIy_0f1lvd7ZJpbyad2sA">
  <meta name="yandex-verification" content="808eb057eb8396cc">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"kezunlin.me","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="TutorialIn this example we’ll classify an image with the bundled CaffeNet model (which is based on the network architecture of Krizhevsky et al. for ImageNet). We’ll compare CPU and GPU modes and then">
<meta property="og:type" content="article">
<meta property="og:title" content="Classification: Instant Recognition with Caffe">
<meta property="og:url" content="https://kezunlin.me/blog/Classification-Instant-Recognition-with-Caffe/index.html">
<meta property="og:site_name" content="Kezunlin&#39;s Blog">
<meta property="og:description" content="TutorialIn this example we’ll classify an image with the bundled CaffeNet model (which is based on the network architecture of Krizhevsky et al. for ImageNet). We’ll compare CPU and GPU modes and then">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://kezunlin.me/images/posts/635233-20180807173641145-432603467.png">
<meta property="og:image" content="https://kezunlin.me/images/posts/635233-20180807173745487-782490699.png">
<meta property="og:image" content="https://kezunlin.me/images/posts/635233-20180807173803768-454494158.png">
<meta property="og:image" content="https://kezunlin.me/images/posts/635233-20180807173817099-163236065.png">
<meta property="og:image" content="https://kezunlin.me/images/posts/635233-20180807173830706-986799321.png">
<meta property="og:image" content="https://kezunlin.me/images/posts/635233-20180807173851980-73956897.png">
<meta property="article:published_time" content="2018-08-07T09:33:00.000Z">
<meta property="article:modified_time" content="2024-10-14T05:39:28.656Z">
<meta property="article:author" content="kezunlin">
<meta property="article:tag" content="caffe">
<meta property="article:tag" content="image classification">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://kezunlin.me/images/posts/635233-20180807173641145-432603467.png">

<link rel="canonical" href="https://kezunlin.me/blog/Classification-Instant-Recognition-with-Caffe/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Classification: Instant Recognition with Caffe | Kezunlin's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Kezunlin's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Kezunlin's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Live and Learn</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://kezunlin.me/blog/Classification-Instant-Recognition-with-Caffe/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="kezunlin">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Kezunlin's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Classification: Instant Recognition with Caffe
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2018-08-07 17:33:00" itemprop="dateCreated datePublished" datetime="2018-08-07T17:33:00+08:00">2018-08-07</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2024-10-14 13:39:28" itemprop="dateModified" datetime="2024-10-14T13:39:28+08:00">2024-10-14</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/deep-learning/" itemprop="url" rel="index"><span itemprop="name">deep learning</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="Tutorial"><a href="#Tutorial" class="headerlink" title="Tutorial"></a>Tutorial</h2><p>In this example we’ll classify an image with the bundled CaffeNet model (which is based on the network architecture of Krizhevsky et al. for ImageNet).</p>
<p>We’ll compare CPU and GPU modes and then dig into the model to inspect features and the output.</p>
<h3 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h3><ul>
<li>First, set up Python, <code>numpy</code>, and <code>matplotlib</code>.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set up Python environment: numpy for numerical routines, and matplotlib for plotting</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># display plots in this notebook</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># set display defaults</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">10</span>, <span class="number">10</span>)        <span class="comment"># large images</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;image.interpolation&#x27;</span>] = <span class="string">&#x27;nearest&#x27;</span>  <span class="comment"># don&#x27;t interpolate: show square pixels</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;image.cmap&#x27;</span>] = <span class="string">&#x27;gray&#x27;</span>  <span class="comment"># use grayscale output rather than a (potentially misleading) color heatmap</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># The caffe module needs to be on the Python path;</span></span><br><span class="line"><span class="comment">#  we&#x27;ll add it here explicitly.</span></span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line">caffe_root = <span class="string">&#x27;../&#x27;</span>  <span class="comment"># this file should be run from &#123;caffe_root&#125;/examples (otherwise change this line)</span></span><br><span class="line">sys.path.insert(<span class="number">0</span>, caffe_root + <span class="string">&#x27;python&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> caffe</span><br><span class="line"><span class="comment"># If you get &quot;No module named _caffe&quot;, either you have not built pycaffe or you have the wrong path.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">if</span> os.path.isfile(caffe_root + <span class="string">&#x27;models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel&#x27;</span>):</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;CaffeNet found.&#x27;</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&#x27;Downloading pre-trained CaffeNet model...&#x27;</span></span><br><span class="line">    !../scripts/download_model_binary.py ../models/bvlc_reference_caffenet</span><br></pre></td></tr></table></figure>

<pre><code>CaffeNet found.
</code></pre>
<h3 id="Load-net-and-set-up-input-preprocessing"><a href="#Load-net-and-set-up-input-preprocessing" class="headerlink" title="Load net and set up input preprocessing"></a>Load net and set up input preprocessing</h3><ul>
<li>Set Caffe to CPU mode and load the net from disk.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">caffe.set_mode_cpu()</span><br><span class="line"></span><br><span class="line">model_def = caffe_root + <span class="string">&#x27;models/bvlc_reference_caffenet/deploy.prototxt&#x27;</span></span><br><span class="line">model_weights = caffe_root + <span class="string">&#x27;models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel&#x27;</span></span><br><span class="line"></span><br><span class="line">net = caffe.Net(model_def,      <span class="comment"># defines the structure of the model</span></span><br><span class="line">                model_weights,  <span class="comment"># contains the trained weights</span></span><br><span class="line">                caffe.TEST)     <span class="comment"># use test mode (e.g., don&#x27;t perform dropout)</span></span><br></pre></td></tr></table></figure>

<ul>
<li><p>Set up input preprocessing. (We’ll use Caffe’s <code>caffe.io.Transformer</code> to do this, but this step is independent of other parts of Caffe, so any custom preprocessing code may be used).</p>
<p>  Our default CaffeNet is configured to take images in BGR format. Values are expected to start in the range [0, 255] and then have the mean ImageNet pixel value subtracted from them. In addition, the channel dimension is expected as the first (<em>outermost</em>) dimension.</p>
<p>  As matplotlib will load images with values in the range [0, 1] in RGB format with the channel as the <em>innermost</em> dimension, we are arranging for the needed transformations here.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load the mean ImageNet image (as distributed with Caffe) for subtraction</span></span><br><span class="line">mu = np.load(caffe_root + <span class="string">&#x27;python/caffe/imagenet/ilsvrc_2012_mean.npy&#x27;</span>)</span><br><span class="line">mu = mu.mean(<span class="number">1</span>).mean(<span class="number">1</span>)  <span class="comment"># average over pixels to obtain the mean (BGR) pixel values</span></span><br><span class="line"><span class="comment">#mu = np.array([ 104.00698793,  116.66876762,  122.67891434]) </span></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;mean-subtracted values:&#x27;</span>, <span class="built_in">zip</span>(<span class="string">&#x27;BGR&#x27;</span>, mu)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create transformer for the input called &#x27;data&#x27;</span></span><br><span class="line">transformer = caffe.io.Transformer(&#123;<span class="string">&#x27;data&#x27;</span>: net.blobs[<span class="string">&#x27;data&#x27;</span>].data.shape&#125;)</span><br><span class="line"></span><br><span class="line">transformer.set_transpose(<span class="string">&#x27;data&#x27;</span>, (<span class="number">2</span>,<span class="number">0</span>,<span class="number">1</span>))  <span class="comment"># move image channels to outermost dimension</span></span><br><span class="line">transformer.set_mean(<span class="string">&#x27;data&#x27;</span>, mu)            <span class="comment"># subtract the dataset-mean value in each channel</span></span><br><span class="line">transformer.set_raw_scale(<span class="string">&#x27;data&#x27;</span>, <span class="number">255</span>)      <span class="comment"># rescale from [0, 1] to [0, 255]</span></span><br><span class="line">transformer.set_channel_swap(<span class="string">&#x27;data&#x27;</span>, (<span class="number">2</span>,<span class="number">1</span>,<span class="number">0</span>))  <span class="comment"># swap channels from RGB to BGR</span></span><br></pre></td></tr></table></figure>

<pre><code>mean-subtracted values: [(&#39;B&#39;, 104.0069879317889), (&#39;G&#39;, 116.66876761696767), (&#39;R&#39;, 122.6789143406786)]
</code></pre>
<h3 id="CPU-classification"><a href="#CPU-classification" class="headerlink" title="CPU classification"></a>CPU classification</h3><ul>
<li>Now we’re ready to perform classification. Even though we’ll only classify one image, we’ll set a batch size of 50 to demonstrate batching.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># set the size of the input (we can skip this if we&#x27;re happy</span></span><br><span class="line"><span class="comment">#  with the default; we can also change it later, e.g., for different batch sizes)</span></span><br><span class="line">net.blobs[<span class="string">&#x27;data&#x27;</span>].reshape(<span class="number">50</span>,        <span class="comment"># batch size</span></span><br><span class="line">                          <span class="number">3</span>,         <span class="comment"># 3-channel (BGR) images</span></span><br><span class="line">                          <span class="number">227</span>, <span class="number">227</span>)  <span class="comment"># image size is 227x227</span></span><br></pre></td></tr></table></figure>

<ul>
<li>Load an image (that comes with Caffe) and perform the preprocessing we’ve set up.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">image = caffe.io.load_image(caffe_root + <span class="string">&#x27;examples/images/cat.jpg&#x27;</span>)</span><br><span class="line">transformed_image = transformer.preprocess(<span class="string">&#x27;data&#x27;</span>, image)</span><br><span class="line">plt.imshow(image)</span><br></pre></td></tr></table></figure>

<pre><code>/usr/local/lib/python2.7/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, &#39;constant&#39;, will be changed to &#39;reflect&#39; in skimage 0.15.
  warn(&quot;The default mode, &#39;constant&#39;, will be changed to &#39;reflect&#39; in &quot;





&lt;matplotlib.image.AxesImage at 0x7f2088044450&gt;
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180807173641145-432603467.png" alt="png"></p>
<ul>
<li>Adorable! Let’s classify it!</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># copy the image data into the memory allocated for the net</span></span><br><span class="line">net.blobs[<span class="string">&#x27;data&#x27;</span>].data[...] = transformed_image</span><br><span class="line"></span><br><span class="line"><span class="comment">### perform classification</span></span><br><span class="line">output = net.forward()</span><br><span class="line"></span><br><span class="line">output_prob = output[<span class="string">&#x27;prob&#x27;</span>][<span class="number">0</span>]  <span class="comment"># the output probability vector for the first image in the batch</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> output_prob.shape</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;predicted class is:&#x27;</span>, output_prob.argmax()</span><br></pre></td></tr></table></figure>

<pre><code>(1000,)
predicted class is: 281
</code></pre>
<ul>
<li>The net gives us a vector of probabilities; the most probable class was the 281st one. But is that correct? Let’s check the ImageNet labels…</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># load ImageNet labels</span></span><br><span class="line">labels_file = caffe_root + <span class="string">&#x27;data/ilsvrc12/synset_words.txt&#x27;</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(labels_file):</span><br><span class="line">    !../data/ilsvrc12/get_ilsvrc_aux.sh</span><br><span class="line">    </span><br><span class="line">labels = np.loadtxt(labels_file, <span class="built_in">str</span>, delimiter=<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> labels.shape</span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;output label:&#x27;</span>, labels[output_prob.argmax()]</span><br></pre></td></tr></table></figure>

<pre><code>(1000,)
output label: n02123045 tabby, tabby cat
</code></pre>
<ul>
<li>“Tabby cat” is correct! But let’s also look at other top (but less confident predictions).</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># sort top five predictions from softmax output</span></span><br><span class="line">top_inds = output_prob.argsort()[::-<span class="number">1</span>][:<span class="number">5</span>]  <span class="comment"># reverse sort and take five largest items</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;probabilities and labels:&#x27;</span></span><br><span class="line"><span class="built_in">zip</span>(output_prob[top_inds], labels[top_inds])</span><br></pre></td></tr></table></figure>

<pre><code>probabilities and labels:





[(0.31243625, &#39;n02123045 tabby, tabby cat&#39;),
 (0.23797157, &#39;n02123159 tiger cat&#39;),
 (0.12387245, &#39;n02124075 Egyptian cat&#39;),
 (0.10075716, &#39;n02119022 red fox, Vulpes vulpes&#39;),
 (0.070957333, &#39;n02127052 lynx, catamount&#39;)]
</code></pre>
<ul>
<li>We see that less confident predictions are sensible.</li>
</ul>
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- kzl in-article ad -->
<p><ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-5653382914441020"
     data-ad-slot="7925631830"></ins></p>
<script>
     (adsbygoogle = window.adsbygoogle || []).push({});
</script>




<h3 id="Switching-to-GPU-mode"><a href="#Switching-to-GPU-mode" class="headerlink" title="Switching to GPU mode"></a>Switching to GPU mode</h3><ul>
<li>Let’s see how long classification took, and compare it to GPU mode.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">%timeit net.forward()</span><br></pre></td></tr></table></figure>

<pre><code>1 loop, best of 3: 4.26 s per loop
</code></pre>
<ul>
<li>That’s a while, even for a batch of 50 images. Let’s switch to GPU mode.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">caffe.set_device(<span class="number">0</span>)  <span class="comment"># if we have multiple GPUs, pick the first one</span></span><br><span class="line">caffe.set_mode_gpu()</span><br><span class="line">net.forward()  <span class="comment"># run once before timing to set up memory</span></span><br><span class="line">%timeit net.forward()</span><br></pre></td></tr></table></figure>

<pre><code>10 loops, best of 3: 29.6 ms per loop
</code></pre>
<ul>
<li>That should be much faster!</li>
</ul>
<h3 id="Examining-intermediate-output"><a href="#Examining-intermediate-output" class="headerlink" title="Examining intermediate output"></a>Examining intermediate output</h3><ul>
<li>A net is not just a black box; let’s take a look at some of the parameters and intermediate activations.</li>
</ul>
<p>First we’ll see how to read out the structure of the net in terms of activation and parameter shapes.</p>
<ul>
<li><p>For each layer, let’s look at the activation shapes, which typically have the form <code>(batch_size, channel_dim, height, width)</code>.</p>
<p>  The activations are exposed as an <code>OrderedDict</code>, <code>net.blobs</code>.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># for each layer, show the output shape</span></span><br><span class="line"><span class="keyword">for</span> layer_name, blob <span class="keyword">in</span> net.blobs.iteritems():</span><br><span class="line">    <span class="built_in">print</span> layer_name + <span class="string">&#x27;\t&#x27;</span> + <span class="built_in">str</span>(blob.data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>data	(50, 3, 227, 227)
conv1	(50, 96, 55, 55)
pool1	(50, 96, 27, 27)
norm1	(50, 96, 27, 27)
conv2	(50, 256, 27, 27)
pool2	(50, 256, 13, 13)
norm2	(50, 256, 13, 13)
conv3	(50, 384, 13, 13)
conv4	(50, 384, 13, 13)
conv5	(50, 256, 13, 13)
pool5	(50, 256, 6, 6)
fc6	(50, 4096)
fc7	(50, 4096)
fc8	(50, 1000)
prob	(50, 1000)
</code></pre>
<ul>
<li><p>Now look at the parameter shapes. The parameters are exposed as another <code>OrderedDict</code>, <code>net.params</code>. We need to index the resulting values with either <code>[0]</code> for weights or <code>[1]</code> for biases.</p>
<p>  The param shapes typically have the form <code>(output_channels, input_channels, filter_height, filter_width)</code> (for the weights) and the 1-dimensional shape <code>(output_channels,)</code> (for the biases).</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> layer_name, param <span class="keyword">in</span> net.params.iteritems():</span><br><span class="line">    <span class="built_in">print</span> layer_name + <span class="string">&#x27;\t&#x27;</span> + <span class="built_in">str</span>(param[<span class="number">0</span>].data.shape), <span class="built_in">str</span>(param[<span class="number">1</span>].data.shape)</span><br></pre></td></tr></table></figure>

<pre><code>conv1	(96, 3, 11, 11) (96,)
conv2	(256, 48, 5, 5) (256,)
conv3	(384, 256, 3, 3) (384,)
conv4	(384, 192, 3, 3) (384,)
conv5	(256, 192, 3, 3) (256,)
fc6	(4096, 9216) (4096,)
fc7	(4096, 4096) (4096,)
fc8	(1000, 4096) (1000,)
</code></pre>
<ul>
<li>Since we’re dealing with four-dimensional data here, we’ll define a helper function for visualizing sets of rectangular heatmaps.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">vis_square</span>(<span class="params">data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Take an array of shape (n, height, width) or (n, height, width, 3)</span></span><br><span class="line"><span class="string">       and visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># normalize data for display</span></span><br><span class="line">    data = (data - data.<span class="built_in">min</span>()) / (data.<span class="built_in">max</span>() - data.<span class="built_in">min</span>())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># force the number of filters to be square</span></span><br><span class="line">    n = <span class="built_in">int</span>(np.ceil(np.sqrt(data.shape[<span class="number">0</span>])))</span><br><span class="line">    padding = (((<span class="number">0</span>, n ** <span class="number">2</span> - data.shape[<span class="number">0</span>]),</span><br><span class="line">               (<span class="number">0</span>, <span class="number">1</span>), (<span class="number">0</span>, <span class="number">1</span>))                 <span class="comment"># add some space between filters</span></span><br><span class="line">               + ((<span class="number">0</span>, <span class="number">0</span>),) * (data.ndim - <span class="number">3</span>))  <span class="comment"># don&#x27;t pad the last dimension (if there is one)</span></span><br><span class="line">    data = np.pad(data, padding, mode=<span class="string">&#x27;constant&#x27;</span>, constant_values=<span class="number">1</span>)  <span class="comment"># pad with ones (white)</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># tile the filters into an image</span></span><br><span class="line">    data = data.reshape((n, n) + data.shape[<span class="number">1</span>:]).transpose((<span class="number">0</span>, <span class="number">2</span>, <span class="number">1</span>, <span class="number">3</span>) + <span class="built_in">tuple</span>(<span class="built_in">range</span>(<span class="number">4</span>, data.ndim + <span class="number">1</span>)))</span><br><span class="line">    data = data.reshape((n * data.shape[<span class="number">1</span>], n * data.shape[<span class="number">3</span>]) + data.shape[<span class="number">4</span>:])</span><br><span class="line">    </span><br><span class="line">    plt.imshow(data); plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br></pre></td></tr></table></figure>

<ul>
<li>First we’ll look at the first layer filters, <code>conv1</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># the parameters are a list of [weights, biases]</span></span><br><span class="line">filters = net.params[<span class="string">&#x27;conv1&#x27;</span>][<span class="number">0</span>].data</span><br><span class="line">vis_square(filters.transpose(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>


<p><img src="https://kezunlin.me/images/posts/635233-20180807173745487-782490699.png" alt="png"></p>
<ul>
<li>The first layer output, <code>conv1</code> (rectified responses of the filters above, first 36 only)</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">feat = net.blobs[<span class="string">&#x27;conv1&#x27;</span>].data[<span class="number">0</span>, :<span class="number">36</span>]</span><br><span class="line">vis_square(feat)</span><br></pre></td></tr></table></figure>


<p><img src="https://kezunlin.me/images/posts/635233-20180807173803768-454494158.png" alt="png"></p>
<ul>
<li>The fifth layer after pooling, <code>pool5</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">feat = net.blobs[<span class="string">&#x27;pool5&#x27;</span>].data[<span class="number">0</span>]</span><br><span class="line">vis_square(feat)</span><br></pre></td></tr></table></figure>


<p><img src="https://kezunlin.me/images/posts/635233-20180807173817099-163236065.png" alt="png"></p>
<ul>
<li><p>The first fully connected layer, <code>fc6</code> (rectified)</p>
<p>  We show the output values and the histogram of the positive values</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">feat = net.blobs[<span class="string">&#x27;fc6&#x27;</span>].data[<span class="number">0</span>]</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">plt.plot(feat.flat)</span><br><span class="line">plt.subplot(<span class="number">2</span>, <span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">_ = plt.hist(feat.flat[feat.flat &gt; <span class="number">0</span>], bins=<span class="number">100</span>)</span><br></pre></td></tr></table></figure>


<p><img src="https://kezunlin.me/images/posts/635233-20180807173830706-986799321.png" alt="png"></p>
<ul>
<li>The final probability output, <code>prob</code></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">feat = net.blobs[<span class="string">&#x27;prob&#x27;</span>].data[<span class="number">0</span>]</span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">3</span>))</span><br><span class="line">plt.plot(feat.flat)</span><br></pre></td></tr></table></figure>




<pre><code>[&lt;matplotlib.lines.Line2D at 0x7f2060250650&gt;]
</code></pre>
<p><img src="https://kezunlin.me/images/posts/635233-20180807173851980-73956897.png" alt="png"></p>
<p>Note the cluster of strong predictions; the labels are sorted semantically. The top peaks correspond to the top predicted labels, as shown above.</p>
<h3 id="Try-your-own-image"><a href="#Try-your-own-image" class="headerlink" title="Try your own image"></a>Try your own image</h3><p>Now we’ll grab an image from the web and classify it using the steps above.</p>
<ul>
<li>Try setting <code>my_image_url</code> to any JPEG image URL.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># download an image</span></span><br><span class="line">my_image_url = <span class="string">&quot;...&quot;</span>  <span class="comment"># paste your URL here</span></span><br><span class="line"><span class="comment"># for example:</span></span><br><span class="line"><span class="comment"># my_image_url = &quot;https://upload.wikimedia.org/wikipedia/commons/b/be/Orang_Utan%2C_Semenggok_Forest_Reserve%2C_Sarawak%2C_Borneo%2C_Malaysia.JPG&quot;</span></span><br><span class="line">!wget -O image.jpg $my_image_url</span><br><span class="line"></span><br><span class="line"><span class="comment"># transform it and copy it into the net</span></span><br><span class="line">image = caffe.io.load_image(<span class="string">&#x27;image.jpg&#x27;</span>)</span><br><span class="line">net.blobs[<span class="string">&#x27;data&#x27;</span>].data[...] = transformer.preprocess(<span class="string">&#x27;data&#x27;</span>, image)</span><br><span class="line"></span><br><span class="line"><span class="comment"># perform classification</span></span><br><span class="line">net.forward()</span><br><span class="line"></span><br><span class="line"><span class="comment"># obtain the output probabilities</span></span><br><span class="line">output_prob = net.blobs[<span class="string">&#x27;prob&#x27;</span>].data[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># sort top five predictions from softmax output</span></span><br><span class="line">top_inds = output_prob.argsort()[::-<span class="number">1</span>][:<span class="number">5</span>]</span><br><span class="line"></span><br><span class="line">plt.imshow(image)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span> <span class="string">&#x27;probabilities and labels:&#x27;</span></span><br><span class="line"><span class="built_in">zip</span>(output_prob[top_inds], labels[top_inds])</span><br></pre></td></tr></table></figure>

<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a target="_blank" rel="noopener" href="http://demo.vislab.berkeleyvision.org/">demo</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/BVLC/caffe">caffe git</a></li>
</ul>
<h2 id="History"><a href="#History" class="headerlink" title="History"></a>History</h2><ul>
<li>20180807: created.</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/caffe/" rel="tag"># caffe</a>
              <a href="/tags/image-classification/" rel="tag"># image classification</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/blog/Tutorial-for-Training-LeNet-on-MNIST-with-Caffe/" rel="prev" title="Tutorial for Training LeNet on MNIST with Caffe">
      <i class="fa fa-chevron-left"></i> Tutorial for Training LeNet on MNIST with Caffe
    </a></div>
      <div class="post-nav-item">
    <a href="/blog/learning-lenet/" rel="next" title="learning lenet with caffe and python">
      learning lenet with caffe and python <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Tutorial"><span class="nav-number">1.</span> <span class="nav-text">Tutorial</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Setup"><span class="nav-number">1.1.</span> <span class="nav-text">Setup</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Load-net-and-set-up-input-preprocessing"><span class="nav-number">1.2.</span> <span class="nav-text">Load net and set up input preprocessing</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CPU-classification"><span class="nav-number">1.3.</span> <span class="nav-text">CPU classification</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Switching-to-GPU-mode"><span class="nav-number">1.4.</span> <span class="nav-text">Switching to GPU mode</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Examining-intermediate-output"><span class="nav-number">1.5.</span> <span class="nav-text">Examining intermediate output</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Try-your-own-image"><span class="nav-number">1.6.</span> <span class="nav-text">Try your own image</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-number">2.</span> <span class="nav-text">Reference</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#History"><span class="nav-number">3.</span> <span class="nav-text">History</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">kezunlin</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">181</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">213</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">kezunlin</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  

</body>
</html>
